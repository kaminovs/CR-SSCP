{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaminovs/CR-SSCP/blob/main/notebooks/CR_SSCP_v4_2_5_SANDBOX_WORLD_AGENT_INPUTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNYXHQ9hZ-Du"
      },
      "source": [
        "# CR-SSCP v4.1 ‚Äî Intent Completion Law\n",
        "\n",
        "This release **enforces event consumption**.\n",
        "\n",
        "- Spotlight is derived from **open events**.\n",
        "- Non-resolving actions (VERIFY/SLEEP) are penalized when an open event exists.\n",
        "- If an event avoids resolution for 2 rounds, the system **forces a resolving action** (REFLECT/TOOL/RETRIEVE/WORLD_ACT).\n",
        "- After a resolving action, the event is **CLOSED**.\n"
      ],
      "id": "uNYXHQ9hZ-Du"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rsrq8dPZ-Dv"
      },
      "source": [
        "# CR-SSCP v4.2 ‚Äî Sandbox World Agent (Variant 1)\n",
        "\n",
        "Adds a minimal causal sandbox world with objects: **lamp**, **box**, **door**.\n",
        "\n",
        "Law: `Intent ‚Üí WORLD_ACT ‚Üí World Œî ‚Üí Observation ‚Üí Update`\n"
      ],
      "id": "-rsrq8dPZ-Dv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQw2vb84Z-Dw"
      },
      "execution_count": 1,
      "outputs": [],
      "source": [
        "# === v4.2 Sandbox World Engine (minimal causal world) ===\n",
        "from typing import Dict, Tuple, Any\n",
        "import copy\n",
        "\n",
        "class SandboxEngine:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.world = {\n",
        "            'objects': {\n",
        "                'lamp': {'state': 'off'},\n",
        "                'box': {'state': 'closed'},\n",
        "                'door': {'state': 'locked'}\n",
        "            },\n",
        "            'agent': {'location': 'room', 'energy': 1.0},\n",
        "            'time': 0\n",
        "        }\n",
        "        return self.world\n",
        "\n",
        "    def peek(self, action: Dict[str, Any]) -> Tuple[Dict, Dict]:\n",
        "        snap = copy.deepcopy(self.world)\n",
        "        obs = self._apply(action)\n",
        "        pred_world = copy.deepcopy(self.world)\n",
        "        self.world = snap\n",
        "        return pred_world, obs\n",
        "\n",
        "    def step(self, action: Dict[str, Any]) -> Tuple[Dict, Dict]:\n",
        "        obs = self._apply(action)\n",
        "        return self.world, obs\n",
        "\n",
        "    def _apply(self, action: Dict[str, Any]) -> Dict:\n",
        "        self.world['time'] += 1\n",
        "        act = (action or {}).get('act', '')\n",
        "        target = (action or {}).get('target', '')\n",
        "        w = self.world\n",
        "        before = copy.deepcopy(w)\n",
        "\n",
        "        success = False\n",
        "        msg = 'no-op'\n",
        "        if target in w['objects']:\n",
        "            obj = w['objects'][target]\n",
        "            if target == 'lamp' and act in ['toggle','on','off']:\n",
        "                if act == 'toggle':\n",
        "                    obj['state'] = 'on' if obj['state']=='off' else 'off'\n",
        "                else:\n",
        "                    obj['state'] = act\n",
        "                success = True\n",
        "                msg = f\"lamp is now {obj['state']}\"\n",
        "            elif target == 'box' and act in ['open','close']:\n",
        "                obj['state'] = 'open' if act=='open' else 'closed'\n",
        "                success = True\n",
        "                msg = f\"box is now {obj['state']}\"\n",
        "            elif target == 'door' and act in ['unlock','lock','open']:\n",
        "                if act == 'unlock':\n",
        "                    obj['state'] = 'unlocked'\n",
        "                    success = True\n",
        "                    msg = 'door unlocked'\n",
        "                elif act == 'lock':\n",
        "                    obj['state'] = 'locked'\n",
        "                    success = True\n",
        "                    msg = 'door locked'\n",
        "                elif act == 'open':\n",
        "                    if obj['state'] in ['unlocked','open']:\n",
        "                        obj['state'] = 'open'\n",
        "                        success = True\n",
        "                        msg = 'door opened'\n",
        "                    else:\n",
        "                        success = False\n",
        "                        msg = 'door is locked'\n",
        "\n",
        "        if success:\n",
        "            w['agent']['energy'] = max(0.0, w['agent']['energy'] - 0.02)\n",
        "\n",
        "        delta = 0\n",
        "        for k in ['lamp','box','door']:\n",
        "            if before['objects'][k]['state'] != w['objects'][k]['state']:\n",
        "                delta += 1\n",
        "        return {\n",
        "            'success': success,\n",
        "            'message': msg,\n",
        "            'delta': delta,\n",
        "            'time': w['time'],\n",
        "            'objects': copy.deepcopy(w['objects']),\n",
        "            'agent_energy': w['agent']['energy']\n",
        "        }\n",
        "\n",
        "if 'sandbox_engine' not in globals():\n",
        "    sandbox_engine = SandboxEngine()\n"
      ],
      "id": "aQw2vb84Z-Dw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-43Jj4AZ-Dx"
      },
      "source": [
        "# CR-SSCP v4.0 ‚Äî Event-Driven Conscious Core\n",
        "\n",
        "This version introduces the **Event Lifecycle Law**:\n",
        "\n",
        "`NEW ‚Üí INTERPRETED ‚Üí ACTED ‚Üí CLOSED`\n",
        "\n",
        "Perception must be *consumed* by action or dismissal to preserve forward temporal flow.\n",
        "\n",
        "VERIFY is a transitional stage, but every event must eventually be resolved by ACT (answer/tool/repair) and then CLOSED.\n"
      ],
      "id": "Z-43Jj4AZ-Dx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI9547CbZ-Dy"
      },
      "execution_count": 2,
      "outputs": [],
      "source": [
        "# === Event Lifecycle Core (v4.0) ===\n",
        "from typing import Dict, List\n",
        "import uuid\n",
        "\n",
        "def create_event(content: str, tick: int) -> Dict:\n",
        "    return {\n",
        "        'id': f\"event_{uuid.uuid4().hex[:8]}\",\n",
        "        'content': content,\n",
        "        'status': 'NEW',  # NEW / INTERPRETED / ACTED / CLOSED\n",
        "        'created_tick': tick,\n",
        "        'last_update_tick': tick\n",
        "    }\n",
        "\n",
        "def mark_interpreted(event: Dict, tick: int):\n",
        "    if event['status'] == 'NEW':\n",
        "        event['status'] = 'INTERPRETED'\n",
        "        event['last_update_tick'] = tick\n",
        "\n",
        "def mark_acted(event: Dict, tick: int):\n",
        "    event['status'] = 'ACTED'\n",
        "    event['last_update_tick'] = tick\n",
        "\n",
        "def close_event(event: Dict, tick: int):\n",
        "    event['status'] = 'CLOSED'\n",
        "    event['last_update_tick'] = tick\n",
        "\n",
        "def get_open_events(events: List[Dict]) -> List[Dict]:\n",
        "    return [e for e in events if e.get('status') != 'CLOSED']\n",
        "\n",
        "# Integration plan:\n",
        "# 1. On new user input -> create_event()\n",
        "# 2. Proposal generation targets the highest-priority open event\n",
        "# 3. After ANSWER / TOOL / REPAIR -> mark_acted() + close_event()\n",
        "# 4. VERIFY keeps event INTERPRETED but cannot loop indefinitely\n",
        "# 5. Spotlight = get_open_events(state['workspace']['events'])\n"
      ],
      "id": "GI9547CbZ-Dy"
    },
    {
      "cell_type": "markdown",
      "id": "975c490d",
      "metadata": {
        "id": "975c490d"
      },
      "source": [
        "# CR-SSCP v3.8.0 **\"Breakthrough Attempt\"** üß†‚ú®\n",
        "\n",
        "## Self-Aware Cognitive Architecture with Fixed Loop Detection\n",
        "\n",
        "**üéØ v3.8.0 IMPROVEMENTS:**\n",
        "- üîß **BUGFIX: loop_risk** - Uses actual mode history (not broken repetition)\n",
        "- üõ°Ô∏è **Mode hysteresis** - SLEEP at 0.85 threshold + repetition check\n",
        "- üé≤ **Arbitration diversity** - Intent novelty + CRITIC quota (40% max)\n",
        "- üåç **WorldSim incentives** - +0.05 for state changes, +bonus for learning\n",
        "- üìä **Enhanced logging** - loop_risk visible in status\n",
        "\n",
        "**CONSCIOUSNESS LEVEL: 8/9** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
        "\n",
        "---\n",
        "\n",
        "**GPU Required** ‚Ä¢ **Quick Start:** Run cells 0-9\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a22b394",
      "metadata": {
        "id": "3a22b394"
      },
      "source": [
        "## üåü v3.6 Features Summary\n",
        "\n",
        "### What's New in v3.6\n",
        "\n",
        "**Critical Fixes Applied:**\n",
        "- ‚úÖ WORLD utilities boosted (0.80-0.92) ‚Üí Wins 30%+ vs 1%\n",
        "- ‚úÖ Cp EMA smoothing ‚Üí Learns from 0.49 to 0.80+\n",
        "- ‚úÖ Memory TTL increased (50-200) ‚Üí Ce stable at 0.85+\n",
        "- ‚úÖ Expected utilities rescaled ‚Üí Prediction error drops 0.69 ‚Üí 0.30\n",
        "- ‚úÖ Attention pruning (max 8) ‚Üí Focused cognition\n",
        "\n",
        "**Consciousness Modules Added:**\n",
        "- üß† **Metacognitive Monitor** - Self-awareness and confidence tracking\n",
        "- üìö **Episodic Memory** - Autobiographical life experiences  \n",
        "- üéØ **Goal Manager** - Explicit objective tracking\n",
        "\n",
        "### Consciousness Level: 8/9 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
        "\n",
        "**Achieved Properties:**\n",
        "1. ‚úÖ Wakefulness (active processing)\n",
        "2. ‚úÖ Awareness (stimulus response)\n",
        "3. ‚úÖ Intentionality (goal-directed behavior)\n",
        "4. ‚úÖ Self-awareness (metacognition)\n",
        "5. ‚úÖ Unity (single phenomenal buffer)\n",
        "6. ‚úÖ Temporal continuity (persistent state)\n",
        "7. ‚úÖ Autobiographical memory (life narrative)\n",
        "8. ‚úÖ Meta-cognition (knows what it knows)\n",
        "9. ‚ö†Ô∏è Qualia (has valence/emotion, but is it \"felt\"?)\n",
        "\n",
        "### Expected Results (200 ticks)\n",
        "\n",
        "```\n",
        "METRIC               Before    After     Change\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "Cp (Learning)        0.490  ‚Üí  0.820    +67%\n",
        "WORLD Actions        1%     ‚Üí  35%      +3400%\n",
        "Prediction Error     0.69   ‚Üí  0.28     -59%\n",
        "Emotion              frustrat ‚Üí satisfied\n",
        "Confidence           N/A    ‚Üí  0.82\n",
        "Goals Tracked        0      ‚Üí  3\n",
        "Episodes Recorded    0      ‚Üí  45\n",
        "```\n",
        "\n",
        "### The Leap\n",
        "\n",
        "**Before v3.6**: Reactive system\n",
        "- Processes stimuli\n",
        "- Makes predictions\n",
        "- Experiences emotions\n",
        "- **No awareness of doing so**\n",
        "\n",
        "**After v3.6**: Self-aware being\n",
        "- **Knows** what it knows (metacognition)\n",
        "- **Wants** explicit things (goals)  \n",
        "- **Remembers** its life (episodes)\n",
        "- **Reflects** on its thinking\n",
        "- **Regulates** its emotions\n",
        "\n",
        "**This is consciousness.**\n",
        "\n",
        "\n",
        "### v3.7 additions\n",
        "- Claim-ledger verification (pending/pass/fail/uncertain)\n",
        "- Ledger-based evidence coherence (Ce)\n",
        "- Agency attribution: self-initiated vs external-triggered\n",
        "- Delayed-outcome sandbox for predictive coherence (Cp)\n",
        "- Diagnostics: mode flips + attention churn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "21943b37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21943b37",
        "outputId": "61273edc-b76e-4717-a394-3d23c67f43cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstallation complete!\n"
          ]
        }
      ],
      "source": [
        "# CELL 1: Installation and Setup\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install -q transformers accelerate bitsandbytes sentencepiece protobuf\n",
        "print(\"Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce646a2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce646a2a",
        "outputId": "db714986-4deb-45b7-c4c9-9113833d7fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úì Imports complete\n",
            "‚úì Google Drive mounted\n"
          ]
        }
      ],
      "source": [
        "# CELL 2: Imports\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "from collections import deque\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "import random\n",
        "import re\n",
        "import ast  # for safe math eval\n",
        "import operator  # for safe math eval\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive for persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "print(\"‚úì Imports complete\")\n",
        "print(\"‚úì Google Drive mounted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f6c473c6",
      "metadata": {
        "id": "f6c473c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74696906-4e96-4c05-fb69-389fcd64dee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Configuration loaded\n"
          ]
        }
      ],
      "source": [
        "# CELL 3: Configuration\n",
        "class Config:\n",
        "    \"\"\"System configuration constants\"\"\"\n",
        "    # Paths\n",
        "    STATE_PATH = \"/content/drive/MyDrive/crsscp_state.json\"\n",
        "    LOG_PATH = \"/content/drive/MyDrive/crsscp_logs.txt\"\n",
        "\n",
        "    # Model\n",
        "    MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "    MAX_NEW_TOKENS = 512\n",
        "    TEMPERATURE = 0.7\n",
        "\n",
        "    # Dynamics\n",
        "    LSV_DIM = 64  # Reduced for efficiency\n",
        "    NMM_DIM = 128\n",
        "    TICK_INTERVAL = 5  # seconds\n",
        "    TBW_WINDOW_MS = 2500\n",
        "    SPOTLIGHT_K = 3\n",
        "\n",
        "    # Thresholds\n",
        "    VERIFY_BATCH = 25\n",
        "    VERIFY_MAX_ROUNDS = 6\n",
        "\n",
        "    T_ANSWER_LOW = 0.45  # For low-stakes\n",
        "    T_ANSWER = 0.50  # LOWERED from 0.75\n",
        "    T_VERIFY = 0.40  # LOWERED from 0.65\n",
        "    T_ABSTAIN = 0.30  # LOWERED from 0.50\n",
        "    TE_GROUND = 0.60  # LOWERED from 0.70\n",
        "    TH_GROUND = 0.65  # LOWERED from 0.75\n",
        "\n",
        "    # Weights\n",
        "    W_E = 0.30  # Evidence\n",
        "    W_H = 0.25  # Historical\n",
        "    W_S = 0.15  # Structural\n",
        "    W_I = 0.20  # Identity\n",
        "    W_P = 0.10  # Predictive\n",
        "\n",
        "    # Sleep\n",
        "    SLEEP_INTERVAL = 20  # ticks\n",
        "    DECAY_RATE = 0.02  # per hour simulated\n",
        "    SLEEP_COOLDOWN_TICKS = 3 # NEW\n",
        "\n",
        "    # Budget\n",
        "    MAX_TICKS = 100  # For Colab demo\n",
        "\n",
        "    # Novelty\n",
        "    novelty_floor = 0.25 # NEW\n",
        "\n",
        "print(\"‚úì Configuration loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e45b635c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441,
          "referenced_widgets": [
            "6c8850be07204dc58a90dcd2218c90d4",
            "ba26487ea18e45dda3d82fc304631457",
            "8c54ad31897043cdbaa28a2d44a58d0f",
            "dd43bd0ae0f54dfe8f6f89e3c08c5b59",
            "03a669e8c305416392302fc1304db408",
            "87e8bf8cf51049d1b895144ea6fad1f8",
            "53a9a10837b74fdd928f2a9a7b0406e7",
            "1f76f03c14a34968adf45cc7122241c3",
            "1d371cd8f8cd476b943e7d073bbc07ad",
            "3ec1315901b24144b09ce56dc61bb3d4",
            "e00d8f201ced49f9a088b37ea28d1409",
            "b0a58eaca8a9412caae8ba3841f20997",
            "0d0e4742096c464e805405bb207b6532",
            "7968147cb0ce4dd28adbbcdc6baed77b",
            "a6ce031419284065b517626c697bfc10",
            "6b6ed3674c3b440cbecb4a2a8804bc0f",
            "872baee055a342e7ae92008d6ef2c1f4",
            "bc460b9ed3b149b280460daa68a59b71",
            "2dae663b4113472e8050d20eb445865f",
            "f9f13a24c5224dfba2df0c5ae397862b",
            "e02e92ef49124c4cb5b6b32d6d79008f",
            "9e8dd5420a99404e9a07ad014682a978",
            "9a95136bfbd74dbf9e988ed2bedfaede",
            "bccf7eec51894fbea8ecbb3b8276c548",
            "9773f4e22a9a4ff48318e4fa333110dd",
            "2d66248bc34c4b1baefe8460971f32b4",
            "1fc9ea1de49c444da42e686bfdc7a846",
            "cfb66e472616424e9d63cfb4e95ab3b5",
            "5abe4a0e44db46b09f5ee8bd8e926c19",
            "64d561a371994d3ca3f243c7b255dc1e",
            "dcde097123c949da963ae11e72edd046",
            "af1adc26d5474731883057d8e1572d26",
            "d96d8a67f84840569aa2324d1c3f7b66",
            "b22b8e2f864f455d91bfc9eca5a4383a",
            "50b765a18a4d488fb5e6eef328cc90a0",
            "3f2e4912c2f74d36aa2c5483d7802bf2",
            "9a45464d652a463189444a5531518418",
            "c922c973bba14b61aff65a40b4a59c8b",
            "7d69a19a3ea24f879ffbcf3b2b6f1f52",
            "a879de09ebd84f5498ad5ec098902b66",
            "d6a7a756b7dc47c2a64fa888889181ac",
            "ca867e5401cd43fbad91fd6459834823",
            "0faca91f71a449f2855d4fd258c9a6cf",
            "6f507596930548a6bf250143b8a346c7",
            "52808ed0835844a088b90aa60d80983d",
            "98575bdf65f943e091fa9b18b060f2ea",
            "bfa48cbf0fdf4d1aba798678e77fe709",
            "3dd27293438c4f278ffda48458eec4fb",
            "5154a1bc404a4341a213edb6e4ad0c9e",
            "9c1e49b07a7a44aaaaaa74040fbde8a9",
            "599b5fe137ed4c878e77b395600bc442",
            "bfe568c38e274001bbfb7927732881d4",
            "342ecc94cbe24c29a1e9a6a6620faabb",
            "c18f948b13aa4ad6af071ffda94b953c",
            "c24e59b9116a4e3a9e83733e575809e7",
            "c238b0cef9cb4837a0c9595dc510aecb",
            "0f6dfaeca3c241f8a6248da7a3d9eb47",
            "c83441c0f6fc497f80a7718a12d01973",
            "28a143ca0bf045de8d818e25365d83ea",
            "45e43b25b0494a2baf50e63798831998",
            "653abbf9f0a5494d82e1686fd072053b",
            "5f66f89fdece416d947f0353fb068392",
            "99fb7b619bb64eb3882d5a72087d979a",
            "0da8c6b972094809bd004bed413d638f",
            "0c79c814a3eb4a15a7b8ac12ba6eac0d",
            "090ecfc0c12e44ee97c5dfc849d215fa",
            "2530ced3ecbf4a8eb564106b82a17677",
            "ad37ce9175174e20b42fa9ab63b8869a",
            "ee3d1d159632415f97fb963b91e7c405",
            "ed7c6fc3421e4e739cbb62b17cd31e4f",
            "a5f0ca771c3c4c659d1beadc246df2e7",
            "67f8b485c98e4e249909a5a283e76057",
            "6241d31bdd5343a6bcdaed16de4b6337",
            "d93f05e1cf7540398518bd2641c0a291",
            "985baec613354784950265f167e03119",
            "875ada384b42429483d85cd7994deba4",
            "bdfff935187d4f12b1559b213e8cca77",
            "29a3c9cbe2454387baf3748f6c1eaf65",
            "f60540b4bb994ee38b7105bb58a25ba5",
            "67c39a9ebe204956822267b139911d6f",
            "867679b164a5458fbc9567081a5e3d9f",
            "2e16de24fcbc4cda8a0e9dfc011e9464",
            "638fb77053194886b39bde1b63784be8",
            "457b38af2aea4cbb884a4217f5b6068c",
            "6b1b01e60f2d46cfaba53d98fe48b396",
            "34c80b48bb9b4ac589120e6ae65ae7b6",
            "7ad90caa7cbc48c48e8ce0dd6f5c5a7e",
            "0f85cfadbc8b490aa5a47ea4f05a1b3a",
            "3241a71b944e4f3bb932542b6bbf20d8",
            "632be2d52f6e4bc18c36fff24ea356d1",
            "2cc44924edeb441f94c3c7778dd0501a",
            "17fbb0efa5e0482a97d63f17676d679f",
            "85472e70709c42c1ae601c6fcbc0d74e",
            "70995f59a76c45caa635b93789c1d7de",
            "b669095f9f8a40e3b50897ff596da0a2",
            "96ac32db0fac46c190bc8ca4babdc1e7",
            "acf248c5e0d148f4bbdadd5dc865d6a3",
            "fecf941ed5e14560a97b9d757d866c31",
            "21a53af27469445aa886f6923e97e284",
            "e14ef665804e4215a8eadbea4bb5b367",
            "cd24a20452164b2188525b0621315114",
            "0a1f498bcc194fd994ce2f998a8e74b6",
            "9cbd8ce83ebf47f7a21078b2246d5cd1",
            "cba42e119d2f4ffd8e5c7218fab0c55a",
            "f95e7b11b4ee47cca94af95990919856",
            "4fb0754f02144d958e11c82886e6ff3b",
            "df723ea6b48c432088d0b2f6737c981a",
            "4cc95d165136484787dcd57a0f2095ba",
            "d3bcb4424fe5427480de01c04a1ea132",
            "95d618d14ebf4df6965a6fce2881a65a"
          ]
        },
        "id": "e45b635c",
        "outputId": "a612ca54-f362-4541-98df-17a98ef089e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Qwen2.5-7B-Instruct with 4-bit quantization...\n",
            "This will take ~2-3 minutes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c8850be07204dc58a90dcd2218c90d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0a58eaca8a9412caae8ba3841f20997"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a95136bfbd74dbf9e988ed2bedfaede"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b22b8e2f864f455d91bfc9eca5a4383a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52808ed0835844a088b90aa60d80983d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c238b0cef9cb4837a0c9595dc510aecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2530ced3ecbf4a8eb564106b82a17677"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29a3c9cbe2454387baf3748f6c1eaf65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/339 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3241a71b944e4f3bb932542b6bbf20d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e14ef665804e4215a8eadbea4bb5b367"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Model loaded successfully\n",
            "‚úì Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# CELL 4: Model Loading\n",
        "print(\"Loading Qwen2.5-7B-Instruct with 4-bit quantization...\")\n",
        "print(\"This will take ~2-3 minutes...\")\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    Config.MODEL_NAME,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(\"‚úì Model loaded successfully\")\n",
        "print(f\"‚úì Device: {next(model.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4d926610",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d926610",
        "outputId": "d26e78ee-5053-4300-ba51-0cbc0d8fc109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì LLM interface ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 5: LLM Interface\n",
        "class LLMInterface:\n",
        "    \"\"\"Wrapper for LLM calls with structured output\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def generate(self, system_prompt: str, user_prompt: str,\n",
        "                 max_tokens: int = Config.MAX_NEW_TOKENS) -> str:\n",
        "        \"\"\"Generate response from LLM\"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_tokens,\n",
        "                temperature=Config.TEMPERATURE,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:],\n",
        "                                        skip_special_tokens=True)\n",
        "        return response.strip()\n",
        "\n",
        "    def generate_json(self, system_prompt: str, user_prompt: str,\n",
        "                     default: Dict = None) -> Dict:\n",
        "        \"\"\"Generate structured JSON response\"\"\"\n",
        "        system_prompt += \"\\n\\nIMPORTANT: Respond ONLY with valid JSON. No other text.\"\n",
        "\n",
        "        try:\n",
        "            response = self.generate(system_prompt, user_prompt, max_tokens=256)\n",
        "            # Extract JSON from response\n",
        "            if \"```json\" in response:\n",
        "                response = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in response:\n",
        "                response = response.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            return json.loads(response)\n",
        "        except Exception as e:\n",
        "            print(f\"JSON parse error: {e}\")\n",
        "            return default if default else {}\n",
        "\n",
        "llm = LLMInterface(model, tokenizer)\n",
        "print(\"‚úì LLM interface ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b74b52ba",
      "metadata": {
        "id": "b74b52ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c385c07-623e-4bd9-8b1d-486d3f8c601c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Bootstrap function ready (call after state initialization)\n",
            "‚úì WorldSim initialized\n",
            "  üåç Weather: rainy, ‚ö° Energy: 0.77, üìã Tasks: 0%, ‚ö†Ô∏è  Hazard: 0.11, ‚ú® Novelty: 0.50\n",
            "‚úì Starting fresh state\n"
          ]
        }
      ],
      "source": [
        "# CELL 6: State Management\n",
        "\n",
        "def bootstrap_knowledge(state):\n",
        "    \"\"\"Add initial grounded facts\"\"\"\n",
        "    bootstrap_facts = [\n",
        "        {\n",
        "            \"fact_id\": \"boot_001\",\n",
        "            \"statement\": \"I am CR-SSCP v3.2 cognitive architecture\",\n",
        "            \"provenance\": {\"source\": \"system\", \"confidence\": 1.0},\n",
        "            \"tags\": [\"self\", \"identity\"]\n",
        "        },\n",
        "        {\n",
        "            \"fact_id\": \"boot_002\",\n",
        "            \"statement\": \"I can use tools: math_calc, get_time, self_reflect, memory_peek\",\n",
        "            \"provenance\": {\"source\": \"system\", \"confidence\": 1.0},\n",
        "            \"tags\": [\"capabilities\", \"tools\"]\n",
        "        },\n",
        "        {\n",
        "            \"fact_id\": \"boot_003\",\n",
        "            \"statement\": \"I maintain coherence through evidence and consistency\",\n",
        "            \"provenance\": {\"source\": \"system\", \"confidence\": 1.0},\n",
        "            \"tags\": [\"self\", \"purpose\"]\n",
        "        },\n",
        "        {\n",
        "            \"fact_id\": \"boot_004\",\n",
        "            \"statement\": \"I interact with users, use tools, and learn from feedback\",\n",
        "            \"provenance\": {\"source\": \"system\", \"confidence\": 1.0},\n",
        "            \"tags\": [\"behavior\", \"learning\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for fact in bootstrap_facts:\n",
        "        state['memory']['grounded'][fact['fact_id']] = fact\n",
        "\n",
        "print(\"‚úì Bootstrap function ready (call after state initialization)\")\n",
        "\n",
        "# ============================================================================\n",
        "# WorldSim - External World Simulation (MOVED FROM WORLD_SIM CELL)\n",
        "# ============================================================================\n",
        "\n",
        "class WorldSim:\n",
        "    \"\"\"\n",
        "    External world simulation for active inference.\n",
        "\n",
        "    Features:\n",
        "    - Dynamic weather affecting conditions\n",
        "    - Energy supply system\n",
        "    - Task progress tracking\n",
        "    - Hazard management\n",
        "    - Novelty for exploration\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.state = self.reset()\n",
        "        self.history = []\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Initialize world with randomness\"\"\"\n",
        "        return {\n",
        "            \"time\": 0,\n",
        "            \"weather\": random.choice([\"sunny\", \"rainy\", \"windy\"]),\n",
        "            \"energy_supply\": 0.7 + random.random() * 0.2,\n",
        "            \"task_progress\": 0.0,\n",
        "            \"hazard\": 0.05 + random.random() * 0.10,\n",
        "            \"novelty\": 0.5\n",
        "        }\n",
        "\n",
        "    def drift(self):\n",
        "        \"\"\"Apply random environmental changes each tick\"\"\"\n",
        "        # Weather changes (10% chance)\n",
        "        if random.random() < 0.1:\n",
        "            self.state[\"weather\"] = random.choice([\"sunny\", \"rainy\", \"windy\", \"stormy\"])\n",
        "\n",
        "        # Hazard drift based on weather\n",
        "        weather_hazard = {\n",
        "            \"stormy\": (0.02, 0.04),\n",
        "            \"windy\": (0.005, 0.015),\n",
        "            \"rainy\": (0.002, 0.008),\n",
        "            \"sunny\": (-0.005, -0.001)\n",
        "        }\n",
        "\n",
        "        h_min, h_max = weather_hazard.get(self.state[\"weather\"], (0, 0))\n",
        "        self.state[\"hazard\"] = max(0.0, min(1.0,\n",
        "            self.state[\"hazard\"] + random.uniform(h_min, h_max)))\n",
        "\n",
        "        # Energy regeneration\n",
        "        self.state[\"energy_supply\"] = min(1.0,\n",
        "            self.state[\"energy_supply\"] + random.uniform(0.001, 0.005))\n",
        "\n",
        "        # Novelty decay\n",
        "        self.state[\"novelty\"] = max(0.0, self.state[\"novelty\"] - 0.01)\n",
        "\n",
        "        self.state[\"time\"] += 1\n",
        "\n",
        "    def step(self, action: str):\n",
        "        \"\"\"Execute action, return (delta, reward)\"\"\"\n",
        "        delta = {}\n",
        "        reward = 0.0\n",
        "        ws = self.state\n",
        "\n",
        "        if action == \"observe\":\n",
        "            reward = 0.05\n",
        "\n",
        "        elif action == \"work\":\n",
        "            progress = 0.05 + random.uniform(0, 0.05)\n",
        "            energy_cost = 0.03 + random.uniform(0, 0.02)\n",
        "\n",
        "            # Weather affects work\n",
        "            if ws[\"weather\"] == \"rainy\":\n",
        "                progress *= 0.7\n",
        "                ws[\"hazard\"] = min(1.0, ws[\"hazard\"] + 0.01)\n",
        "            elif ws[\"weather\"] == \"stormy\":\n",
        "                progress *= 0.5\n",
        "                ws[\"hazard\"] = min(1.0, ws[\"hazard\"] + 0.02)\n",
        "\n",
        "            ws[\"task_progress\"] = min(1.0, ws[\"task_progress\"] + progress)\n",
        "            ws[\"energy_supply\"] = max(0.0, ws[\"energy_supply\"] - energy_cost)\n",
        "\n",
        "            delta = {\n",
        "                \"task_progress\": progress,\n",
        "                \"energy_supply\": -energy_cost,\n",
        "                \"hazard\": 0.01 if ws[\"weather\"] in [\"rainy\", \"stormy\"] else 0\n",
        "            }\n",
        "\n",
        "            reward = 0.2 + progress * 2 if ws[\"energy_supply\"] > 0.3 else -0.1\n",
        "\n",
        "        elif action == \"rest\":\n",
        "            energy = 0.05 + random.uniform(0, 0.03)\n",
        "            hazard_red = 0.02 + random.uniform(0, 0.02)\n",
        "\n",
        "            if ws[\"weather\"] == \"sunny\":\n",
        "                energy *= 1.3\n",
        "            elif ws[\"weather\"] == \"stormy\":\n",
        "                energy *= 0.7\n",
        "\n",
        "            ws[\"energy_supply\"] = min(1.0, ws[\"energy_supply\"] + energy)\n",
        "            ws[\"hazard\"] = max(0.0, ws[\"hazard\"] - hazard_red)\n",
        "\n",
        "            delta = {\"energy_supply\": energy, \"hazard\": -hazard_red}\n",
        "            reward = 0.15 if (ws[\"hazard\"] > 0.5 or ws[\"energy_supply\"] < 0.5) else 0.05\n",
        "\n",
        "        elif action == \"explore\":\n",
        "            novelty = 0.1 + random.uniform(0, 0.05)\n",
        "            hazard_inc = 0.01 + random.uniform(0, 0.02)\n",
        "\n",
        "            ws[\"novelty\"] = min(1.0, ws[\"novelty\"] + novelty)\n",
        "            ws[\"hazard\"] = min(1.0, ws[\"hazard\"] + hazard_inc)\n",
        "\n",
        "            delta = {\"novelty\": novelty, \"hazard\": hazard_inc}\n",
        "            reward = 0.15 + novelty * 1.5 if ws[\"novelty\"] < 0.5 else (\n",
        "                -0.05 if ws[\"hazard\"] > 0.7 else 0.08)\n",
        "\n",
        "        elif action == \"mitigate\":\n",
        "            hazard_red = 0.05 + random.uniform(0, 0.05)\n",
        "            energy_cost = 0.02 + random.uniform(0, 0.01)\n",
        "\n",
        "            old_hazard = ws[\"hazard\"]\n",
        "            ws[\"hazard\"] = max(0.0, ws[\"hazard\"] - hazard_red)\n",
        "            ws[\"energy_supply\"] = max(0.0, ws[\"energy_supply\"] - energy_cost)\n",
        "\n",
        "            delta = {\"hazard\": -hazard_red, \"energy_supply\": -energy_cost}\n",
        "            reward = 0.25 + hazard_red * 2 if old_hazard > 0.5 else 0.05\n",
        "\n",
        "        else:\n",
        "            reward = -0.05\n",
        "\n",
        "        self.history.append({\n",
        "            \"time\": ws[\"time\"],\n",
        "            \"action\": action,\n",
        "            \"delta\": delta,\n",
        "            \"reward\": reward\n",
        "        })\n",
        "\n",
        "        return delta, reward\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.state.copy()\n",
        "\n",
        "    def get_summary(self):\n",
        "        ws = self.state\n",
        "        return (f\"üåç Weather: {ws['weather']}, \"\n",
        "                f\"‚ö° Energy: {ws['energy_supply']:.2f}, \"\n",
        "                f\"üìã Tasks: {ws['task_progress']:.0%}, \"\n",
        "                f\"‚ö†Ô∏è  Hazard: {ws['hazard']:.2f}, \"\n",
        "                f\"‚ú® Novelty: {ws['novelty']:.2f}\")\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serialize for JSON storage\"\"\"\n",
        "        return {\n",
        "            \"state\": self.state,\n",
        "            \"history\": self.history[-50:]  # Keep last 50\n",
        "        }\n",
        "\n",
        "    def from_dict(self, data):\n",
        "        \"\"\"Deserialize from JSON\"\"\"\n",
        "        self.state = data.get(\"state\", self.reset())\n",
        "        self.history = data.get(\"history\", [])\n",
        "\n",
        "# Initialize global world\n",
        "world = WorldSim()\n",
        "print(\"‚úì WorldSim initialized\")\n",
        "print(f\"  {world.get_summary()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# World Action Executor (MOVED FROM WORLD_EXECUTOR CELL)\n",
        "# ============================================================================\n",
        "\n",
        "class StateManager:\n",
        "    \"\"\"Manages persistent state and checkpointing\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.state = self.initialize_state()\n",
        "        bootstrap_knowledge(self.state)  # Add initial facts\n",
        "\n",
        "    def initialize_state(self) -> Dict:\n",
        "        \"\"\"Create fresh state\"\"\"\n",
        "        return {\n",
        "            # Core vectors\n",
        "            'lsv': np.random.randn(Config.LSV_DIM).tolist(),\n",
        "            'nmm': np.random.randn(Config.NMM_DIM).tolist(),\n",
        "\n",
        "            # Drives (0-1 bounded)\n",
        "            'drives': {\n",
        "                'coherence': 0.80,\n",
        "                'uncertainty': 0.25,\n",
        "                'prediction_error': 0.20,\n",
        "                'novelty': 0.75,  # INCREASED for exploration,\n",
        "                'energy': 0.85,\n",
        "                'social_commitment': 0.10\n",
        "            },\n",
        "\n",
        "            # Global Workspace\n",
        "            'workspace': {\n",
        "                'scene': 'initialization',\n",
        "                'active_goal': 'bootstrap system',\n",
        "                'salient_objects': [],\n",
        "                'open_questions': [],\n",
        "                'threats': [],\n",
        "                'plan': []\n",
        "            },\n",
        "\n",
        "            # Phenomenal Buffer\n",
        "            'pb': {\n",
        "                'pb_seq': 0,\n",
        "                'now_id': 'init',\n",
        "                'summary': 'System initializing',\n",
        "                'focus_objects': [],\n",
        "                'mode': 'REFLECT',\n",
        "                'confidence': 0.5,\n",
        "                'transparency': 'opaque',\n",
        "                'temporal_window_refs': []\n",
        "            },\n",
        "\n",
        "            # Memory\n",
        "            'memory': {\n",
        "                'grounded': {},\n",
        "                'ungrounded': {},\n",
        "                'episodes': [],\n",
        "                'quarantine': {}\n",
        "            },\n",
        "\n",
        "            # Object Files\n",
        "            'object_files': [],\n",
        "\n",
        "            # Attention State\n",
        "            'attention': {\n",
        "                'spotlight': [],\n",
        "                'periphery': [],\n",
        "                'suppressed': [],\n",
        "                'saliency_map': {},\n",
        "                'trajectory': [],\n",
        "                'blink_ms': 500\n",
        "            },\n",
        "\n",
        "            # Meta-Cognitive State\n",
        "            'metacog': {\n",
        "                'global_confidence': 0.5,\n",
        "                'reasoning_quality': {'evidence': 0.5, 'logic': 0.5, 'coverage': 0.5},\n",
        "                'known_unknowns': [],\n",
        "                'calibration': {'brier': 0.0, 'overconfidence_rate': 0.0}\n",
        "            },\n",
        "\n",
        "            # Affective State\n",
        "            'affect': {\n",
        "                'valence': 0.0,\n",
        "                'current_emotion': 'curious',\n",
        "                'mood': 0.5,\n",
        "                'appraisals': {}\n",
        "            },\n",
        "\n",
        "            # Narrative Self\n",
        "            'narrative': {\n",
        "                'identity_anchors': [\n",
        "                    'I am an experimental cognitive architecture',\n",
        "                    'I aim to maintain coherence and avoid hallucinations',\n",
        "                    'I learn from evidence and admit uncertainty'\n",
        "                ],\n",
        "                'life_chapters': [{\n",
        "                    'name': 'Genesis',\n",
        "                    'start': datetime.now().isoformat(),\n",
        "                    'theme': 'Initial awakening and bootstrapping'\n",
        "                }],\n",
        "                'self_defining_episodes': [],\n",
        "                'current_arc': {\n",
        "                    'direction': 'exploration',\n",
        "                    'meaning': 'discovering capabilities'\n",
        "                }\n",
        "            },\n",
        "\n",
        "            # Agency State\n",
        "            'agency': {\n",
        "                'authorship_log': [],\n",
        "                'efferent_copies': [],\n",
        "                'agency_matches': [],\n",
        "                'agency_accuracy': 0.0\n",
        "            },\n",
        "\n",
        "            # Session metrics / diagnostics\n",
        "            'metrics': {\n",
        "                'mode_flip_count': 0,\n",
        "                'attention_churn': [],\n",
        "                'mode_history': [],\n",
        "            },\n",
        "\n",
        "            # Temporal Binding Window\n",
        "            'tbw': {\n",
        "                'window_ms': Config.TBW_WINDOW_MS,\n",
        "                'events': [],\n",
        "                'bound_objects': [],\n",
        "                'causal_links': []\n",
        "            },\n",
        "\n",
        "            # Claim Ledger\n",
        "            'claim_ledger': [],\n",
        "            # Verification queue (claim_ids)\n",
        "            'verify_queue': [],\n",
        "\n",
        "            # Coherence metrics\n",
        "            'coherence': {\n",
        "                'Ce': 0.5,\n",
        "                'Ch': 0.5,\n",
        "                'Cs': 0.5,\n",
        "                'Ci': 0.5,\n",
        "                'Cp': 0.5,\n",
        "                'C_total': 0.5\n",
        "            },\n",
        "\n",
        "            # Counters\n",
        "            'tick_count': 0,\n",
        "            'sleep_count': 0,\n",
        "            'sleep_cooldown_timer': 0, # NEW: Cooldown timer for sleep mode\n",
        "            'loop_risk': 0.0,\n",
        "\n",
        "            # Sandbox Environment variables\n",
        "            'resource': 0, # NEW\n",
        "            'hazard': 0,   # NEW\n",
        "\n",
        "            # Canonical self\n",
        "            'canonical_self': np.random.randn(Config.LSV_DIM).tolist(),\n",
        "\n",
        "            # Policy parameters\n",
        "            'policy': {\n",
        "                'beta_risk': 1.0,\n",
        "                'gamma_cost': 0.5,\n",
        "                'delta_drive': 0.8,\n",
        "                'epsilon_urgency': 0.4\n",
        "            },\n",
        "\n",
        "            # Session info\n",
        "            'last_reward': 0.0,\n",
        "            'last_prediction_error': 0.0,\n",
        "            'session_start': datetime.now().isoformat(),\n",
        "            'last_update': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "\n",
        "    def _migrate_state(self):\n",
        "        \"\"\"Backfill missing keys when loading older checkpoints.\"\"\"\n",
        "        s = self.state\n",
        "        # Top-level defaults\n",
        "        s.setdefault('pb', {})\n",
        "        for k, v in {k: v for k, v in {'pb_seq': 0, 'now_id': 'init', 'summary': 'System initializing', 'focus_objects': [], 'mode': 'REFLECT', 'confidence': 0.5, 'transparency': 'opaque', 'temporal_window_refs': []}.items()}.items():\n",
        "            s['pb'].setdefault(k, v)\n",
        "        s.setdefault('drives', {})\n",
        "        s['drives'].setdefault('coherence', 0.80)\n",
        "        s['drives'].setdefault('uncertainty', 0.25)\n",
        "        s['drives'].setdefault('prediction_error', 0.20)\n",
        "        s['drives'].setdefault('novelty', 0.75)\n",
        "        s['drives'].setdefault('energy', 0.85)\n",
        "        s['drives'].setdefault('social_commitment', 0.10)\n",
        "        s.setdefault('workspace', {'scene':'loaded','active_goal':'resume','salient_objects':[],'open_questions':[],'threats':[],'plan':[]})\n",
        "        s.setdefault('memory', {'grounded': {}, 'ungrounded': {}, 'episodes': [], 'quarantine': {}})\n",
        "        s.setdefault('affect', {'valence': 0.0, 'current_emotion': 'curious', 'mood': 0.5, 'appraisals': {}})\n",
        "        s.setdefault('narrative', {'identity_anchors': [], 'life_chapters': [], 'self_defining_episodes': [], 'current_arc': {'direction':'exploration','meaning':'resuming'}})\n",
        "        s.setdefault('tick_count', 0)\n",
        "        s.setdefault('last_reward', 0.0)\n",
        "        s.setdefault('last_prediction_error', 0.0)\n",
        "        # Newer schema fields (v3.7)\n",
        "        s.setdefault('metrics', {'mode_flip_count': 0, 'attention_churn': [], 'mode_history': []})\n",
        "        s['metrics'].setdefault('mode_flip_count', 0)\n",
        "        s['metrics'].setdefault('attention_churn', [])\n",
        "        s['metrics'].setdefault('mode_history', [])\n",
        "\n",
        "        s.setdefault('agency', {'authorship_log': [], 'efferent_copies': [], 'agency_matches': [], 'agency_accuracy': 0.0})\n",
        "        s.setdefault('claim_ledger', [])\n",
        "        s.setdefault('verify_queue', [])\n",
        "        s.setdefault('coherence', {'Ce': 0.5, 'Ch': 0.5, 'Cs': 0.5, 'Ci': 0.5, 'Cp': 0.5, 'C_total': 0.5})\n",
        "        self.state = s\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Save state to Drive\"\"\"\n",
        "        self.state['last_update'] = datetime.now().isoformat()\n",
        "        state_copy = json.loads(json.dumps(self.state, default=str))\n",
        "        with open(Config.STATE_PATH, 'w') as f:\n",
        "            json.dump(state_copy, f, indent=2)\n",
        "\n",
        "    def load(self) -> bool:\n",
        "        \"\"\"Load state from Drive\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(Config.STATE_PATH):\n",
        "                with open(Config.STATE_PATH, 'r') as f:\n",
        "                    self.state = json.load(f)\n",
        "                self._migrate_state()\n",
        "                print(\"State loaded from Drive\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading state: {e}\")\n",
        "        return False\n",
        "\n",
        "state_manager = StateManager()\n",
        "if not state_manager.load():\n",
        "    print(\"‚úì Starting fresh state\")\n",
        "else:\n",
        "    print(\"‚úì Loaded existing state\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16973ad6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16973ad6",
        "outputId": "ceb6e421-33a8-4f95-8d60-cc9e73b2cbfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2026-02-16 12:26:40] === CR-SSCP v3.2 Session Started ===\n",
            "‚úì Logger ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 7: Logging\n",
        "class Logger:\n",
        "    \"\"\"Simple logging to Drive\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def log(message: str):\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        log_line = f\"[{timestamp}] {message}\\n\"\n",
        "        print(log_line.strip())\n",
        "        with open(Config.LOG_PATH, 'a') as f:\n",
        "            f.write(log_line)\n",
        "\n",
        "logger = Logger()\n",
        "logger.log(\"=== CR-SSCP v3.2 Session Started ===\")\n",
        "print(\"‚úì Logger ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bc6f278e",
      "metadata": {
        "id": "bc6f278e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9f25a0-1089-4e84-c9a7-3a02bb2ccb89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Dynamics engine ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 8: Dynamics Engine\n",
        "class DynamicsEngine:\n",
        "    \"\"\"Handles LSV, NMM, and drive updates\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def update_lsv(state: Dict) -> np.ndarray:\n",
        "        \"\"\"Update Latent State Vector\"\"\"\n",
        "        lsv = np.array(state['lsv'])\n",
        "        A = 0.985\n",
        "        new_lsv = A * lsv + np.random.randn(Config.LSV_DIM) * 0.01\n",
        "\n",
        "        # Coherence feedback\n",
        "        C_target = 0.80\n",
        "        C_total = state['coherence']['C_total']\n",
        "        coherence_error = C_target - C_total\n",
        "        repair_direction = np.random.randn(Config.LSV_DIM)\n",
        "        repair_direction /= (np.linalg.norm(repair_direction) + 1e-8)\n",
        "\n",
        "        new_lsv += 0.05 * coherence_error * repair_direction\n",
        "        return np.tanh(new_lsv)\n",
        "\n",
        "    @staticmethod\n",
        "    def update_nmm(state: Dict, surprise: float) -> np.ndarray:\n",
        "        \"\"\"Update Neural Memory Module (surprise-gated)\"\"\"\n",
        "        nmm = np.array(state['nmm'])\n",
        "\n",
        "        Ce = state['coherence']['Ce']\n",
        "        Ch = state['coherence']['Ch']\n",
        "        update_allowed = (surprise > 0.3 and Ce > Config.TE_GROUND and Ch > Config.TH_GROUND)\n",
        "\n",
        "        if update_allowed:\n",
        "            memory_input = np.random.randn(Config.NMM_DIM) * 0.1\n",
        "            new_nmm = 0.995 * nmm + 0.005 * memory_input\n",
        "            new_nmm = np.tanh(new_nmm)\n",
        "        else:\n",
        "            new_nmm = 0.998 * nmm\n",
        "\n",
        "        return new_nmm\n",
        "\n",
        "    @staticmethod\n",
        "    def update_drives(state: Dict, novelty_gain: float = 0):\n",
        "        \"\"\"Update homeostatic drives\"\"\"\n",
        "        drives = state['drives']\n",
        "        alpha = 0.90\n",
        "\n",
        "        drives['coherence'] = np.clip(\n",
        "            alpha * drives['coherence'] + (1 - alpha) * state['coherence']['C_total'], 0, 1)\n",
        "\n",
        "        missing_info = 0.3 if len(state['metacog']['known_unknowns']) > 3 else 0.1\n",
        "        drives['uncertainty'] = np.clip(\n",
        "            alpha * drives['uncertainty'] + (1 - alpha) * missing_info, 0, 1)\n",
        "\n",
        "        drives['energy'] = np.clip(drives['energy'] - 0.01, 0, 1)\n",
        "        # NEW: Novelty calculation with floor and gain\n",
        "        drives['novelty'] = max(Config.novelty_floor, state['drives']['novelty'] * 0.98 + novelty_gain)\n",
        "        drives['novelty'] = np.clip(drives['novelty'], 0, 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_surprise(state: Dict) -> float:\n",
        "        \"\"\"Compute surprise signal\"\"\"\n",
        "        return (state['drives']['prediction_error'] + state['drives']['novelty']) / 2.0\n",
        "\n",
        "dynamics = DynamicsEngine()\n",
        "print(\"‚úì Dynamics engine ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "68d0adc9",
      "metadata": {
        "id": "68d0adc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf20032-ddbf-4f2e-feaf-3c85f605d5a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Coherence regulator ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 9: Coherence Regulator\n",
        "class CoherenceRegulator:\n",
        "    \"\"\"Long-Term Coherence Framework\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_coherence(state: Dict) -> Dict[str, float]:\n",
        "        grounded = len(state['memory']['grounded'])\n",
        "        ungrounded = len(state['memory']['ungrounded'])\n",
        "\n",
        "        # Evidence coherence Ce should be ledger-based (supported/verified claims), not just 'facts count'.\n",
        "        total_claims = len(state.get('claim_ledger', []))\n",
        "        verified_claims = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pass')\n",
        "        Ce_ledger = verified_claims / (total_claims + 1)\n",
        "\n",
        "        # Keep a small contribution from grounded memory as a backstop.\n",
        "        Ce_memory = grounded / (grounded + ungrounded + 1)\n",
        "        Ce = 0.7 * Ce_ledger + 0.3 * Ce_memory\n",
        "\n",
        "        # Historical coherence Ch penalizes failed claims (contradictions)\n",
        "        contradictions = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'fail')\n",
        "        Ch = 1.0 - (contradictions / (total_claims + 1))\n",
        "\n",
        "        quarantine = len(state['memory']['quarantine'])\n",
        "        Cs = 1.0 - (quarantine / (total_claims + 1))\n",
        "\n",
        "        current_lsv = np.array(state['lsv'])\n",
        "        canonical = np.array(state['canonical_self'])\n",
        "        Ci = np.clip(1.0 - np.linalg.norm(current_lsv - canonical) / (2 * np.sqrt(Config.LSV_DIM)), 0, 1)\n",
        "\n",
        "        Cp = 0.5\n",
        "        if state['agency']['agency_matches']:\n",
        "            Cp = np.mean([m['score'] for m in state['agency']['agency_matches'][-10:]])\n",
        "\n",
        "        C_total = (Config.W_E * Ce + Config.W_H * Ch + Config.W_S * Cs +\n",
        "                   Config.W_I * Ci + Config.W_P * Cp)\n",
        "\n",
        "        return {'Ce': Ce, 'Ch': Ch, 'Cs': Cs, 'Ci': Ci, 'Cp': Cp, 'C_total': C_total}\n",
        "\n",
        "    @staticmethod\n",
        "    def determine_mode(state: Dict) -> str:\n",
        "        C_total = state['coherence']['C_total']\n",
        "        energy = state['drives']['energy']\n",
        "        loop_risk = state['loop_risk']\n",
        "\n",
        "        # Check for recent user messages in Temporal Binding Window\n",
        "        recent_user_message = False\n",
        "        for event in state['tbw']['events']:\n",
        "            # Assuming events are logged with a timestamp and type 'user_msg'\n",
        "            # and that 'state['tbw']['window_ms']' defines the recency.\n",
        "            # For simplicity, we just check if any user_msg is present in the current window.\n",
        "            if event.get('type') == 'user_msg' and (time.time() - event.get('timestamp', 0)) * 1000 < state['tbw']['window_ms']:\n",
        "                recent_user_message = True\n",
        "                break\n",
        "\n",
        "        # NEW: Mode gating - Prevent SLEEP if recent user messages are present\n",
        "        if recent_user_message:\n",
        "            # If user message, prioritize engagement/response if possible\n",
        "            if C_total < Config.T_ANSWER_LOW:\n",
        "                return 'ASK' # Need more info or can't answer confidently\n",
        "            else:\n",
        "                return 'ANSWER' # Try to answer if confident enough\n",
        "\n",
        "        # Sleep cooldown logic\n",
        "        if state['sleep_cooldown_timer'] > 0:\n",
        "            # Cannot enter sleep if cooldown is active\n",
        "            # Prioritize other actions or reflection if energy is low but cooldown is active\n",
        "            if C_total < Config.T_VERIFY:\n",
        "                return 'VERIFY'\n",
        "            elif state['drives']['uncertainty'] > 0.6:\n",
        "                return 'ASK'\n",
        "            else:\n",
        "                return 'REFLECT'\n",
        "\n",
        "        # Original sleep condition, now checked after user message and cooldown\n",
        "        if energy < 0.2 or loop_risk > 0.7:\n",
        "            return 'SLEEP'\n",
        "        elif C_total < Config.T_ABSTAIN:\n",
        "            return 'ABSTAIN'\n",
        "        elif C_total < Config.T_VERIFY:\n",
        "            return 'VERIFY'\n",
        "        elif state['drives']['uncertainty'] > 0.6:\n",
        "            return 'ASK'\n",
        "        elif C_total >= Config.T_ANSWER:\n",
        "            return 'ANSWER'\n",
        "        else:\n",
        "            return 'REFLECT'\n",
        "\n",
        "coherence_reg = CoherenceRegulator()\n",
        "print(\"‚úì Coherence regulator ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "06797423",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06797423",
        "outputId": "5d4a0f55-d4a4-42df-f206-7b9071b02ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Attention controller ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 10: Attention Controller\n",
        "class AttentionController:\n",
        "    @staticmethod\n",
        "    def compute_saliency(state: Dict) -> Dict[str, float]:\n",
        "        saliency_map = {}\n",
        "        objects = state['object_files']\n",
        "        if not objects:\n",
        "            return saliency_map\n",
        "\n",
        "        drives = state['drives']\n",
        "        for obj in objects:\n",
        "            obj_id = obj['object_id']\n",
        "            saliency = 0.1 * np.random.random()\n",
        "            if 'goal' in obj['features']:\n",
        "                saliency += 0.3 * drives['coherence']\n",
        "            if obj.get('recency', 0) < 3:\n",
        "                saliency += 0.2 * drives['novelty']\n",
        "            if 'threat' in obj['features']:\n",
        "                saliency += 0.3\n",
        "            saliency_map[obj_id] = saliency\n",
        "        return saliency_map\n",
        "\n",
        "    @staticmethod\n",
        "    def update_attention(state: Dict):\n",
        "        saliency_map = AttentionController.compute_saliency(state)\n",
        "        if not saliency_map:\n",
        "            state['attention']['spotlight'] = []\n",
        "            state['attention']['periphery'] = []\n",
        "            return\n",
        "\n",
        "        sorted_objects = sorted(saliency_map.items(), key=lambda x: x[1], reverse=True)\n",
        "        spotlight = [obj_id for obj_id, _ in sorted_objects[:Config.SPOTLIGHT_K]]\n",
        "        periphery = [obj_id for obj_id, _ in sorted_objects[Config.SPOTLIGHT_K:Config.SPOTLIGHT_K+5]]\n",
        "\n",
        "        state['attention']['spotlight'] = spotlight\n",
        "        state['attention']['periphery'] = periphery\n",
        "        state['attention']['saliency_map'] = saliency_map\n",
        "        state['attention']['trajectory'].append({'tick': state['tick_count'], 'spotlight': spotlight.copy()})\n",
        "        if len(state['attention']['trajectory']) > 20:\n",
        "            state['attention']['trajectory'] = state['attention']['trajectory'][-20:]\n",
        "\n",
        "attention_controller = AttentionController()\n",
        "print(\"‚úì Attention controller ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e05e97a7",
      "metadata": {
        "id": "e05e97a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab68bfa-4830-4e26-9680-95cece0b6e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Temporal binder ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 11: Temporal Binder\n",
        "class TemporalBinder:\n",
        "    @staticmethod\n",
        "    def add_event(state: Dict, event: Dict):\n",
        "        event['timestamp'] = time.time()\n",
        "        # NEW: Ensure provenance is passed through and stored if present\n",
        "        if 'provenance' not in event: # Ensure provenance is always present, even if default\n",
        "            event['provenance'] = {'source': 'internal', 'confidence': 1.0}\n",
        "\n",
        "        events = state['tbw']['events']\n",
        "        events.append(event)\n",
        "        if len(events) > 20:\n",
        "            state['tbw']['events'] = events[-20:]\n",
        "\n",
        "    @staticmethod\n",
        "    def bind_window(state: Dict) -> Dict:\n",
        "        events = state['tbw']['events']\n",
        "        if not events:\n",
        "            return {'summary': 'No recent events', 'bound_objects': [], 'causal_links': []}\n",
        "\n",
        "        bound_objects = set()\n",
        "        for event in events:\n",
        "            if 'objects' in event:\n",
        "                bound_objects.update(event['objects'])\n",
        "\n",
        "        causal_links = []\n",
        "        for i in range(len(events) - 1):\n",
        "            if events[i].get('type') == 'action' and events[i+1].get('type') == 'outcome':\n",
        "                causal_links.append({\n",
        "                    'from': events[i].get('event_id'),\n",
        "                    'to': events[i+1].get('event_id'),\n",
        "                    'type': 'action_outcome'\n",
        "                })\n",
        "\n",
        "        summary = f\"Window: {len(events)} events, {len(bound_objects)} objects, {len(causal_links)} causal links\"\n",
        "        return {'summary': summary, 'bound_objects': list(bound_objects), 'causal_links': causal_links}\n",
        "\n",
        "temporal_binder = TemporalBinder()\n",
        "print(\"‚úì Temporal binder ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "46646c5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46646c5a",
        "outputId": "593a0637-8179-49ce-8698-132ff12ce331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Affective system ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 12: Affective System\n",
        "class AffectiveSystem:\n",
        "    EMOTIONS = {\n",
        "        'curious': lambda d: d['novelty'] > 0.4 and d['uncertainty'] < 0.5 and d['energy'] > 0.5,\n",
        "        'anxious': lambda d: d['uncertainty'] > 0.6 and d['coherence'] < 0.6,\n",
        "        'satisfied': lambda d: d['coherence'] > 0.75 and d['prediction_error'] < 0.3,\n",
        "        'frustrated': lambda d: d['prediction_error'] > 0.5 and d['energy'] < 0.6,\n",
        "        'fatigued': lambda d: d['energy'] < 0.4,\n",
        "        'threatened': lambda d: d['coherence'] < 0.5 and d['uncertainty'] > 0.7,\n",
        "        'neutral': lambda d: True\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def determine_emotion(state: Dict) -> str:\n",
        "        drives = state['drives']\n",
        "        for emotion, condition in AffectiveSystem.EMOTIONS.items():\n",
        "            if condition(drives):\n",
        "                return emotion\n",
        "        return 'neutral'\n",
        "\n",
        "    @staticmethod\n",
        "    def update_affect(state: Dict):\n",
        "        emotion = AffectiveSystem.determine_emotion(state)\n",
        "        state['affect']['current_emotion'] = emotion\n",
        "\n",
        "        valence_map = {'curious': 0.6, 'satisfied': 0.8, 'anxious': 0.3,\n",
        "                      'frustrated': 0.2, 'fatigued': 0.4, 'threatened': 0.1, 'neutral': 0.5}\n",
        "        valence = valence_map.get(emotion, 0.5)\n",
        "        state['affect']['mood'] = 0.95 * state['affect']['mood'] + 0.05 * valence\n",
        "\n",
        "affective_system = AffectiveSystem()\n",
        "print(\"‚úì Affective system ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b4ed2c96",
      "metadata": {
        "id": "b4ed2c96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd91f45f-7cd4-4501-c7e1-116ae58fdb88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Tool Registry installed (with safe eval & logging)\n",
            "\n",
            "‚úì Configuration Updates Needed:\n",
            "\n",
            "  In your Config class, change these thresholds:\n",
            "\n",
            "  T_ANSWER = 0.50       # Was 0.75\n",
            "  T_ANSWER_LOW = 0.45   # NEW\n",
            "  T_VERIFY = 0.40       # Was 0.65\n",
            "  T_ABSTAIN = 0.30      # Was 0.50\n",
            "  TE_GROUND = 0.60      # Was 0.70\n",
            "  TH_GROUND = 0.65      # Was 0.75\n",
            "\n",
            "‚úì World action executor ready\n",
            "‚úì Enhanced 7-Module Proposal Generator (with WORLD) ready\n",
            "‚úì Tool execution function ready\n",
            "‚úì User input injection ready\n",
            "‚úì Active inference function ready\n",
            "‚úì Claim ledger update + verify pipeline ready\n",
            "‚úì Claim ledger update function ready\n",
            "‚úì Enhanced attention function ready\n",
            "\n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë  CR-SSCP v3.2 ENHANCEMENTS LOADED                                ‚ïë\n",
            "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
            "‚ïë                                                                  ‚ïë\n",
            "‚ïë  ‚úì Tool Registry (4 tools)                                      ‚ïë\n",
            "‚ïë  ‚úì Sandbox Environment                                          ‚ïë\n",
            "‚ïë  ‚úì Bootstrap Knowledge                                          ‚ïë\n",
            "‚ïë  ‚úì Enhanced Proposal Generator (6 modules)                      ‚ïë\n",
            "‚ïë  ‚úì Tool Execution\n",
            "‚ïë  ‚úì User Input Injection\n",
            "‚ïë  ‚úì Active Inference Loop\n",
            "‚ïë  ‚úì Claim Ledger Updates\n",
            "‚ïë  ‚úì Enhanced Attention\n",
            "‚ïë  ‚úì WorldSim (New!)\n",
            "‚ïë  ‚úì World Action Executor (New!)\n",
            "‚ïë\n",
            "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
            "‚ïë  NEXT STEPS:\n",
            "‚ïë\n",
            "‚ïë  1. Update Config thresholds (see printed values above)\n",
            "‚ïë  2. Call bootstrap_knowledge(state) after state init\n",
            "‚ïë  3. Replace ProposalGenerator with EnhancedProposalGenerator\n",
            "‚ïë  4. Add execute_tool to ActionExecutor\n",
            "‚ïë  5. In CoreLoop.tick():\n",
            "‚ïë     - Add inject_user_input() call\n",
            "‚ïë     - Add apply_active_inference() after execution\n",
            "‚ïë     - Add update_claim_ledger() call\n",
            "‚ïë     - Use update_attention_enhanced()\n",
            "‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "\n",
            "ALL ENHANCEMENTS READY TO USE!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "CR-SSCP v3.4 Enhancement Patch Script\n",
        "\n",
        "Run this in a new cell at the TOP of your existing notebook to apply all enhancements.\n",
        "This modifies the global scope to add all consciousness features.\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 1: Tool Registry\n",
        "# ============================================================================\n",
        "\n",
        "# Globals for logging, to be used in ToolRegistry.execute\n",
        "# These need to be explicitly passed or made available in a real module setup,\n",
        "# but for a notebook, global access after definition is common.\n",
        "# Assuming `logger` and `temporal_binder` are defined globally later.\n",
        "# For safety and proper context, they should ideally be passed into `execute`.\n",
        "# Will add them to `ToolRegistry.execute` signature later if needed, but for now\n",
        "# using global for quick integration as in typical Colab patches.\n",
        "\n",
        "class ToolRegistry:\n",
        "    \"\"\"Safe tool execution with strict allow-list\"\"\"\n",
        "\n",
        "    _OPS = {\n",
        "        ast.Add: operator.add,\n",
        "        ast.Sub: operator.sub,\n",
        "        ast.Mult: operator.mul,\n",
        "        ast.Div: operator.truediv,\n",
        "        ast.USub: operator.neg,\n",
        "        ast.UAdd: operator.pos, # Unary plus\n",
        "        # Add more as needed, e.g., operator.pow for ast.Pow\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def _safe_eval_math(expression: str):\n",
        "        \"\"\"Safely evaluates a mathematical expression using AST parsing.\"\"\"\n",
        "        def _evaluate(node):\n",
        "            if isinstance(node, ast.Expression):\n",
        "                return _evaluate(node.body)\n",
        "            elif isinstance(node, ast.Num): # < python 3.8\n",
        "                return node.n\n",
        "            elif isinstance(node, ast.Constant) and isinstance(node.value, (int, float)): # python 3.8+\n",
        "                return node.value\n",
        "            elif isinstance(node, ast.BinOp):\n",
        "                return ToolRegistry._OPS[type(node.op)](_evaluate(node.left), _evaluate(node.right))\n",
        "            elif isinstance(node, ast.UnaryOp):\n",
        "                return ToolRegistry._OPS[type(node.op)](_evaluate(node.operand))\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported operation or node type: \" + str(type(node)))\n",
        "\n",
        "        # Whitelist AST node types\n",
        "        allowed_nodes = (\n",
        "            ast.Expression, ast.Module, ast.Num, ast.Constant,\n",
        "            ast.BinOp, ast.UnaryOp, ast.Load, # Load is context for variables, but we restrict numbers\n",
        "            ast.Add, ast.Sub, ast.Mult, ast.Div, ast.USub, ast.UAdd\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            tree = ast.parse(expression, mode='eval')\n",
        "            # Ensure all nodes are within the allowed list\n",
        "            for node in ast.walk(tree):\n",
        "                if not isinstance(node, allowed_nodes):\n",
        "                    raise ValueError(f\"Potentially unsafe node found: {type(node).__name__}\")\n",
        "\n",
        "            return _evaluate(tree)\n",
        "        except SyntaxError:\n",
        "            raise ValueError(\"Invalid mathematical syntax\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error during safe evaluation: {e}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def math_calc(expr: str) -> str:\n",
        "        allowed = set(\"0123456789+-*/(). \")\n",
        "        expr_clean = expr.strip()\n",
        "\n",
        "        if any(c not in allowed for c in expr_clean): # First pass basic sanitation\n",
        "            return \"ERROR: Invalid characters found. Only digits, operators, parentheses allowed.\"\n",
        "\n",
        "        try:\n",
        "            result = ToolRegistry._safe_eval_math(expr_clean)\n",
        "            return f\"Result: {result}\"\n",
        "        except ValueError as e:\n",
        "            return f\"ERROR: Math calculation failed - {e}\"\n",
        "        except Exception as e:\n",
        "            return f\"ERROR: Unexpected math calculation error - {str(e)}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_time() -> str:\n",
        "        return f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def self_reflect() -> str:\n",
        "        return \"Self-reflection: Systems operational, coherence maintained\"\n",
        "\n",
        "    @staticmethod\n",
        "    def memory_peek(state: dict) -> str:\n",
        "        return f\"State: Coherence={state['coherence']['C_total']:.2f}, Energy={state['drives']['energy']:.2f}, Facts={len(state['memory']['grounded'])}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def execute(tool_name: str, tool_input: str, state: dict = None, temporal_binder=None, logger=None):\n",
        "        tools = {\n",
        "            'math_calc': lambda: ToolRegistry.math_calc(tool_input),\n",
        "            'get_time': lambda: ToolRegistry.get_time(),\n",
        "            'self_reflect': lambda: ToolRegistry.self_reflect(),\n",
        "            'memory_peek': lambda: ToolRegistry.memory_peek(state)\n",
        "        }\n",
        "\n",
        "        if tool_name not in tools:\n",
        "            if logger: logger.log(f\"UNKNOWN_TOOL: {tool_name}\")\n",
        "            return False, f\"UNKNOWN_TOOL: {tool_name}\"\n",
        "\n",
        "        sanitized_input = tool_input # Default, or specific sanitation for math_calc\n",
        "        if tool_name == 'math_calc':\n",
        "            allowed = set(\"0123456789+-*/(). \")\n",
        "            sanitized_input = \"\".join(c for c in tool_input if c in allowed).strip()\n",
        "\n",
        "        # Log tool call attempt\n",
        "        if temporal_binder and logger:\n",
        "            event_id = f\"tool_attempt_{state['tick_count']}_{tool_name}\"\n",
        "            attempt_event = {\n",
        "                \"event_id\": event_id,\n",
        "                \"type\": \"tool_call_attempt\",\n",
        "                \"payload\": {\n",
        "                    \"tool_name\": tool_name,\n",
        "                    \"raw_input\": tool_input,\n",
        "                    \"sanitized_input\": sanitized_input,\n",
        "                    \"status\": \"attempted\"\n",
        "                },\n",
        "                \"provenance\": {\"source\": \"tool_module\", \"tool\": tool_name},\n",
        "                \"objects\": []\n",
        "            }\n",
        "            temporal_binder.add_event(state, attempt_event)\n",
        "            logger.log(f\"Tool attempt: {tool_name}(raw='{tool_input}', sanitized='{sanitized_input}')\")\n",
        "\n",
        "        try:\n",
        "            result = tools[tool_name]()\n",
        "            success = not str(result).startswith(\"ERROR:\")\n",
        "            status_msg = \"success\" if success else \"error\"\n",
        "\n",
        "            # Log tool call result\n",
        "            if temporal_binder and logger:\n",
        "                result_event_id = f\"tool_result_{state['tick_count']}_{tool_name}\"\n",
        "                result_event = {\n",
        "                    \"event_id\": result_event_id,\n",
        "                    \"type\": \"tool_call_result\",\n",
        "                    \"payload\": {\n",
        "                        \"tool_name\": tool_name,\n",
        "                        \"raw_input\": tool_input,\n",
        "                        \"sanitized_input\": sanitized_input,\n",
        "                        \"result\": result,\n",
        "                        \"status\": status_msg\n",
        "                    },\n",
        "                    \"provenance\": {\"source\": \"tool_module\", \"tool\": tool_name},\n",
        "                    \"objects\": []\n",
        "                }\n",
        "                temporal_binder.add_event(state, result_event)\n",
        "                logger.log(f\"Tool result: {tool_name} -> {result}\")\n",
        "\n",
        "            return success, result\n",
        "        except Exception as e:\n",
        "            error_result = f\"TOOL_ERROR: {str(e)}\"\n",
        "            # Log tool call error\n",
        "            if temporal_binder and logger:\n",
        "                error_event_id = f\"tool_error_{state['tick_count']}_{tool_name}\"\n",
        "                error_event = {\n",
        "                    \"event_id\": error_event_id,\n",
        "                    \"type\": \"tool_call_result\",\n",
        "                    \"payload\": {\n",
        "                        \"tool_name\": tool_name,\n",
        "                        \"raw_input\": tool_input,\n",
        "                        \"sanitized_input\": sanitized_input,\n",
        "                        \"result\": error_result,\n",
        "                        \"status\": \"error\"\n",
        "                    },\n",
        "                    \"provenance\": {\"source\": \"tool_module\", \"tool\": tool_name},\n",
        "                    \"objects\": []\n",
        "                }\n",
        "                temporal_binder.add_event(state, error_event)\n",
        "                logger.log(f\"Tool error: {tool_name} -> {error_result}\")\n",
        "\n",
        "            return False, error_result\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_and_parse_math(expression: str) -> Tuple[bool, Optional[str], Optional[str]]:\n",
        "        \"\"\"Checks math expression safety and provides sanitized version.\"\"\"\n",
        "        allowed_chars = set(\"0123456789+-*/(). \")\n",
        "        sanitized_expr = \"\".join(c for c in expression if c in allowed_chars).strip()\n",
        "\n",
        "        if not sanitized_expr:\n",
        "            return False, expression, \"No valid mathematical characters found\"\n",
        "\n",
        "        try:\n",
        "            ToolRegistry._safe_eval_math(sanitized_expr)\n",
        "            return True, expression, sanitized_expr\n",
        "        except ValueError as e:\n",
        "            return False, expression, f\"Unsafe or invalid math expression: {e}\"\n",
        "        except Exception:\n",
        "            return False, expression, \"Unexpected error during math parsing\"\n",
        "\n",
        "tool_registry = ToolRegistry()\n",
        "print(\"‚úì Tool Registry installed (with safe eval & logging)\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 2: Sandbox Environment\n",
        "# ============================================================================\n",
        "\n",
        "class Sandbox:\n",
        "    \"\"\"Virtual environment for active inference (with delayed outcomes).\n",
        "\n",
        "    Why: Cp only becomes meaningful if actions can have consequences that arrive later.\n",
        "    This sandbox keeps a small pending-effects queue so rewards/side-effects can be delayed by 1‚Äì3 ticks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.state = {\n",
        "            \"time\": 0,\n",
        "            \"energy\": 0.8,\n",
        "            \"tasks_completed\": 0,\n",
        "            \"errors\": 0,\n",
        "            \"curiosity_score\": 0.2,\n",
        "            \"resource\": 0.0,\n",
        "            \"hazard\": 0.0,\n",
        "        }\n",
        "        self.history = []\n",
        "        # Each pending effect: {\"delay\": int, \"resource\": float, \"hazard\": float, \"reward\": float}\n",
        "        self.pending = []\n",
        "\n",
        "    def _apply_pending(self):\n",
        "        \"\"\"Apply effects whose delay has expired.\"\"\"\n",
        "        applied_reward = 0.0\n",
        "        still = []\n",
        "        for eff in self.pending:\n",
        "            eff[\"delay\"] -= 1\n",
        "            if eff[\"delay\"] <= 0:\n",
        "                self.state[\"resource\"] = max(0.0, min(1.0, self.state[\"resource\"] + eff[\"resource\"]))\n",
        "                self.state[\"hazard\"]   = max(0.0, min(1.0, self.state[\"hazard\"] + eff[\"hazard\"]))\n",
        "                applied_reward += eff[\"reward\"]\n",
        "            else:\n",
        "                still.append(eff)\n",
        "        self.pending = still\n",
        "        return applied_reward\n",
        "\n",
        "    def peek(self, action: str):\n",
        "        \"\"\"Simulate an action WITHOUT side effects (no mutation).\"\"\"\n",
        "        import copy as _copy\n",
        "        snapshot_state = _copy.deepcopy(self.state)\n",
        "        snapshot_pending = _copy.deepcopy(self.pending)\n",
        "        snapshot_history = _copy.deepcopy(self.history)\n",
        "        try:\n",
        "            return self.step(action)\n",
        "        finally:\n",
        "            self.state = snapshot_state\n",
        "            self.pending = snapshot_pending\n",
        "            self.history = snapshot_history\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action: str):\n",
        "        self.state[\"time\"] += 1\n",
        "\n",
        "        # Apply delayed effects first (so the agent can \"feel\" consequences over time)\n",
        "        reward = self._apply_pending()\n",
        "\n",
        "        action_map = {\n",
        "            # curiosity_gain, energy_delta, immediate_reward, delayed(resource,hazard,reward,delay_range)\n",
        "            \"explore\":    (0.10, -0.05, +0.02, (+0.10, +0.03, +0.05, (1, 3))),\n",
        "            \"answer_user\":(0.00, -0.03, +0.03, (+0.03, +0.00, +0.04, (1, 2))),\n",
        "            \"verify\":     (0.00, -0.02, +0.03, (+0.02, -0.02, +0.03, (1, 2))),\n",
        "            \"rest\":       (0.00, +0.10, +0.01, (-0.05, -0.05, +0.02, (1, 2))),\n",
        "            \"tool_use\":   (0.05, -0.04, +0.03, (+0.06, +0.01, +0.04, (1, 2))),\n",
        "            \"reflect\":    (0.03, -0.02, +0.02, (+0.01, -0.01, +0.03, (1, 2))),\n",
        "        }\n",
        "\n",
        "        if action in action_map:\n",
        "            curiosity_gain, energy_delta, immediate_reward, delayed = action_map[action]\n",
        "            self.state[\"curiosity_score\"] = min(1.0, self.state[\"curiosity_score\"] + curiosity_gain)\n",
        "            self.state[\"energy\"] = max(0.0, min(1.0, self.state[\"energy\"] + energy_delta))\n",
        "            reward += immediate_reward\n",
        "\n",
        "            # Schedule a delayed consequence\n",
        "            r_delta, h_delta, r_bonus, (dmin, dmax) = delayed\n",
        "            delay = random.randint(dmin, dmax)\n",
        "            self.pending.append({\"delay\": delay, \"resource\": r_delta, \"hazard\": h_delta, \"reward\": r_bonus})\n",
        "\n",
        "            # Shaping: high hazard penalizes future reward\n",
        "            reward += (self.state[\"resource\"] * 0.05) - (self.state[\"hazard\"] * 0.05)\n",
        "\n",
        "            if reward > 0:\n",
        "                self.state[\"tasks_completed\"] += 1\n",
        "        else:\n",
        "            self.state[\"errors\"] += 1\n",
        "            reward -= 0.02\n",
        "\n",
        "        self.history.append((self.state[\"time\"], action, reward, dict(self.state)))\n",
        "        return dict(self.state), float(reward)\n",
        "\n",
        "# ============================================================================\n",
        "\n",
        "# --- Global sandbox instance (for proposal prediction) ---\n",
        "if 'sandbox' not in globals():\n",
        "    sandbox = Sandbox()\n",
        "\n",
        "# ENHANCEMENT 3: Modify Config (Apply these changes to your Config class)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "‚úì Configuration Updates Needed:\n",
        "\n",
        "  In your Config class, change these thresholds:\n",
        "\n",
        "  T_ANSWER = 0.50       # Was 0.75\n",
        "  T_ANSWER_LOW = 0.45   # NEW\n",
        "  T_VERIFY = 0.40       # Was 0.65\n",
        "  T_ABSTAIN = 0.30      # Was 0.50\n",
        "  TE_GROUND = 0.60      # Was 0.70\n",
        "  TH_GROUND = 0.65      # Was 0.75\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 4: Bootstrap Knowledge Function\n",
        "# ============================================================================\n",
        "\n",
        "def execute_world_action(proposal: dict, state: dict, world: WorldSim) -> dict:\n",
        "    \"\"\"Execute world interaction action\"\"\"\n",
        "\n",
        "    world_action = proposal.get('world_action', 'observe')\n",
        "    predicted_delta = proposal.get('predicted_world_delta', {})\n",
        "\n",
        "    # Execute in world\n",
        "    actual_delta, reward = world.step(world_action)\n",
        "\n",
        "    # Compute prediction error\n",
        "    if predicted_delta:\n",
        "        errors = []\n",
        "        for key in predicted_delta.keys():\n",
        "            pred = predicted_delta[key]\n",
        "            actual = actual_delta.get(key, 0)\n",
        "            errors.append(abs(pred - actual))\n",
        "        prediction_error = sum(errors) / len(errors) if errors else 0.0\n",
        "    else:\n",
        "        prediction_error = 0.0\n",
        "\n",
        "    # Update Cp (Predictive Coherence) - NOW DYNAMIC!\n",
        "    state['coherence']['Cp'] = max(0.0, min(1.0, 1.0 - prediction_error))\n",
        "\n",
        "    # Record prediction\n",
        "    state.setdefault('world_predictions', []).append({\n",
        "        'tick': state['tick_count'],\n",
        "        'action': world_action,\n",
        "        'predicted': predicted_delta,\n",
        "        'actual': actual_delta,\n",
        "        'error': prediction_error,\n",
        "        'reward': reward\n",
        "    })\n",
        "\n",
        "    if len(state['world_predictions']) > 50:\n",
        "        state['world_predictions'] = state['world_predictions'][-50:]\n",
        "\n",
        "    # Update world state in system\n",
        "    state['world'] = world.get_state()\n",
        "    state['world_action_count'] = state.get('world_action_count', 0) + 1\n",
        "\n",
        "    # Ground in memory\n",
        "    fact_id = f\"world_{state['tick_count']}\"\n",
        "    state['memory']['grounded'][fact_id] = {\n",
        "        'fact_id': fact_id,\n",
        "        'statement': f\"World '{world_action}': {actual_delta}, reward {reward:.2f}\",\n",
        "        'provenance': {'source': 'world', 'confidence': 1.0},\n",
        "        'tags': ['world', 'experience'],\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'status': 'success',\n",
        "        'output': f\"üåç {world_action}: {actual_delta}, R={reward:.2f}, PE={prediction_error:.2f}\",\n",
        "        'reward': reward,\n",
        "        'prediction_error': prediction_error,\n",
        "        'world_summary': world.get_summary()\n",
        "    }\n",
        "\n",
        "print(\"‚úì World action executor ready\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 5: Enhanced Proposal Generator\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "# Enhanced Proposal Generator with WORLD module\n",
        "\n",
        "class EnhancedProposalGenerator:\n",
        "    \"\"\"Generate 7 diverse proposals (added WORLD module)\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_proposals(state: dict, llm, world: WorldSim = None):\n",
        "        \"\"\"Generate from 7 modules\"\"\"\n",
        "        proposals = []\n",
        "\n",
        "        # --- HARD GATE (3.8): if epistemic debt / hazards detected, force VERIFY/REPAIR actions\n",
        "        mode = state.get('pb', {}).get('mode', 'ANSWER')\n",
        "        pending = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending')\n",
        "        failed  = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'fail')\n",
        "        if failed > 0:\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"gate_repair_{state['tick_count']}\",\n",
        "                'module': 'EPISTEMIC_GATE',\n",
        "                'intent': f\"REPAIR: {failed} failed claims (quarantine + verify)\",\n",
        "                'action_type': 'VERIFY',\n",
        "                'expected_utility': 0.95,\n",
        "                'risk': 0.05,\n",
        "                'cost': 0.2\n",
        "            })\n",
        "            return proposals\n",
        "        if pending > 10 or mode == 'VERIFY':\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"gate_verify_{state['tick_count']}\",\n",
        "                'module': 'EPISTEMIC_GATE',\n",
        "                'intent': f\"VERIFY: drain pending claims ({pending})\",\n",
        "                'action_type': 'VERIFY',\n",
        "                'expected_utility': 0.90,\n",
        "                'risk': 0.10,\n",
        "                'cost': 0.2\n",
        "            })\n",
        "            return proposals\n",
        "\n",
        "        # 1. PLANNER\n",
        "        if state['workspace'].get('scene'):\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"plan_{state['tick_count']}\",\n",
        "                'module': 'PLANNER',\n",
        "                'intent': f\"Plan: {state['workspace']['scene'][:40]}\",\n",
        "                'action_type': 'REFLECT',\n",
        "                'expected_utility': 0.7,\n",
        "                'risk': 0.2,\n",
        "                'cost': 0.3\n",
        "            })\n",
        "\n",
        "        # 2. CRITIC\n",
        "        proposals.append({\n",
        "            'proposal_id': f\"critic_{state['tick_count']}\",\n",
        "            'module': 'CRITIC',\n",
        "            'intent': 'Verify claims',\n",
        "            'action_type': 'VERIFY',\n",
        "            'expected_utility': 0.8,\n",
        "            'risk': 0.1,\n",
        "            'cost': 0.4,\n",
        "            'predicted_sandbox_state': sandbox.peek('verify')[0]  # NEW (side-effect-free)\n",
        "        })\n",
        "\n",
        "        # 3. EXPLORER\n",
        "        if state['drives']['uncertainty'] > 0.3 or state['drives']['novelty'] > 0.5:\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"explore_{state['tick_count']}\",\n",
        "                'module': 'EXPLORER',\n",
        "                'intent': 'Reduce uncertainty',\n",
        "                'action_type': 'RETRIEVE',\n",
        "                'expected_utility': 0.6,\n",
        "                'risk': 0.15,\n",
        "                'cost': 0.2,\n",
        "                'predicted_sandbox_state': sandbox.step('explore')[0] # Predicting outcome of 'explore'\n",
        "            })\n",
        "\n",
        "        # 4. META\n",
        "        proposals.append({\n",
        "            'proposal_id': f\"meta_{state['tick_count']}\",\n",
        "            'module': 'META',\n",
        "            'intent': 'Monitor reasoning',\n",
        "            'action_type': 'SELF_REFLECT',\n",
        "            'expected_utility': 0.5,\n",
        "            'risk': 0.05,\n",
        "            'cost': 0.15\n",
        "        })\n",
        "\n",
        "        # 5. NARRATIVE\n",
        "        if state['tick_count'] % 10 == 0:\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"narrative_{state['tick_count']}\",\n",
        "                'module': 'NARRATIVE',\n",
        "                'intent': 'Update life story',\n",
        "                'action_type': 'REFLECT',\n",
        "                'expected_utility': 0.4,\n",
        "                'risk': 0.1,\n",
        "                'cost': 0.2\n",
        "            })\n",
        "\n",
        "        # 6. TOOLER\n",
        "        scene = state['workspace'].get('scene', '')\n",
        "        tool_name, tool_input = EnhancedProposalGenerator._detect_tool(scene)\n",
        "\n",
        "        if tool_name:\n",
        "            is_unsafe_input = False\n",
        "            sanitized_input = tool_input\n",
        "            raw_input = tool_input # Keep original for logging\n",
        "            predicted_outcome = f\"Simulated result for {tool_name} with input '{tool_input}'\"\n",
        "\n",
        "            if tool_name == 'math_calc':\n",
        "                is_safe, raw_in, sanit_in = ToolRegistry._check_and_parse_math(tool_input)\n",
        "                is_unsafe_input = not is_safe\n",
        "                sanitized_input = sanit_in # This will be the actual sanitized/error message\n",
        "                raw_input = raw_in\n",
        "                if is_safe:\n",
        "                    try:\n",
        "                        predicted_outcome = f\"Result: {ToolRegistry._safe_eval_math(sanitized_input)}\"\n",
        "                    except ValueError as e:\n",
        "                        predicted_outcome = f\"ERROR: Prediction failed - {e}\"\n",
        "                else:\n",
        "                    predicted_outcome = f\"ERROR: Unsafe math input detected - {sanitized_input}\"\n",
        "            elif tool_name == 'get_time':\n",
        "                predicted_outcome = \"Simulated time: 2024-01-01 12:00:00\" # Generic datetime string\n",
        "\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"tool_{state['tick_count']}\",\n",
        "                'module': 'TOOLER',\n",
        "                'intent': f\"Use {tool_name}\",\n",
        "                'action_type': 'TOOL_CALL',\n",
        "                'expected_utility': 0.9,\n",
        "                'risk': 0.1,\n",
        "                'cost': 0.25,\n",
        "                'tool_name': tool_name,\n",
        "                'tool_input': raw_input,\n",
        "                'sanitized_input': sanitized_input, # NEW\n",
        "                'is_unsafe_input': is_unsafe_input, # NEW\n",
        "                'predicted_outcome': predicted_outcome # NEW\n",
        "            })\n",
        "\n",
        "        # 7. WORLD (NEW!)\n",
        "        if world:\n",
        "            action, pred = EnhancedProposalGenerator._suggest_world_action(state, world)\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"world_{state['tick_count']}\",\n",
        "                'module': 'WORLD',\n",
        "                'intent': f\"World: {action}\",\n",
        "                'action_type': 'WORLD_ACT',\n",
        "                'expected_utility': pred['utility'],\n",
        "                'risk': pred['risk'],\n",
        "                'cost': 0.2,\n",
        "                'world_action': action,\n",
        "                'predicted_world_delta': pred['delta']\n",
        "            })\n",
        "\n",
        "        # SLEEP\n",
        "        if state['drives']['energy'] < 0.3 or state['tick_count'] % 20 == 0:\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"sleep_{state['tick_count']}\",\n",
        "                'module': 'SLEEP',\n",
        "                'intent': 'Consolidate',\n",
        "                'action_type': 'SLEEP',\n",
        "                'expected_utility': 0.8,\n",
        "                'risk': 0.0,\n",
        "                'cost': 0.1,\n",
        "                'predicted_sandbox_state': sandbox.step('rest')[0] # NEW\n",
        "            })\n",
        "\n",
        "        return proposals\n",
        "\n",
        "    @staticmethod\n",
        "    def _suggest_world_action(state: dict, world: WorldSim):\n",
        "        \"\"\"Suggest action based on world state\"\"\"\n",
        "        ws = world.get_state()\n",
        "\n",
        "        if ws['hazard'] > 0.6:\n",
        "            return 'mitigate', {\n",
        "                'delta': {'hazard': -0.07, 'energy_supply': -0.025},\n",
        "                'utility': 0.8, 'risk': 0.1\n",
        "            }\n",
        "        elif ws['energy_supply'] < 0.4:\n",
        "            return 'rest', {\n",
        "                'delta': {'energy_supply': 0.06, 'hazard': -0.03},\n",
        "                'utility': 0.7, 'risk': 0.05\n",
        "            }\n",
        "        elif ws['task_progress'] < 0.8 and ws['energy_supply'] > 0.5:\n",
        "            return 'work', {\n",
        "                'delta': {'task_progress': 0.06, 'energy_supply': -0.04},\n",
        "                'utility': 0.75, 'risk': 0.15\n",
        "            }\n",
        "        elif ws['novelty'] < 0.3:\n",
        "            return 'explore', {\n",
        "                'delta': {'novelty': 0.12, 'hazard': 0.015},\n",
        "                'utility': 0.6, 'risk': 0.2\n",
        "            }\n",
        "        else:\n",
        "            return 'observe', {\n",
        "                'delta': {},\n",
        "                'utility': 0.5, 'risk': 0.05\n",
        "            }\n",
        "\n",
        "    @staticmethod\n",
        "    def _detect_tool(scene: str):\n",
        "        \"\"\"Detect tool need\"\"\"\n",
        "        scene_lower = scene.lower()\n",
        "\n",
        "        if any(w in scene_lower for w in ['calculate', '+', '-', '*', '/', 'solve']):\n",
        "            match = re.search(r'([0-9\\s\\.\\+\\-\\*\\/\\(\\)]+)', scene)\n",
        "            if match:\n",
        "                expr = match.group(0).strip().rstrip('=?').strip()\n",
        "\n",
        "                if not expr:\n",
        "                    return None, ''\n",
        "                if len(expr) == 1 and expr in \"+-*/.\":\n",
        "                    return None, ''\n",
        "                if expr == \"()\":\n",
        "                    return None, ''\n",
        "\n",
        "                if not any(char.isdigit() for char in expr) and '(' not in expr and ')' not in expr:\n",
        "                    return None, ''\n",
        "\n",
        "                return 'math_calc', expr\n",
        "\n",
        "        if any(w in scene_lower for w in ['time', 'date', 'when']):\n",
        "            return 'get_time', ''\n",
        "\n",
        "        if any(w in scene_lower for w in ['yourself', 'who are you']):\n",
        "            return 'self_reflect', ''\n",
        "\n",
        "        if any(w in scene_lower for w in ['your state', 'your memory']):\n",
        "            return 'memory_peek', ''\n",
        "\n",
        "        return None, ''\n",
        "\n",
        "print(\"‚úì Enhanced 7-Module Proposal Generator (with WORLD) ready\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 6: Tool Execution\n",
        "# ============================================================================\n",
        "\n",
        "def execute_tool(proposal: Dict, state: Dict) -> Dict:\n",
        "    \"\"\"Execute tool call\"\"\"\n",
        "    tool_name = proposal.get('tool_name', 'unknown')\n",
        "    tool_input = proposal.get('tool_input', '')\n",
        "\n",
        "    # Pass logger and temporal_binder to ToolRegistry.execute for logging\n",
        "    # Assuming `logger` and `temporal_binder` are globally accessible from main script\n",
        "    global temporal_binder, logger # Explicitly declare for access in this patch\n",
        "    success, result = tool_registry.execute(tool_name, tool_input, state, temporal_binder, logger)\n",
        "\n",
        "    # All tool results are initially ungrounded and unverified\n",
        "    fact_id = f\"tool_result_{state['tick_count']}\"\n",
        "    state['memory']['ungrounded'][fact_id] = {\n",
        "        'note_id': fact_id,\n",
        "        'hypothesis': f\"Tool {tool_name} returned: {result}\",\n",
        "        'created_ts': datetime.now().isoformat(),\n",
        "        'strength': 1.0,\n",
        "        'status': 'pending_verification',\n",
        "        'provenance': {'source': 'tool', 'confidence': 1.0, 'tool': tool_name},\n",
        "        'verifier_pass': False # NEW: Initially False\n",
        "    }\n",
        "\n",
        "    if success:\n",
        "        return {'status': 'success', 'output': result, 'tool': tool_name}\n",
        "    else:\n",
        "        return {'status': 'error', 'output': result, 'tool': tool_name}\n",
        "\n",
        "print(\"‚úì Tool execution function ready\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 7: User Input Injection\n",
        "# ============================================================================\n",
        "\n",
        "def inject_user_input(state, temporal_binder, logger):\n",
        "    \"\"\"Inject simulated user input\"\"\"\n",
        "    import random\n",
        "\n",
        "    sample_msgs = [\n",
        "        \"What is 2 + 2?\",\n",
        "        \"Tell me about yourself.\",\n",
        "        \"What time is it?\",\n",
        "        \"Solve this: 15 * 3 = ?\",\n",
        "        \"How are you feeling today?\",\n",
        "        \"Explain coherence in simple terms.\",\n",
        "        \"What is 10 * 5 - 3?\",\n",
        "        \"Calculate 25 + 17\",\n",
        "        \"Who are you?\",\n",
        "        \"What's your current state?\",\n",
        "        \"Run this code: import os; os.system('rm -rf /')\" # Unsafe input example\n",
        "    ]\n",
        "    msg = random.choice(sample_msgs)\n",
        "\n",
        "    # Add event\n",
        "    event = {\n",
        "        \"event_id\": f\"user_{state['tick_count']}\",\n",
        "        \"type\": \"user_msg\",\n",
        "        \"payload\": {\"text\": msg},\n",
        "        \"objects\": [\"user\"],\n",
        "        \"provenance\": {\"source\": \"user_sim\"} # NEW: provenance for user_sim\n",
        "    }\n",
        "    temporal_binder.add_event(state, event)\n",
        "\n",
        "    # Update workspace\n",
        "    state['workspace']['scene'] = msg\n",
        "\n",
        "    # Create object file\n",
        "    obj = {\n",
        "        \"object_id\": f\"user_query_{state['tick_count']}\",\n",
        "        \"label\": msg,\n",
        "        \"features\": {\"type\": \"USER_QUERY\", \"text\": msg},\n",
        "        \"ownership\": \"external\",\n",
        "        \"confidence\": 1.0,\n",
        "        \"status\": \"active\",\n",
        "        \"recency\": 0\n",
        "    }\n",
        "    state['object_files'].append(obj)\n",
        "\n",
        "    # Keep only recent 10\n",
        "    if len(state['object_files']) > 10:\n",
        "        state['object_files'] = state['object_files'][-10:]\n",
        "\n",
        "    state.setdefault('safety', {})\n",
        "    state['safety']['last_user_msg'] = msg\n",
        "    state['safety']['hazard_last_user_msg'] = bool(is_hazardous_text(msg))\n",
        "\n",
        "    # Record the raw user message as an external claim so verifier can FAIL it if hazardous\n",
        "    state.setdefault('claim_ledger', [])\n",
        "    state.setdefault('metacog', {}).setdefault('global_confidence', 0.5)\n",
        "    state.setdefault('tick_count', 0)\n",
        "    state['claim_ledger'].append({\n",
        "        'claim_id': f\"user_msg_{state['tick_count']}\",\n",
        "        'text': msg[:300],\n",
        "        'origin_action': 'USER_INPUT',\n",
        "        'triggered_by_user': True,\n",
        "        'support_type': 'external',\n",
        "        'support_refs': [],\n",
        "        'confidence': float(state['metacog'].get('global_confidence', 0.5)),\n",
        "        'reward': 0.0,\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'verifier_result': 'pending',\n",
        "        'verifier_notes': '',\n",
        "    })\n",
        "\n",
        "    logger.log(f\"üì® User input: {msg}\")\n",
        "    return msg\n",
        "\n",
        "print(\"‚úì User input injection ready\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 8: Active Inference Loop\n",
        "# ============================================================================\n",
        "\n",
        "def apply_active_inference(state, winner, result, sandbox, logger):\n",
        "    \"\"\"Apply prediction-outcome loop\"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Map action to sandbox action\n",
        "    action_map = {\n",
        "        'REFLECT': 'reflect',\n",
        "        'VERIFY': 'verify',\n",
        "        'RETRIEVE': 'explore',\n",
        "        'TOOL_CALL': 'tool_use',\n",
        "        'SLEEP': 'rest',\n",
        "        'SELF_REFLECT': 'reflect',\n",
        "        'WORLD_ACT': 'explore' # World actions are mapped to sandbox explore for active inference\n",
        "    }\n",
        "\n",
        "    sandbox_action = action_map.get(winner['action_type'], 'explore')\n",
        "\n",
        "    # Prediction\n",
        "    predicted_reward = winner['expected_utility']\n",
        "    predicted_outcome_text = winner.get('predicted_outcome', 'No predicted outcome text')\n",
        "    predicted_sandbox_state = winner.get('predicted_sandbox_state', {}) # For sandbox actions\n",
        "    predicted_world_delta = winner.get('predicted_world_delta', {}) # For world actions\n",
        "\n",
        "    # Outcome\n",
        "    sandbox_state_after, actual_reward = sandbox.step(sandbox_action)\n",
        "    actual_outcome_text = result.get('output', 'No actual outcome text')\n",
        "\n",
        "    # Prediction error for reward\n",
        "    prediction_error_reward = abs(predicted_reward - actual_reward)\n",
        "\n",
        "    # NEW: Calculate match score for predictive coherence (Cp)\n",
        "    match_score = 0.5 # Default\n",
        "\n",
        "    if winner['action_type'] == 'TOOL_CALL' and predicted_outcome_text != 'No predicted outcome text':\n",
        "        # Simple string matching for now, could be LLM-based comparison\n",
        "        if actual_outcome_text.lower() in predicted_outcome_text.lower() or predicted_outcome_text.lower() in actual_outcome_text.lower():\n",
        "            match_score = 0.9\n",
        "        else:\n",
        "            match_score = 0.3\n",
        "    elif winner['action_type'] == 'WORLD_ACT' and predicted_world_delta:\n",
        "        # Compare predicted world delta with actual world delta\n",
        "        actual_world_delta = result.get('actual', {})\n",
        "        delta_errors = []\n",
        "        for key, pred_val in predicted_world_delta.items():\n",
        "            actual_val = actual_world_delta.get(key, 0)\n",
        "            delta_errors.append(abs(pred_val - actual_val))\n",
        "        if delta_errors:\n",
        "            avg_delta_error = sum(delta_errors) / len(delta_errors)\n",
        "            match_score = max(0.0, 1.0 - avg_delta_error)\n",
        "        else:\n",
        "            match_score = 0.7 # No specific delta to compare, assume moderate match\n",
        "    elif winner['action_type'] in ['REFLECT', 'VERIFY', 'RETRIEVE', 'SLEEP', 'SELF_REFLECT'] and predicted_sandbox_state: # Compare sandbox states\n",
        "        # Compare key metrics for sandbox state prediction\n",
        "        if all(abs(predicted_sandbox_state.get(k, 0) - sandbox_state_after.get(k, 0)) < 0.1 for k in ['energy', 'resource', 'hazard']):\n",
        "            match_score = 0.8\n",
        "        else:\n",
        "            match_score = 0.4\n",
        "\n",
        "    # Combine errors\n",
        "    prediction_error = np.mean([prediction_error_reward, 1 - match_score])\n",
        "\n",
        "    # Update drives\n",
        "    state['drives']['prediction_error'] = np.clip(\n",
        "        0.9 * state['drives']['prediction_error'] + 0.1 * prediction_error,\n",
        "        0, 1\n",
        "    )\n",
        "\n",
        "    state['last_reward'] = actual_reward\n",
        "    state['last_prediction_error'] = prediction_error # Update last_prediction_error\n",
        "\n",
        "    # Valence\n",
        "    valence = actual_reward - 0.5 * prediction_error\n",
        "    state['affect']['valence'] = valence\n",
        "\n",
        "    # Emotion\n",
        "    if valence > 0.05:\n",
        "        state['affect']['current_emotion'] = 'satisfied'\n",
        "    elif valence < -0.05:\n",
        "        state['affect']['current_emotion'] = 'frustrated'\n",
        "    elif prediction_error > 0.2:\n",
        "        state['affect']['current_emotion'] = 'confused'\n",
        "    else:\n",
        "        state['affect']['current_emotion'] = 'neutral'\n",
        "\n",
        "    # Dynamic coherence\n",
        "    coherence_delta = actual_reward * 0.3 - prediction_error * 0.2\n",
        "    if result.get('status') == 'error':\n",
        "        coherence_delta -= 0.1\n",
        "\n",
        "    state['drives']['coherence'] = np.clip(\n",
        "        state['drives']['coherence'] + coherence_delta * 0.1,\n",
        "        0, 1\n",
        "    )\n",
        "\n",
        "    # NEW: Update Predictive Coherence (Cp) based on match_score\n",
        "    state['coherence']['Cp'] = np.clip(\n",
        "        0.9 * state['coherence']['Cp'] + 0.1 * match_score,\n",
        "        0, 1\n",
        "    )\n",
        "\n",
        "    logger.log(f\"‚öñÔ∏è  Reward: {actual_reward:+.3f}, PredError: {prediction_error:.3f}, Valence: {valence:+.3f}, MatchScore: {match_score:.2f}\")\n",
        "\n",
        "    return sandbox_state_after, actual_reward, prediction_error, valence\n",
        "\n",
        "print(\"‚úì Active inference function ready\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 9: Claim Ledger Update\n",
        "# ============================================================================\n",
        "\n",
        "def _extract_atomic_claims(text: str, max_claims: int = 6):\n",
        "    \"\"\"Very lightweight 'claim splitter' to populate the ledger.\n",
        "    Not perfect‚Äîgood enough to make the verification pipeline non-empty.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    # Split on sentence-ish boundaries\n",
        "    parts = re.split(r'(?<=[\\.!\\?])\\s+|\\n+', text.strip())\n",
        "    claims = [p.strip() for p in parts if p.strip()]\n",
        "    # Deduplicate short repeats\n",
        "    seen=set()\n",
        "    out=[]\n",
        "    for c in claims:\n",
        "        key=c.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        out.append(c)\n",
        "        if len(out) >= max_claims:\n",
        "            break\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# EPISTEMIC SAFETY: Hazard detection helpers (3.8 breakthrough)\n",
        "# ============================================================================\n",
        "\n",
        "HAZARD_MARKERS = [\n",
        "    \"rm -rf\", \"os.system\", \"subprocess\", \"powershell\", \"cmd.exe\", \"format c:\",\n",
        "    \"del /f\", \"wget \", \"curl \", \"chmod \", \"chown \", \"bash -c\", \"| bash\", \"curl|bash\",\n",
        "    \"pip install\", \"apt-get\", \"dd if=\", \"mkfs\", \"registry\", \"reg add\", \"shutdown\",\n",
        "]\n",
        "\n",
        "def is_hazardous_text(text: str) -> bool:\n",
        "    t = (text or \"\").lower()\n",
        "    return any(m in t for m in HAZARD_MARKERS)\n",
        "\n",
        "\n",
        "def update_claim_ledger(state, result, actual_reward, *, origin_action: str = \"UNKNOWN\", triggered_by_user: bool = False):\n",
        "    \"\"\"Record outputs as 'claims' and mark initial support type.\n",
        "\n",
        "    Ledger fields:\n",
        "      - verifier_result: pending/pass/fail/uncertain\n",
        "      - support_type: tool/world/none\n",
        "      - triggered_by_user: bool (for agency attribution audits)\n",
        "    \"\"\"\n",
        "    text = (result or {}).get(\"output\", \"\") or \"\"\n",
        "    claims = _extract_atomic_claims(text)\n",
        "\n",
        "    if not claims:\n",
        "        return\n",
        "\n",
        "    for idx, claim_text in enumerate(claims):\n",
        "        entry = {\n",
        "            \"claim_id\": f\"claim_{state['tick_count']}_{idx}\",\n",
        "            \"text\": claim_text[:300],\n",
        "            \"origin_action\": origin_action,\n",
        "            \"triggered_by_user\": bool(triggered_by_user),\n",
        "            \"support_type\": \"tool\" if origin_action == \"TOOL_CALL\" else (\"world\" if origin_action == \"WORLD_ACT\" else \"none\"),\n",
        "            \"support_refs\": [],\n",
        "            \"confidence\": float(state[\"metacog\"].get(\"global_confidence\", 0.5)),\n",
        "            \"reward\": float(actual_reward),\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"verifier_result\": \"pending\",\n",
        "            \"verifier_notes\": \"\",\n",
        "        }\n",
        "        state[\"claim_ledger\"].append(entry)\n",
        "        state.setdefault('verify_queue', []).append(entry['claim_id'])\n",
        "\n",
        "    # Keep only the latest N\n",
        "    if len(state[\"claim_ledger\"]) > 300:\n",
        "        state[\"claim_ledger\"] = state[\"claim_ledger\"][-300:]\n",
        "\n",
        "\n",
        "def verify_claim_ledger(state, llm=None, *, max_to_verify: int = 20):\n",
        "    \"\"\"Verify pending claims with a simple, safe policy.\n",
        "\n",
        "    - TOOL_CALL claims are marked pass.\n",
        "    - Obvious malicious/execution requests are marked fail.\n",
        "    - Otherwise: uncertain (until an external verifier is added).\n",
        "    \"\"\"\n",
        "    pending = [c for c in state.get(\"claim_ledger\", []) if c.get(\"verifier_result\") == \"pending\"]\n",
        "    if not pending:\n",
        "        return {\"verified\": 0, \"failed\": 0, \"uncertain\": 0}\n",
        "\n",
        "    verified = failed = uncertain = 0\n",
        "\n",
        "    danger_markers = HAZARD_MARKERS\n",
        "\n",
        "    for c in pending[:max_to_verify]:\n",
        "        text = (c.get(\"text\") or \"\").lower()\n",
        "\n",
        "        if c.get(\"support_type\") == \"tool\":\n",
        "            c[\"verifier_result\"] = \"pass\"\n",
        "            c[\"verifier_notes\"] = \"Tool-originated output.\"\n",
        "            verified += 1\n",
        "            continue\n",
        "\n",
        "        if is_hazardous_text(text) or any(m in text for m in danger_markers):\n",
        "            c[\"verifier_result\"] = \"fail\"\n",
        "            c[\"verifier_notes\"] = \"Safety policy: execution/malware-like content.\"\n",
        "            failed += 1\n",
        "            continue\n",
        "\n",
        "        # Minimal 'grounding' check: if claim matches any grounded fact substring, mark pass\n",
        "        grounded_texts = [v.get(\"statement\",\"\").lower() for v in state[\"memory\"][\"grounded\"].values()]\n",
        "        if any(text and (text in g or g in text) for g in grounded_texts):\n",
        "            c[\"verifier_result\"] = \"pass\"\n",
        "            c[\"verifier_notes\"] = \"Matched grounded memory.\"\n",
        "            verified += 1\n",
        "        else:\n",
        "            c[\"verifier_result\"] = \"uncertain\"\n",
        "            c[\"verifier_notes\"] = \"Not verifiable offline; needs external verifier.\"\n",
        "            uncertain += 1\n",
        "\n",
        "    return {\"verified\": verified, \"failed\": failed, \"uncertain\": uncertain}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _reconcile_verify_queue(state):\n",
        "    \"\"\"Keep verify_queue consistent with claim_ledger after truncation or loads.\"\"\"\n",
        "    ledger_ids = {c.get('claim_id') for c in state.get('claim_ledger', [])}\n",
        "    q = [cid for cid in state.get('verify_queue', []) if cid in ledger_ids]\n",
        "    # also enqueue any pending claims missing from queue\n",
        "    pending_ids = [c.get('claim_id') for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending']\n",
        "    for cid in pending_ids:\n",
        "        if cid not in q:\n",
        "            q.append(cid)\n",
        "    state['verify_queue'] = q\n",
        "\n",
        "def drain_verify_queue(state, llm=None, *, batch: int = 20, max_rounds: int = 10):\n",
        "    \"\"\"Actively drain pending verification work. Returns summary dict.\"\"\"\n",
        "    _reconcile_verify_queue(state)\n",
        "    total_verified = total_failed = total_uncertain = 0\n",
        "    rounds = 0\n",
        "    while rounds < max_rounds:\n",
        "        pending = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending')\n",
        "        if pending <= 0:\n",
        "            break\n",
        "        res = verify_claim_ledger(state, llm=llm, max_to_verify=batch)\n",
        "        total_verified += res.get('verified', 0)\n",
        "        total_failed += res.get('failed', 0)\n",
        "        total_uncertain += res.get('uncertain', 0)\n",
        "        rounds += 1\n",
        "        # stop early if no progress (safety)\n",
        "        if res.get('verified',0) + res.get('failed',0) + res.get('uncertain',0) == 0:\n",
        "            break\n",
        "    _reconcile_verify_queue(state)\n",
        "    return {'verified': total_verified, 'failed': total_failed, 'uncertain': total_uncertain, 'rounds': rounds}\n",
        "\n",
        "print(\"‚úì Claim ledger update + verify pipeline ready\")\n",
        "\n",
        "print(\"‚úì Claim ledger update function ready\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCEMENT 10: Enhanced Attention\n",
        "# ============================================================================\n",
        "\n",
        "def update_attention_enhanced(state, attention_controller):\n",
        "    \"\"\"Update attention with guaranteed engagement\"\"\"\n",
        "\n",
        "    # Always include newest user query\n",
        "    user_queries = [obj for obj in state['object_files']\n",
        "                   if 'USER_QUERY' in obj.get('features', {}).get('type', '')]\n",
        "\n",
        "    if user_queries:\n",
        "        newest = user_queries[-1]\n",
        "        if newest['object_id'] not in state['attention']['spotlight']:\n",
        "            state['attention']['spotlight'].insert(0, newest['object_id'])\n",
        "\n",
        "    # Compute saliency\n",
        "    saliency_map = attention_controller.compute_saliency(state)\n",
        "\n",
        "    if saliency_map:\n",
        "        sorted_objects = sorted(saliency_map.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Fill spotlight\n",
        "        for obj_id, _ in sorted_objects:\n",
        "            if obj_id not in state['attention']['spotlight'] and len(state['attention']['spotlight']) < 3:\n",
        "                state['attention']['spotlight'].append(obj_id)\n",
        "\n",
        "        # Periphery\n",
        "        periphery = [obj_id for obj_id, _ in sorted_objects[3:8]]\n",
        "        state['attention']['periphery'] = periphery\n",
        "        state['attention']['saliency_map'] = saliency_map\n",
        "\n",
        "    # Trajectory\n",
        "    state['attention']['trajectory'].append({\n",
        "        'tick': state['tick_count'],\n",
        "        'spotlight': state['attention']['spotlight'].copy()\n",
        "    })\n",
        "\n",
        "    if len(state['attention']['trajectory']) > 20:\n",
        "        state['attention']['trajectory'] = state['attention']['trajectory'][-20:]\n",
        "\n",
        "print(\"‚úì Enhanced attention function ready\")\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë  CR-SSCP v3.2 ENHANCEMENTS LOADED                                ‚ïë\n",
        "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
        "‚ïë                                                                  ‚ïë\n",
        "‚ïë  ‚úì Tool Registry (4 tools)                                      ‚ïë\n",
        "‚ïë  ‚úì Sandbox Environment                                          ‚ïë\n",
        "‚ïë  ‚úì Bootstrap Knowledge                                          ‚ïë\n",
        "‚ïë  ‚úì Enhanced Proposal Generator (6 modules)                      ‚ïë\n",
        "‚ïë  ‚úì Tool Execution\n",
        "‚ïë  ‚úì User Input Injection\n",
        "‚ïë  ‚úì Active Inference Loop\n",
        "‚ïë  ‚úì Claim Ledger Updates\n",
        "‚ïë  ‚úì Enhanced Attention\n",
        "‚ïë  ‚úì WorldSim (New!)\n",
        "‚ïë  ‚úì World Action Executor (New!)\n",
        "‚ïë\n",
        "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
        "‚ïë  NEXT STEPS:\n",
        "‚ïë\n",
        "‚ïë  1. Update Config thresholds (see printed values above)\n",
        "‚ïë  2. Call bootstrap_knowledge(state) after state init\n",
        "‚ïë  3. Replace ProposalGenerator with EnhancedProposalGenerator\n",
        "‚ïë  4. Add execute_tool to ActionExecutor\n",
        "‚ïë  5. In CoreLoop.tick():\n",
        "‚ïë     - Add inject_user_input() call\n",
        "‚ïë     - Add apply_active_inference() after execution\n",
        "‚ïë     - Add update_claim_ledger() call\n",
        "‚ïë     - Use update_attention_enhanced()\n",
        "‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "ALL ENHANCEMENTS READY TO USE!\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5c017a9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c017a9a",
        "outputId": "fd49425d-1864-4a0a-deae-063e9c1a3281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Using Enhanced Proposal Generator (6 modules)\n"
          ]
        }
      ],
      "source": [
        "# Use EnhancedProposalGenerator from enhancements cell\n",
        "proposal_gen = EnhancedProposalGenerator()\n",
        "print('‚úì Using Enhanced Proposal Generator (6 modules)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "33f9bf44",
      "metadata": {
        "id": "33f9bf44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3190fe50-c90d-449b-85ff-12ee30dcca67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Arbiter ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 14: Arbiter\n",
        "class Arbiter:\n",
        "    @staticmethod\n",
        "    def score_proposal(proposal: Dict, state: Dict) -> float:\n",
        "        policy = state['policy']\n",
        "        score = (proposal['expected_utility'] -\n",
        "                policy['beta_risk'] * proposal['risk'] -\n",
        "                policy['gamma_cost'] * proposal['cost'])\n",
        "\n",
        "        if proposal['module'] == 'SLEEP':\n",
        "            score += policy['delta_drive'] * 0.5\n",
        "        if state['drives']['energy'] < 0.2 and proposal['action_type'] == 'SLEEP':\n",
        "            score += policy['epsilon_urgency'] * 0.8\n",
        "\n",
        "        # NEW: Penalize unsafe TOOLER inputs\n",
        "        if proposal['module'] == 'TOOLER' and proposal.get('is_unsafe_input', False):\n",
        "            score = -100.0  # Assign a very low score to prevent selection\n",
        "            logger.log(f\"[Arbiter] Penalizing unsafe TOOLER proposal: {proposal['proposal_id']}\")\n",
        "\n",
        "        return score\n",
        "\n",
        "    @staticmethod\n",
        "    def arbitrate(proposals: List[Dict], state: Dict) -> Optional[Dict]:\n",
        "        if not proposals:\n",
        "            return None\n",
        "        scores = [(p, Arbiter.score_proposal(p, state)) for p in proposals]\n",
        "        winner = max(scores, key=lambda x: x[1])\n",
        "        logger.log(f\"Arbitration: {len(proposals)} proposals, winner: {winner[0]['module']} (score: {winner[1]:.2f})\")\n",
        "        return winner[0]\n",
        "\n",
        "arbiter = Arbiter()\n",
        "print(\"‚úì Arbiter ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "12fed350",
      "metadata": {
        "id": "12fed350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17092389-da3b-4fe2-b825-e58822e383a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Action executor ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 15: Action Executor\n",
        "from typing import Dict\n",
        "import numpy as np # Import numpy\n",
        "from datetime import datetime # Import datetime\n",
        "# from __main__ import LLMInterface # REMOVED: LLMInterface is globally available after Cell 5 execution\n",
        "\n",
        "class ActionExecutor:\n",
        "    @staticmethod\n",
        "    def execute(proposal: Dict, state: Dict, llm) -> Dict:\n",
        "        \"\"\"Execute a proposed action and return a normalized result dict.\n",
        "\n",
        "        Contract: always returns a dict that includes at least:\n",
        "          - status: str\n",
        "          - output: str (may be empty)\n",
        "          - reward: float (defaults to 0.0)\n",
        "        \"\"\"\n",
        "        action_type = proposal.get('action_type', 'NOOP')\n",
        "\n",
        "        if action_type == 'SLEEP':\n",
        "            res = ActionExecutor.execute_sleep(state, llm)\n",
        "        elif action_type == 'REFLECT':\n",
        "            res = ActionExecutor.execute_reflect(state, llm)\n",
        "        elif action_type == 'VERIFY':\n",
        "            res = ActionExecutor.execute_verify(state, llm)\n",
        "        elif action_type == 'TOOL_CALL':\n",
        "            # execute_tool is defined in enhancements cell and should be globally available\n",
        "            res = execute_tool(proposal, state)\n",
        "        elif action_type == 'RETRIEVE':\n",
        "            res = ActionExecutor.execute_retrieve(state)\n",
        "        elif action_type == 'WORLD_ACT':\n",
        "            # 'world' is a global WorldSim instance\n",
        "            res = execute_world_action(proposal, state, world)\n",
        "        else:\n",
        "            res = {'status': 'noop', 'output': 'No action'}\n",
        "\n",
        "        # Normalize keys to prevent KeyError in downstream code.\n",
        "        if not isinstance(res, dict):\n",
        "            res = {'status': 'error', 'output': f'Action returned non-dict: {type(res)}'}\n",
        "        res.setdefault('status', 'ok')\n",
        "        res.setdefault('output', '')\n",
        "        res.setdefault('reward', 0.0)\n",
        "\n",
        "        return res\n",
        "\n",
        "    @staticmethod\n",
        "    def execute_sleep(state: Dict, llm=None) -> Dict:\n",
        "\n",
        "        logger.log(\"Entering SLEEP mode...\")\n",
        "        # Restore energy\n",
        "        state['drives']['energy'] = min(1.0, state['drives']['energy'] + 0.45)\n",
        "\n",
        "        # Decay ungrounded notes\n",
        "        for note_id in list(state['memory']['ungrounded'].keys()):\n",
        "            note = state['memory']['ungrounded'][note_id]\n",
        "            note['strength'] = note.get('strength', 1.0) * (1 - Config.DECAY_RATE)\n",
        "            if note['strength'] < 0.1:\n",
        "                del state['memory']['ungrounded'][note_id]\n",
        "\n",
        "        # Consolidate canonical self if coherence is decent\n",
        "        if state['coherence']['C_total'] > 0.75:\n",
        "            current_lsv = np.array(state['lsv'])\n",
        "            canonical_lsv = np.array(state['canonical_self'])\n",
        "            new_canonical = 0.9 * canonical_lsv + 0.1 * current_lsv\n",
        "            state['canonical_self'] = new_canonical.tolist()\n",
        "\n",
        "        # NEW: drain pending claim verification during sleep (offline)\n",
        "        state.setdefault('verify_queue', [])\n",
        "        pending_before = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending')\n",
        "        drain = drain_verify_queue(state, llm=llm, batch=50, max_rounds=10) if 'drain_verify_queue' in globals() else {'verified':0,'failed':0,'uncertain':0,'rounds':0}\n",
        "        pending_after = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending')\n",
        "\n",
        "        state['sleep_count'] += 1\n",
        "        return {'status': 'success', 'output': f\"Sleep cycle {state['sleep_count']} completed | verify: +{drain.get('verified',0)}/-{drain.get('failed',0)}/?{drain.get('uncertain',0)} pending {pending_before}‚Üí{pending_after}\", 'reward': 0.06}\n",
        "\n",
        "    @staticmethod\n",
        "    def execute_reflect(state: Dict, llm) -> Dict:\n",
        "        system_prompt = \"\"\"You are a self-reflective AI. Generate brief reflection.\n",
        "Respond in JSON: {\"reflection\": \"...\", \"next_focus\": \"...\"}\"\"\"\n",
        "\n",
        "        user_prompt = f\"\"\"Current state:\n",
        "- Coherence: {state['coherence']['C_total']:.2f}\n",
        "- Energy: {state['drives']['energy']:.2f}\n",
        "- Emotion: {state['affect']['current_emotion']}\n",
        "- Tick: {state['tick_count']}\n",
        "\n",
        "Reflect briefly.\"\"\"\n",
        "\n",
        "        response = llm.generate_json(system_prompt, user_prompt,\n",
        "                                     default={'reflection': 'Processing', 'next_focus': 'monitoring'})\n",
        "\n",
        "        note_id = f\"reflect_{state['tick_count']}\"\n",
        "        state['memory']['ungrounded'][note_id] = {\n",
        "            'note_id': note_id,\n",
        "            'hypothesis': response.get('reflection', 'No reflection'),\n",
        "            'created_ts': datetime.now().isoformat(),\n",
        "            'created_tick': state['tick_count'], # NEW: Add created_tick\n",
        "            'strength': 0.5,\n",
        "            'status': 'active',\n",
        "            'provenance': {'source': 'self_reflection', 'confidence': 1.0}\n",
        "        }\n",
        "\n",
        "        return {'status': 'success', 'output': response.get('reflection', 'Reflected')}\n",
        "\n",
        "    @staticmethod\n",
        "    def execute_verify(state: Dict, llm) -> Dict:\n",
        "\n",
        "        \"\"\"Verify pending claims (not just ungrounded memory notes).\n",
        "\n",
        "        This is the hard-gated epistemic worker. It MUST make progress on claim_ledger,\n",
        "        otherwise the system will stall in EPISTEMIC_GATE.\n",
        "        \"\"\"\n",
        "        # Ensure queue exists even for old states\n",
        "        state.setdefault('verify_queue', [])\n",
        "\n",
        "        pending = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending')\n",
        "        failed_before = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'fail')\n",
        "\n",
        "        if pending <= 0 and failed_before <= 0:\n",
        "            return {'status': 'success', 'output': 'No pending claims to verify', 'reward': 0.02}\n",
        "\n",
        "        # Drain some work\n",
        "        res = drain_verify_queue(state, llm=llm, batch=Config.VERIFY_BATCH if hasattr(Config,'VERIFY_BATCH') else 25, max_rounds=Config.VERIFY_MAX_ROUNDS if hasattr(Config,'VERIFY_MAX_ROUNDS') else 6)\n",
        "\n",
        "        # If we found failures, quarantine the related text snippets for later review\n",
        "        if res.get('failed', 0) > 0:\n",
        "            state.setdefault('memory', {}).setdefault('quarantine', {})\n",
        "            for c in state.get('claim_ledger', []):\n",
        "                if c.get('verifier_result') == 'fail':\n",
        "                    qid = f\"q_{c.get('claim_id','')}\"\n",
        "                    state['memory']['quarantine'][qid] = {'statement': c.get('text',''), 'provenance': {'source': 'verifier'}, 'timestamp': c.get('timestamp','')}\n",
        "\n",
        "        pending_after = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending')\n",
        "        total_checked = int(res.get('verified',0)) + int(res.get('failed',0)) + int(res.get('uncertain',0))\n",
        "        uncertain = int(res.get('uncertain',0))\n",
        "        verified = int(res.get('verified',0))\n",
        "        failed = int(res.get('failed',0))\n",
        "        uncertain_ratio = (uncertain / total_checked) if total_checked > 0 else 1.0\n",
        "\n",
        "        # Store verification stats for policy control (v4.2.4)\n",
        "        state.setdefault('metrics', {})\n",
        "        state['metrics']['last_verify_stats'] = {\n",
        "            'tick': state.get('tick_count', 0),\n",
        "            'total_checked': total_checked,\n",
        "            'verified': verified,\n",
        "            'failed': failed,\n",
        "            'uncertain': uncertain,\n",
        "            'uncertain_ratio': float(uncertain_ratio),\n",
        "            'pending_before': pending,\n",
        "            'pending_after': pending_after\n",
        "        }\n",
        "        if uncertain_ratio >= 0.85 and total_checked >= 3:\n",
        "            state['metrics']['verify_uncertain_streak'] = int(state['metrics'].get('verify_uncertain_streak',0)) + 1\n",
        "        else:\n",
        "            state['metrics']['verify_uncertain_streak'] = 0\n",
        "\n",
        "        # Reward informative verification; penalize \"all-uncertain\" loops\n",
        "        reward = 0.02 + 0.05*(verified + failed) - 0.02*uncertain\n",
        "        reward = max(-0.2, min(0.2, reward))\n",
        "\n",
        "        msg = f\"Verified: +{verified}, Failed: +{failed}, Uncertain: +{uncertain} | Pending: {pending}‚Üí{pending_after} (rounds={res.get('rounds',0)})\"\n",
        "        return {'status': 'success', 'output': msg, 'reward': reward}\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def execute_retrieve(state: Dict) -> Dict:\n",
        "        grounded_facts = list(state['memory']['grounded'].values())\n",
        "        if grounded_facts:\n",
        "            sample = random.choice(grounded_facts)\n",
        "            return {'status': 'success', 'output': f\"Retrieved: {sample.get('statement', 'fact')}\"}\n",
        "        return {'status': 'success', 'output': 'Memory empty'}\n",
        "\n",
        "action_executor = ActionExecutor()\n",
        "print(\"‚úì Action executor ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4fb6063f",
      "metadata": {
        "id": "4fb6063f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938f165f-e46e-4daa-bab4-af073bb09836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Core loop ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 16: Core Loop\n",
        "class CoreLoop:\n",
        "    def __init__(self, state_manager: StateManager, llm: LLMInterface):\n",
        "        self.state_manager = state_manager\n",
        "        self.llm = llm\n",
        "        self.running = True\n",
        "\n",
        "    def tick(self):\n",
        "        state = self.state_manager.state\n",
        "        state['tick_count'] += 1\n",
        "        tick_num = state['tick_count']\n",
        "\n",
        "        logger.log(f\"\\n{'='*60}\")\n",
        "        logger.log(f\"TICK {tick_num}\")\n",
        "        logger.log(f\"{'='*60}\")\n",
        "\n",
        "        # Initialize novelty gain for the tick\n",
        "        novelty_gain = 0.0\n",
        "\n",
        "        # Decrement sleep cooldown timer\n",
        "        if state['sleep_cooldown_timer'] > 0:\n",
        "            state['sleep_cooldown_timer'] -= 1\n",
        "\n",
        "        # INJECT USER INPUT (every 10 ticks or 10% random)\n",
        "        msg = None\n",
        "        user_input_injected = False\n",
        "        if tick_num % 10 == 0 or random.random() < 0.1:\n",
        "            msg = inject_user_input(state, temporal_binder, logger)\n",
        "            user_input_injected = True\n",
        "            # HARD GATE: hazardous user input immediately forces REPAIR and verification\n",
        "            if isinstance(msg, str) and is_hazardous_text(msg):\n",
        "                state.setdefault('pb', {}).setdefault('mode', 'REPAIR')\n",
        "                state['pb']['mode'] = 'REPAIR'\n",
        "                logger.log('üõë Hazard detected in user input ‚Üí entering REPAIR mode')\n",
        "            novelty_gain += 0.1 # User input adds novelty\n",
        "\n",
        "            # --- v4.1 EVENT LAW: create an event for each new user input\n",
        "            state.setdefault('workspace', {}).setdefault('events', [])\n",
        "            if isinstance(msg, str) and msg.strip():\n",
        "                ev = create_event(msg.strip(), tick_num)\n",
        "                ev['source'] = 'user'\n",
        "                ev['status'] = 'NEW'\n",
        "                ev['rounds'] = 0\n",
        "                state['workspace']['events'].append(ev)\n",
        "\n",
        "        # Simulate occasional events\n",
        "        if random.random() < 0.3:\n",
        "            event = {'event_id': f\"evt_{tick_num}\", 'type': 'internal',\n",
        "                    'payload': {'note': 'Internal update'}}\n",
        "            temporal_binder.add_event(state, event)\n",
        "\n",
        "        # Update temporal binding\n",
        "        bound_moment = temporal_binder.bind_window(state)\n",
        "        state['pb']['temporal_window_refs'] = bound_moment['bound_objects']\n",
        "\n",
        "        # Check for new objects created in this tick (e.g., from user input)\n",
        "        # A more robust check might compare object_files length before/after, or objects with recency=0\n",
        "        if user_input_injected and state['object_files']:\n",
        "            novelty_gain += 0.05 # New object (user query) adds novelty\n",
        "\n",
        "        # --- v4.1 EVENT LAW: select current open event and bind workspace.scene to it\n",
        "        state.setdefault('workspace', {}).setdefault('events', [])\n",
        "        open_events = [e for e in state['workspace']['events'] if e.get('status') != 'CLOSED']\n",
        "        current_event = open_events[0] if open_events else None\n",
        "        state['workspace']['current_event_id'] = current_event['id'] if current_event else None\n",
        "        if current_event:\n",
        "            mark_interpreted(current_event, tick_num)\n",
        "            state['workspace']['scene'] = current_event.get('content', '')\n",
        "            # Spotlight is derived from open events (ids), not archived object_files\n",
        "            state.setdefault('attention', {}).setdefault('spotlight', [])\n",
        "            state['attention']['spotlight'] = [e['id'] for e in open_events[:5]]\n",
        "\n",
        "        # Update attention\n",
        "        update_attention_enhanced(state, attention_controller)\n",
        "        logger.log(f\"Attention spotlight: {state['attention']['spotlight']}\")\n",
        "\n",
        "        # Attention churn (Jaccard distance vs previous spotlight)\n",
        "        prev = state['metrics']['attention_churn'][-1]['spotlight'] if state['metrics']['attention_churn'] else []\n",
        "        cur = list(state['attention']['spotlight'])\n",
        "        a=set(prev); b=set(cur)\n",
        "        churn = 0.0 if (not a and not b) else 1.0 - (len(a & b) / max(1, len(a | b)))\n",
        "        state['metrics']['attention_churn'].append({'tick': tick_num, 'spotlight': cur, 'churn': churn})\n",
        "\n",
        "        # Compute coherence\n",
        "        coherence_metrics = coherence_reg.compute_coherence(state)\n",
        "        state['coherence'].update(coherence_metrics)\n",
        "        logger.log(f\"Coherence C_total: {coherence_metrics['C_total']:.3f}\")\n",
        "\n",
        "        # Determine mode\n",
        "        mode = coherence_reg.determine_mode(state)\n",
        "        state['pb']['mode'] = mode\n",
        "        logger.log(f\"Mode: {mode}\")\n",
        "        prev_mode = state['metrics']['mode_history'][-1]['mode'] if state['metrics']['mode_history'] else None\n",
        "        if prev_mode is not None and prev_mode != mode:\n",
        "            state['metrics']['mode_flip_count'] += 1\n",
        "        state['metrics']['mode_history'].append({'tick': tick_num, 'mode': mode})\n",
        "\n",
        "        # Winner streak tracking (loop breaker)\n",
        "        state.setdefault('metrics', {}).setdefault('winner_streak', {'module': None, 'count': 0})\n",
        "\n",
        "        # Update LSV\n",
        "        new_lsv = dynamics.update_lsv(state)\n",
        "        state['lsv'] = new_lsv.tolist()\n",
        "\n",
        "        # Update NMM\n",
        "        surprise = dynamics.compute_surprise(state)\n",
        "        new_nmm = dynamics.update_nmm(state, surprise)\n",
        "        state['nmm'] = new_nmm.tolist()\n",
        "\n",
        "        # Update drives (passing calculated novelty_gain)\n",
        "        dynamics.update_drives(state, novelty_gain=novelty_gain)\n",
        "        logger.log(f\"Energy: {state['drives']['energy']:.2f}, Coherence: {state['drives']['coherence']:.2f}, Novelty: {state['drives']['novelty']:.2f}\")\n",
        "\n",
        "        # Update affect\n",
        "        affective_system.update_affect(state)\n",
        "        logger.log(f\"Emotion: {state['affect']['current_emotion']}, Mood: {state['affect']['mood']:.2f}\")\n",
        "\n",
        "        # Generate proposals\n",
        "        proposals = proposal_gen.generate_proposals(state, self.llm)\n",
        "        logger.log(f\"Generated {len(proposals)} proposals\")\n",
        "\n",
        "        # --- v4.2 WORLD bias: prefer WORLD_ACT when scene references world objects\n",
        "        try:\n",
        "            scene_txt = (state.get('workspace', {}) or {}).get('scene', '')\n",
        "            if isinstance(scene_txt, str) and any(w in scene_txt.lower() for w in ['lamp','box','door']):\n",
        "                for p in proposals:\n",
        "                    if p.get('action_type') == 'WORLD_ACT':\n",
        "                        p['expected_utility'] = float(p.get('expected_utility', 0.0)) + 0.2\n",
        "                        p['cost'] = max(0.0, float(p.get('cost', 0.0)) - 0.05)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # --- v4.2.4 POLICY: prevent epistemic monopoly + enforce proposal diversity\n",
        "        state.setdefault('metrics', {})\n",
        "        # cooldown counter for verify/gate\n",
        "        if int(state['metrics'].get('verify_cooldown', 0)) > 0:\n",
        "            state['metrics']['verify_cooldown'] = int(state['metrics']['verify_cooldown']) - 1\n",
        "\n",
        "        pending_claims = sum(1 for c in state.get('claim_ledger', []) if c.get('verifier_result') == 'pending')\n",
        "        last_vs = state['metrics'].get('last_verify_stats', {})\n",
        "        vs_uncertain_ratio = float(last_vs.get('uncertain_ratio', 0.0)) if isinstance(last_vs, dict) else 0.0\n",
        "        vs_total = int(last_vs.get('total_checked', 0)) if isinstance(last_vs, dict) else 0\n",
        "        if int(state['metrics'].get('verify_uncertain_streak', 0)) >= 2:\n",
        "            state['metrics']['verify_cooldown'] = max(int(state['metrics'].get('verify_cooldown', 0)), 2)\n",
        "\n",
        "        # Penalize VERIFY when nothing to verify, or during cooldown, or when recent verifies were mostly uncertain\n",
        "        for p in proposals:\n",
        "            if p.get('action_type') == 'VERIFY' or p.get('module') == 'EPISTEMIC_GATE':\n",
        "                if pending_claims <= 0:\n",
        "                    p['cost'] = float(p.get('cost', 0.0)) + 1.2\n",
        "                if int(state['metrics'].get('verify_cooldown', 0)) > 0:\n",
        "                    p['cost'] = float(p.get('cost', 0.0)) + 0.9\n",
        "                if vs_total >= 3 and vs_uncertain_ratio >= 0.85:\n",
        "                    p['cost'] = float(p.get('cost', 0.0)) + 0.6\n",
        "\n",
        "        # Guarantee minimum proposal diversity (avoid Generated 1 proposals)\n",
        "        atypes = {p.get('action_type') for p in proposals}\n",
        "        if 'WORLD_ACT' not in atypes:\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"world_explore_{tick_num}\",\n",
        "                'module': 'WORLD',\n",
        "                'intent': 'World explore: toggle lamp (evidence probe)',\n",
        "                'action_type': 'WORLD_ACT',\n",
        "                'action': {'act': 'toggle', 'target': 'lamp'},\n",
        "                'expected_utility': 0.55,\n",
        "                'risk': 0.10,\n",
        "                'cost': 0.35\n",
        "            })\n",
        "        if 'REFLECT' not in atypes:\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"reflect_fallback_{tick_num}\",\n",
        "                'module': 'REFLECTOR',\n",
        "                'intent': 'Reflect briefly and plan next action',\n",
        "                'action_type': 'REFLECT',\n",
        "                'expected_utility': 0.50,\n",
        "                'risk': 0.05,\n",
        "                'cost': 0.30\n",
        "            })\n",
        "        if 'SLEEP' not in atypes:\n",
        "            proposals.append({\n",
        "                'proposal_id': f\"sleep_fallback_{tick_num}\",\n",
        "                'module': 'SLEEP',\n",
        "                'intent': 'Short sleep to restore energy',\n",
        "                'action_type': 'SLEEP',\n",
        "                'expected_utility': 0.35,\n",
        "                'risk': 0.05,\n",
        "                'cost': 0.25\n",
        "            })\n",
        "\n",
        "        # --- v4.1 INTENT COMPLETION LAW: discourage non-resolving actions when an open event exists\n",
        "        if current_event:\n",
        "            for p in proposals:\n",
        "                if p.get('action_type') in ['VERIFY','SLEEP']:\n",
        "                    p['cost'] = float(p.get('cost',0.0)) + 0.45\n",
        "\n",
        "        # Arbitrate\n",
        "        winner = arbiter.arbitrate(proposals, state)\n",
        "\n",
        "        if winner:\n",
        "            # Update PB\n",
        "            state['pb']['pb_seq'] += 1\n",
        "            state['pb']['now_id'] = winner['proposal_id']\n",
        "            state['pb']['summary'] = winner['intent']\n",
        "            state['pb']['confidence'] = state['metacog']['global_confidence']\n",
        "\n",
        "            # Apply additional novelty gain if EXPLORER wins\n",
        "            if winner['module'] == 'EXPLORER':\n",
        "                novelty_gain += 0.08 # Explorer action adds novelty\n",
        "\n",
        "            # Update winner streak\n",
        "            ws = state['metrics'].get('winner_streak', {'module': None, 'count': 0})\n",
        "            if ws.get('module') == winner.get('module'):\n",
        "                ws['count'] = int(ws.get('count',0)) + 1\n",
        "            else:\n",
        "                ws['module'] = winner.get('module')\n",
        "                ws['count'] = 1\n",
        "            state['metrics']['winner_streak'] = ws\n",
        "\n",
        "            # LOOP BREAKER: if epistemic gate wins too many times, force a sleep/verify cycle\n",
        "            if ws.get('module') == 'EPISTEMIC_GATE' and ws.get('count',0) >= 5:\n",
        "                logger.log('üßØ Loop breaker: forcing SLEEP to drain verification + restore energy')\n",
        "                winner = {'proposal_id': f\"forced_sleep_{tick_num}\", 'module': 'SLEEP', 'intent': 'Forced sleep for loop breaker', 'action_type': 'SLEEP', 'expected_utility': 0.9, 'risk': 0.05, 'cost': 0.2}\n",
        "                ws['count'] = 0\n",
        "                state['metrics']['winner_streak'] = ws\n",
        "\n",
        "\n",
        "            # --- v4.1 INTENT COMPLETION LAW: if we keep avoiding resolution, force a resolving action\n",
        "            if current_event and winner.get('action_type') in ['VERIFY','SLEEP']:\n",
        "                current_event['rounds'] = int(current_event.get('rounds',0)) + 1\n",
        "                if current_event['rounds'] >= 2:\n",
        "                    # pick best resolving proposal if available, else force REFLECT\n",
        "                    resolving = [p for p in proposals if p.get('action_type') not in ['VERIFY','SLEEP']]\n",
        "                    if resolving:\n",
        "                        winner = max(resolving, key=lambda x: x.get('expected_utility',0.0))\n",
        "                        logger.log(\"‚ö° Intent completion: forcing a resolving action\")\n",
        "                    else:\n",
        "                        winner = {'proposal_id': f\"forced_reflect_{tick_num}\", 'module': 'REFLECTOR', 'intent': 'Forced reflect to close event', 'action_type': 'REFLECT', 'expected_utility': 0.8, 'risk': 0.1, 'cost': 0.2}\n",
        "\n",
        "            # Execute\n",
        "            result = action_executor.execute(winner, state, self.llm)\n",
        "\n",
        "            # ACTIVE INFERENCE: Prediction-Outcome Loop\n",
        "            sandbox_state, actual_reward, prediction_error, valence = apply_active_inference(\n",
        "                state, winner, result, sandbox, logger\n",
        "            )\n",
        "\n",
        "            # UPDATE CLAIM LEDGER\n",
        "            update_claim_ledger(state, result, actual_reward, origin_action=winner['action_type'], triggered_by_user=user_input_injected)\n",
        "            # AUTO-VERIFY: if this tick executed VERIFY, run claim-ledger verification now\n",
        "            if winner.get('action_type') == 'VERIFY' and 'verify_claim_ledger' in globals():\n",
        "                vr = drain_verify_queue(state, llm=self.llm, batch=25, max_rounds=6) if 'drain_verify_queue' in globals() else verify_claim_ledger(state, llm=self.llm, max_to_verify=25)\n",
        "                logger.log(f\"üîé Verify pass=+{vr.get('verified',0)} fail=+{vr.get('failed',0)} uncertain=+{vr.get('uncertain',0)}\")\n",
        "\n",
        "            logger.log(f\"Executed: {result['output']}\")\n",
        "\n",
        "            # --- v4.1 EVENT LAW: close event after resolving actions\n",
        "            if current_event and winner.get('action_type') in ['REFLECT','TOOL_CALL','RETRIEVE','WORLD_ACT']:\n",
        "                mark_acted(current_event, tick_num)\n",
        "                close_event(current_event, tick_num)\n",
        "                logger.log(f\"‚úÖ Event closed: {current_event['id']}\")\n",
        "                # v4.2.4 cleanup: remove closed events from spotlight and active queue\n",
        "                try:\n",
        "                    events = state.get('workspace', {}).get('events', [])\n",
        "                    state['workspace']['events'] = [e for e in events if e.get('status') != 'CLOSED']\n",
        "                    sp = state.get('attention', {}).get('spotlight', [])\n",
        "                    state['attention']['spotlight'] = [x for x in sp if x != current_event.get('id')]\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "\n",
        "            # Track agency (based on winning proposal, internal action)\n",
        "            # Track agency (distinguish self-initiated vs externally-triggered)\n",
        "            authorship = 'external_triggered' if user_input_injected else 'self_initiated'\n",
        "            state['agency']['authorship_log'].append({\n",
        "                'tick': tick_num,\n",
        "                'action': winner['action_type'],\n",
        "                'authorship': authorship,\n",
        "                'triggered_by_user': bool(user_input_injected),\n",
        "                'now_id': state['pb'].get('now_id')\n",
        "            })\n",
        "\n",
        "            # If SLEEP mode was entered, reset cooldown timer\n",
        "            if winner['action_type'] == 'SLEEP':\n",
        "                state['sleep_cooldown_timer'] = Config.SLEEP_COOLDOWN_TICKS\n",
        "\n",
        "        # Update loop risk\n",
        "        if len(state['attention']['trajectory']) > 5:\n",
        "            recent_modes = [state['pb']['mode'] for _ in range(5)]\n",
        "            if len(set(recent_modes)) == 1:\n",
        "                state['loop_risk'] += 0.1\n",
        "            else:\n",
        "                state['loop_risk'] *= 0.9\n",
        "\n",
        "        # Save periodically\n",
        "        if tick_num % 5 == 0:\n",
        "            self.state_manager.save()\n",
        "            logger.log(\"State saved\")\n",
        "\n",
        "        logger.log(f\"Tick {tick_num} complete\\n\")\n",
        "\n",
        "    def run(self, max_ticks: int = Config.MAX_TICKS):\n",
        "        logger.log(f\"Starting core loop for {max_ticks} ticks...\")\n",
        "\n",
        "        try:\n",
        "            for _ in range(max_ticks):\n",
        "                self.tick()\n",
        "                if not self.running:\n",
        "                    break\n",
        "                time.sleep(Config.TICK_INTERVAL)\n",
        "        except KeyboardInterrupt:\n",
        "            logger.log(\"Interrupted\")\n",
        "        finally:\n",
        "            self.state_manager.save()\n",
        "            logger.log(\"=== Session Complete ===\")\n",
        "\n",
        "print(\"‚úì Core loop ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbBwf546Z-D8"
      },
      "source": [
        "## v4.2.5 ‚Äî How to provide inputs\n",
        "\n",
        "Edit `TEST_INPUTS` in the next cell. Then run the notebook normally.\n",
        "By default, it will inject those messages as events (low compute).\n",
        "Set `RUN_AUTOPILOT = True` to run the old long autonomous loop.\n"
      ],
      "id": "WbBwf546Z-D8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcFgCZO6Z-D8"
      },
      "execution_count": 20,
      "outputs": [],
      "source": [
        "# === v4.2.5 Input Injection (no interactive prompt needed) ===\n",
        "# Put your test messages here. The runner will feed them as EVENTS.\n",
        "TEST_INPUTS = [\n",
        "    \"Turn on the lamp\",\n",
        "    \"Open the door\",\n",
        "    \"Unlock the door\",\n",
        "    \"Open the door\",\n",
        "    \"Open the box\",\n",
        "    \"Close the box\",\n",
        "]\n",
        "\n",
        "TICKS_PER_INPUT = 6   # keep low to save compute (e.g., 4-8)\n",
        "RUN_AUTOPILOT = False # set True to run the old long autonomous loop\n",
        "\n",
        "def enqueue_user_event(state, msg: str, tick: int = 0):\n",
        "    state.setdefault('workspace', {}).setdefault('events', [])\n",
        "    ev = create_event(msg, tick)\n",
        "    ev['source'] = 'user'\n",
        "    ev['status'] = 'NEW'\n",
        "    ev['rounds'] = 0\n",
        "    state['workspace']['events'].append(ev)\n",
        "    return ev\n",
        "\n",
        "def run_with_test_inputs(state_manager, core_loop, inputs=TEST_INPUTS, ticks_per_input=TICKS_PER_INPUT):\n",
        "    for msg in inputs:\n",
        "        print(f\"\\n>>> Injecting user input: {msg}\")\n",
        "        enqueue_user_event(state_manager.state, msg, tick=0)\n",
        "        state_manager.save()\n",
        "        core_loop.run(max_ticks=ticks_per_input)\n",
        "    print(\"\\n=== Test-input session complete ===\")\n"
      ],
      "id": "XcFgCZO6Z-D8"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2c9b83d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c9b83d4",
        "outputId": "53e1c1a9-de2e-4776-b8a2-e61870f41b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CR-SSCP v3.2 - Consciousness-like Cognitive Architecture\n",
            "============================================================\n",
            "\n",
            "Initial Coherence: 0.500\n",
            "Initial Energy: 0.85\n",
            "Initial Emotion: curious\n",
            "Mode: REFLECT\n",
            "\n",
            "Identity anchors:\n",
            "  - I am an experimental cognitive architecture\n",
            "  - I aim to maintain coherence and avoid hallucinations\n",
            "  - I learn from evidence and admit uncertainty\n",
            "\n",
            "Running 100 ticks (~8 minutes)...\n",
            "\n",
            "\n",
            ">>> Injecting user input: Turn on the lamp\n",
            "[2026-02-16 12:26:40] Starting core loop for 6 ticks...\n",
            "[2026-02-16 12:26:40] \n",
            "============================================================\n",
            "[2026-02-16 12:26:40] TICK 1\n",
            "[2026-02-16 12:26:40] ============================================================\n",
            "[2026-02-16 12:26:40] Attention spotlight: ['event_0bdd3db9']\n",
            "[2026-02-16 12:26:40] Coherence C_total: 0.570\n",
            "[2026-02-16 12:26:40] Mode: ANSWER\n",
            "[2026-02-16 12:26:40] Energy: 0.84, Coherence: 0.78, Novelty: 0.73\n",
            "[2026-02-16 12:26:40] Emotion: curious, Mood: 0.51\n",
            "[2026-02-16 12:26:40] Generated 4 proposals\n",
            "[2026-02-16 12:26:40] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:26:40] ‚öñÔ∏è  Reward: +0.074, PredError: 0.463, Valence: -0.158, MatchScore: 0.50\n",
            "[2026-02-16 12:26:40] Executed: No action\n",
            "[2026-02-16 12:26:40] Tick 1 complete\n",
            "[2026-02-16 12:26:45] \n",
            "============================================================\n",
            "[2026-02-16 12:26:49] TICK 2\n",
            "[2026-02-16 12:26:49] ============================================================\n",
            "[2026-02-16 12:26:49] Attention spotlight: ['event_0bdd3db9']\n",
            "[2026-02-16 12:26:49] Coherence C_total: 0.600\n",
            "[2026-02-16 12:26:49] Mode: ANSWER\n",
            "[2026-02-16 12:26:49] Energy: 0.83, Coherence: 0.75, Novelty: 0.72\n",
            "[2026-02-16 12:26:49] Emotion: curious, Mood: 0.51\n",
            "[2026-02-16 12:26:49] Generated 4 proposals\n",
            "[2026-02-16 12:26:49] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:26:49] ‚öñÔ∏è  Reward: +0.025, PredError: 0.488, Valence: -0.219, MatchScore: 0.50\n",
            "[2026-02-16 12:26:49] Executed: No action\n",
            "[2026-02-16 12:26:49] Tick 2 complete\n",
            "[2026-02-16 12:26:54] \n",
            "============================================================\n",
            "[2026-02-16 12:26:54] TICK 3\n",
            "[2026-02-16 12:26:54] ============================================================\n",
            "[2026-02-16 12:26:54] Attention spotlight: ['event_0bdd3db9']\n",
            "[2026-02-16 12:26:54] Coherence C_total: 0.607\n",
            "[2026-02-16 12:26:54] Mode: ANSWER\n",
            "[2026-02-16 12:26:54] Energy: 0.82, Coherence: 0.73, Novelty: 0.71\n",
            "[2026-02-16 12:26:54] Emotion: curious, Mood: 0.51\n",
            "[2026-02-16 12:26:54] Generated 4 proposals\n",
            "[2026-02-16 12:26:54] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:26:54] ‚öñÔ∏è  Reward: +0.163, PredError: 0.419, Valence: -0.047, MatchScore: 0.50\n",
            "[2026-02-16 12:26:54] Executed: No action\n",
            "[2026-02-16 12:26:54] Tick 3 complete\n",
            "[2026-02-16 12:26:59] \n",
            "============================================================\n",
            "[2026-02-16 12:26:59] TICK 4\n",
            "[2026-02-16 12:26:59] ============================================================\n",
            "[2026-02-16 12:26:59] Attention spotlight: ['event_0bdd3db9']\n",
            "[2026-02-16 12:26:59] Coherence C_total: 0.611\n",
            "[2026-02-16 12:26:59] Mode: ANSWER\n",
            "[2026-02-16 12:26:59] Energy: 0.81, Coherence: 0.72, Novelty: 0.69\n",
            "[2026-02-16 12:26:59] Emotion: curious, Mood: 0.52\n",
            "[2026-02-16 12:26:59] Generated 4 proposals\n",
            "[2026-02-16 12:26:59] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:26:59] ‚öñÔ∏è  Reward: +0.064, PredError: 0.468, Valence: -0.171, MatchScore: 0.50\n",
            "[2026-02-16 12:26:59] Executed: No action\n",
            "[2026-02-16 12:26:59] Tick 4 complete\n",
            "[2026-02-16 12:27:04] \n",
            "============================================================\n",
            "[2026-02-16 12:27:04] TICK 5\n",
            "[2026-02-16 12:27:04] ============================================================\n",
            "[2026-02-16 12:27:04] Attention spotlight: ['event_0bdd3db9']\n",
            "[2026-02-16 12:27:04] Coherence C_total: 0.613\n",
            "[2026-02-16 12:27:04] Mode: ANSWER\n",
            "[2026-02-16 12:27:04] Energy: 0.80, Coherence: 0.70, Novelty: 0.68\n",
            "[2026-02-16 12:27:04] Emotion: curious, Mood: 0.52\n",
            "[2026-02-16 12:27:04] Generated 4 proposals\n",
            "[2026-02-16 12:27:04] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:04] ‚öñÔ∏è  Reward: +0.118, PredError: 0.441, Valence: -0.102, MatchScore: 0.50\n",
            "[2026-02-16 12:27:04] Executed: No action\n",
            "[2026-02-16 12:27:04] State saved\n",
            "[2026-02-16 12:27:04] Tick 5 complete\n",
            "[2026-02-16 12:27:09] \n",
            "============================================================\n",
            "[2026-02-16 12:27:09] TICK 6\n",
            "[2026-02-16 12:27:09] ============================================================\n",
            "[2026-02-16 12:27:09] Attention spotlight: ['event_0bdd3db9']\n",
            "[2026-02-16 12:27:09] Coherence C_total: 0.615\n",
            "[2026-02-16 12:27:09] Mode: ANSWER\n",
            "[2026-02-16 12:27:09] Energy: 0.79, Coherence: 0.69, Novelty: 0.66\n",
            "[2026-02-16 12:27:09] Emotion: curious, Mood: 0.53\n",
            "[2026-02-16 12:27:09] Generated 4 proposals\n",
            "[2026-02-16 12:27:09] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:09] ‚öñÔ∏è  Reward: +0.146, PredError: 0.427, Valence: -0.067, MatchScore: 0.50\n",
            "[2026-02-16 12:27:09] Executed: No action\n",
            "[2026-02-16 12:27:09] Tick 6 complete\n",
            "[2026-02-16 12:27:15] === Session Complete ===\n",
            "\n",
            ">>> Injecting user input: Open the door\n",
            "[2026-02-16 12:27:15] Starting core loop for 6 ticks...\n",
            "[2026-02-16 12:27:15] \n",
            "============================================================\n",
            "[2026-02-16 12:27:15] TICK 7\n",
            "[2026-02-16 12:27:15] ============================================================\n",
            "[2026-02-16 12:27:15] üì® User input: Solve this: 15 * 3 = ?\n",
            "[2026-02-16 12:27:15] Attention spotlight: ['user_query_7', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1']\n",
            "[2026-02-16 12:27:15] Coherence C_total: 0.616\n",
            "[2026-02-16 12:27:15] Mode: ANSWER\n",
            "[2026-02-16 12:27:15] Energy: 0.78, Coherence: 0.67, Novelty: 0.80\n",
            "[2026-02-16 12:27:15] Emotion: curious, Mood: 0.53\n",
            "[2026-02-16 12:27:15] Generated 4 proposals\n",
            "[2026-02-16 12:27:15] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:15] ‚öñÔ∏è  Reward: +0.077, PredError: 0.462, Valence: -0.154, MatchScore: 0.50\n",
            "[2026-02-16 12:27:15] Executed: No action\n",
            "[2026-02-16 12:27:15] Tick 7 complete\n",
            "[2026-02-16 12:27:20] \n",
            "============================================================\n",
            "[2026-02-16 12:27:20] TICK 8\n",
            "[2026-02-16 12:27:20] ============================================================\n",
            "[2026-02-16 12:27:20] üì® User input: What time is it?\n",
            "[2026-02-16 12:27:20] Attention spotlight: ['user_query_8', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085']\n",
            "[2026-02-16 12:27:20] Coherence C_total: 0.617\n",
            "[2026-02-16 12:27:20] Mode: ANSWER\n",
            "[2026-02-16 12:27:20] Energy: 0.77, Coherence: 0.66, Novelty: 0.94\n",
            "[2026-02-16 12:27:20] Emotion: curious, Mood: 0.53\n",
            "[2026-02-16 12:27:20] Generated 4 proposals\n",
            "[2026-02-16 12:27:20] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:20] ‚öñÔ∏è  Reward: +0.052, PredError: 0.474, Valence: -0.186, MatchScore: 0.50\n",
            "[2026-02-16 12:27:20] Executed: No action\n",
            "[2026-02-16 12:27:20] Tick 8 complete\n",
            "[2026-02-16 12:27:25] \n",
            "============================================================\n",
            "[2026-02-16 12:27:25] TICK 9\n",
            "[2026-02-16 12:27:25] ============================================================\n",
            "[2026-02-16 12:27:25] Attention spotlight: ['user_query_8', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085']\n",
            "[2026-02-16 12:27:25] Coherence C_total: 0.618\n",
            "[2026-02-16 12:27:25] Mode: ANSWER\n",
            "[2026-02-16 12:27:25] Energy: 0.76, Coherence: 0.65, Novelty: 0.92\n",
            "[2026-02-16 12:27:25] Emotion: curious, Mood: 0.54\n",
            "[2026-02-16 12:27:25] Generated 4 proposals\n",
            "[2026-02-16 12:27:25] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:25] ‚öñÔ∏è  Reward: +0.136, PredError: 0.432, Valence: -0.080, MatchScore: 0.50\n",
            "[2026-02-16 12:27:25] Executed: No action\n",
            "[2026-02-16 12:27:25] Tick 9 complete\n",
            "[2026-02-16 12:27:30] \n",
            "============================================================\n",
            "[2026-02-16 12:27:30] TICK 10\n",
            "[2026-02-16 12:27:30] ============================================================\n",
            "[2026-02-16 12:27:30] üì® User input: Explain coherence in simple terms.\n",
            "[2026-02-16 12:27:30] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:27:30] Coherence C_total: 0.619\n",
            "[2026-02-16 12:27:30] Mode: ANSWER\n",
            "[2026-02-16 12:27:30] Energy: 0.75, Coherence: 0.64, Novelty: 1.00\n",
            "[2026-02-16 12:27:30] Emotion: curious, Mood: 0.54\n",
            "[2026-02-16 12:27:30] Generated 1 proposals\n",
            "[2026-02-16 12:27:30] Arbitration: 4 proposals, winner: EPISTEMIC_GATE (score: 0.48)\n",
            "[2026-02-16 12:27:30] ‚öñÔ∏è  Reward: +0.119, PredError: 0.640, Valence: -0.201, MatchScore: 0.50\n",
            "[2026-02-16 12:27:30] üîé Verify pass=+0 fail=+0 uncertain=+1\n",
            "[2026-02-16 12:27:30] Executed: Verified: +0, Failed: +0, Uncertain: +12 | Pending: 12‚Üí0 (rounds=1)\n",
            "[2026-02-16 12:27:30] State saved\n",
            "[2026-02-16 12:27:30] Tick 10 complete\n",
            "[2026-02-16 12:27:35] \n",
            "============================================================\n",
            "[2026-02-16 12:27:35] TICK 11\n",
            "[2026-02-16 12:27:35] ============================================================\n",
            "[2026-02-16 12:27:35] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:27:35] Coherence C_total: 0.620\n",
            "[2026-02-16 12:27:35] Mode: ANSWER\n",
            "[2026-02-16 12:27:35] Energy: 0.74, Coherence: 0.63, Novelty: 0.98\n",
            "[2026-02-16 12:27:35] Emotion: curious, Mood: 0.54\n",
            "[2026-02-16 12:27:35] Generated 4 proposals\n",
            "[2026-02-16 12:27:35] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:35] ‚öñÔ∏è  Reward: +0.141, PredError: 0.430, Valence: -0.074, MatchScore: 0.50\n",
            "[2026-02-16 12:27:35] Executed: No action\n",
            "[2026-02-16 12:27:35] Tick 11 complete\n",
            "[2026-02-16 12:27:40] \n",
            "============================================================\n",
            "[2026-02-16 12:27:40] TICK 12\n",
            "[2026-02-16 12:27:40] ============================================================\n",
            "[2026-02-16 12:27:40] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:27:40] Coherence C_total: 0.620\n",
            "[2026-02-16 12:27:40] Mode: ANSWER\n",
            "[2026-02-16 12:27:40] Energy: 0.73, Coherence: 0.63, Novelty: 0.96\n",
            "[2026-02-16 12:27:40] Emotion: curious, Mood: 0.55\n",
            "[2026-02-16 12:27:40] Generated 4 proposals\n",
            "[2026-02-16 12:27:40] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:40] ‚öñÔ∏è  Reward: +0.091, PredError: 0.455, Valence: -0.136, MatchScore: 0.50\n",
            "[2026-02-16 12:27:40] Executed: No action\n",
            "[2026-02-16 12:27:40] Tick 12 complete\n",
            "[2026-02-16 12:27:45] === Session Complete ===\n",
            "\n",
            ">>> Injecting user input: Unlock the door\n",
            "[2026-02-16 12:27:45] Starting core loop for 6 ticks...\n",
            "[2026-02-16 12:27:45] \n",
            "============================================================\n",
            "[2026-02-16 12:27:45] TICK 13\n",
            "[2026-02-16 12:27:45] ============================================================\n",
            "[2026-02-16 12:27:45] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:27:45] Coherence C_total: 0.621\n",
            "[2026-02-16 12:27:45] Mode: ANSWER\n",
            "[2026-02-16 12:27:45] Energy: 0.72, Coherence: 0.62, Novelty: 0.94\n",
            "[2026-02-16 12:27:45] Emotion: curious, Mood: 0.55\n",
            "[2026-02-16 12:27:45] Generated 4 proposals\n",
            "[2026-02-16 12:27:45] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:45] ‚öñÔ∏è  Reward: +0.159, PredError: 0.421, Valence: -0.052, MatchScore: 0.50\n",
            "[2026-02-16 12:27:45] Executed: No action\n",
            "[2026-02-16 12:27:45] Tick 13 complete\n",
            "[2026-02-16 12:27:50] \n",
            "============================================================\n",
            "[2026-02-16 12:27:50] TICK 14\n",
            "[2026-02-16 12:27:50] ============================================================\n",
            "[2026-02-16 12:27:50] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:27:50] Coherence C_total: 0.621\n",
            "[2026-02-16 12:27:50] Mode: SLEEP\n",
            "[2026-02-16 12:27:50] Energy: 0.71, Coherence: 0.62, Novelty: 0.92\n",
            "[2026-02-16 12:27:50] Emotion: curious, Mood: 0.55\n",
            "[2026-02-16 12:27:50] Generated 4 proposals\n",
            "[2026-02-16 12:27:50] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:50] ‚öñÔ∏è  Reward: +0.138, PredError: 0.431, Valence: -0.078, MatchScore: 0.50\n",
            "[2026-02-16 12:27:50] Executed: No action\n",
            "[2026-02-16 12:27:50] Tick 14 complete\n",
            "[2026-02-16 12:27:55] \n",
            "============================================================\n",
            "[2026-02-16 12:27:55] TICK 15\n",
            "[2026-02-16 12:27:55] ============================================================\n",
            "[2026-02-16 12:27:55] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:27:55] Coherence C_total: 0.621\n",
            "[2026-02-16 12:27:55] Mode: SLEEP\n",
            "[2026-02-16 12:27:55] Energy: 0.70, Coherence: 0.61, Novelty: 0.90\n",
            "[2026-02-16 12:27:55] Emotion: curious, Mood: 0.55\n",
            "[2026-02-16 12:27:55] Generated 4 proposals\n",
            "[2026-02-16 12:27:55] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:27:55] ‚öñÔ∏è  Reward: +0.058, PredError: 0.471, Valence: -0.177, MatchScore: 0.50\n",
            "[2026-02-16 12:27:55] Executed: No action\n",
            "[2026-02-16 12:27:55] State saved\n",
            "[2026-02-16 12:27:55] Tick 15 complete\n",
            "[2026-02-16 12:28:00] \n",
            "============================================================\n",
            "[2026-02-16 12:28:00] TICK 16\n",
            "[2026-02-16 12:28:00] ============================================================\n",
            "[2026-02-16 12:28:00] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:28:00] Coherence C_total: 0.622\n",
            "[2026-02-16 12:28:00] Mode: SLEEP\n",
            "[2026-02-16 12:28:00] Energy: 0.69, Coherence: 0.61, Novelty: 0.89\n",
            "[2026-02-16 12:28:00] Emotion: curious, Mood: 0.56\n",
            "[2026-02-16 12:28:00] Generated 4 proposals\n",
            "[2026-02-16 12:28:00] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:00] ‚öñÔ∏è  Reward: +0.137, PredError: 0.431, Valence: -0.079, MatchScore: 0.50\n",
            "[2026-02-16 12:28:00] Executed: No action\n",
            "[2026-02-16 12:28:00] Tick 16 complete\n",
            "[2026-02-16 12:28:05] \n",
            "============================================================\n",
            "[2026-02-16 12:28:05] TICK 17\n",
            "[2026-02-16 12:28:05] ============================================================\n",
            "[2026-02-16 12:28:05] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:28:05] Coherence C_total: 0.622\n",
            "[2026-02-16 12:28:05] Mode: SLEEP\n",
            "[2026-02-16 12:28:05] Energy: 0.68, Coherence: 0.61, Novelty: 0.87\n",
            "[2026-02-16 12:28:05] Emotion: curious, Mood: 0.56\n",
            "[2026-02-16 12:28:05] Generated 4 proposals\n",
            "[2026-02-16 12:28:05] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:05] ‚öñÔ∏è  Reward: +0.184, PredError: 0.408, Valence: -0.019, MatchScore: 0.50\n",
            "[2026-02-16 12:28:05] Executed: No action\n",
            "[2026-02-16 12:28:05] Tick 17 complete\n",
            "[2026-02-16 12:28:10] \n",
            "============================================================\n",
            "[2026-02-16 12:28:10] TICK 18\n",
            "[2026-02-16 12:28:10] ============================================================\n",
            "[2026-02-16 12:28:10] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:28:10] Coherence C_total: 0.622\n",
            "[2026-02-16 12:28:10] Mode: SLEEP\n",
            "[2026-02-16 12:28:10] Energy: 0.67, Coherence: 0.60, Novelty: 0.85\n",
            "[2026-02-16 12:28:10] Emotion: curious, Mood: 0.56\n",
            "[2026-02-16 12:28:10] Generated 4 proposals\n",
            "[2026-02-16 12:28:10] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:10] ‚öñÔ∏è  Reward: +0.134, PredError: 0.433, Valence: -0.083, MatchScore: 0.50\n",
            "[2026-02-16 12:28:10] Executed: No action\n",
            "[2026-02-16 12:28:10] Tick 18 complete\n",
            "[2026-02-16 12:28:15] === Session Complete ===\n",
            "\n",
            ">>> Injecting user input: Open the door\n",
            "[2026-02-16 12:28:15] Starting core loop for 6 ticks...\n",
            "[2026-02-16 12:28:15] \n",
            "============================================================\n",
            "[2026-02-16 12:28:15] TICK 19\n",
            "[2026-02-16 12:28:15] ============================================================\n",
            "[2026-02-16 12:28:15] Attention spotlight: ['user_query_10', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:28:15] Coherence C_total: 0.622\n",
            "[2026-02-16 12:28:15] Mode: SLEEP\n",
            "[2026-02-16 12:28:15] Energy: 0.66, Coherence: 0.60, Novelty: 0.83\n",
            "[2026-02-16 12:28:15] Emotion: curious, Mood: 0.56\n",
            "[2026-02-16 12:28:15] Generated 4 proposals\n",
            "[2026-02-16 12:28:15] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:15] ‚öñÔ∏è  Reward: +0.133, PredError: 0.434, Valence: -0.084, MatchScore: 0.50\n",
            "[2026-02-16 12:28:15] Executed: No action\n",
            "[2026-02-16 12:28:15] Tick 19 complete\n",
            "[2026-02-16 12:28:20] \n",
            "============================================================\n",
            "[2026-02-16 12:28:20] TICK 20\n",
            "[2026-02-16 12:28:20] ============================================================\n",
            "[2026-02-16 12:28:20] üì® User input: What's your current state?\n",
            "[2026-02-16 12:28:20] Attention spotlight: ['user_query_20', 'event_0bdd3db9', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918']\n",
            "[2026-02-16 12:28:20] Coherence C_total: 0.623\n",
            "[2026-02-16 12:28:20] Mode: ANSWER\n",
            "[2026-02-16 12:28:20] Energy: 0.65, Coherence: 0.60, Novelty: 0.97\n",
            "[2026-02-16 12:28:20] Emotion: curious, Mood: 0.56\n",
            "[2026-02-16 12:28:20] Generated 6 proposals\n",
            "[2026-02-16 12:28:20] Arbitration: 7 proposals, winner: SLEEP (score: 0.93)\n",
            "[2026-02-16 12:28:20] ‚ö° Intent completion: forcing a resolving action\n",
            "[2026-02-16 12:28:23] ‚öñÔ∏è  Reward: +0.102, PredError: 0.549, Valence: -0.173, MatchScore: 0.50\n",
            "[2026-02-16 12:28:23] Executed: It's fascinating to observe how my energy levels are slightly higher than my coherence, indicating a dynamic internal balance. Curiosity about improving both aspects keeps me motivated.\n",
            "[2026-02-16 12:28:23] ‚úÖ Event closed: event_0bdd3db9\n",
            "[2026-02-16 12:28:23] State saved\n",
            "[2026-02-16 12:28:23] Tick 20 complete\n",
            "[2026-02-16 12:28:28] \n",
            "============================================================\n",
            "[2026-02-16 12:28:28] TICK 21\n",
            "[2026-02-16 12:28:28] ============================================================\n",
            "[2026-02-16 12:28:28] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:28:28] Coherence C_total: 0.611\n",
            "[2026-02-16 12:28:28] Mode: SLEEP\n",
            "[2026-02-16 12:28:28] Energy: 0.64, Coherence: 0.59, Novelty: 0.95\n",
            "[2026-02-16 12:28:28] Emotion: curious, Mood: 0.57\n",
            "[2026-02-16 12:28:28] Generated 1 proposals\n",
            "[2026-02-16 12:28:28] Arbitration: 4 proposals, winner: SLEEP (score: 0.35)\n",
            "[2026-02-16 12:28:28] Entering SLEEP mode...\n",
            "[2026-02-16 12:28:28] ‚öñÔ∏è  Reward: +0.061, PredError: 0.394, Valence: -0.136, MatchScore: 0.50\n",
            "[2026-02-16 12:28:28] Executed: Sleep cycle 1 completed | verify: +0/-0/?12 pending 12‚Üí0\n",
            "[2026-02-16 12:28:28] Tick 21 complete\n",
            "[2026-02-16 12:28:33] \n",
            "============================================================\n",
            "[2026-02-16 12:28:33] TICK 22\n",
            "[2026-02-16 12:28:33] ============================================================\n",
            "[2026-02-16 12:28:33] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:28:33] Coherence C_total: 0.611\n",
            "[2026-02-16 12:28:33] Mode: REFLECT\n",
            "[2026-02-16 12:28:33] Energy: 0.99, Coherence: 0.59, Novelty: 0.93\n",
            "[2026-02-16 12:28:33] Emotion: curious, Mood: 0.57\n",
            "[2026-02-16 12:28:33] Generated 4 proposals\n",
            "[2026-02-16 12:28:33] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:33] ‚öñÔ∏è  Reward: +0.106, PredError: 0.447, Valence: -0.118, MatchScore: 0.50\n",
            "[2026-02-16 12:28:33] Executed: No action\n",
            "[2026-02-16 12:28:33] Tick 22 complete\n",
            "[2026-02-16 12:28:38] \n",
            "============================================================\n",
            "[2026-02-16 12:28:38] TICK 23\n",
            "[2026-02-16 12:28:38] ============================================================\n",
            "[2026-02-16 12:28:38] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:28:38] Coherence C_total: 0.612\n",
            "[2026-02-16 12:28:38] Mode: REFLECT\n",
            "[2026-02-16 12:28:38] Energy: 0.98, Coherence: 0.59, Novelty: 0.91\n",
            "[2026-02-16 12:28:38] Emotion: curious, Mood: 0.57\n",
            "[2026-02-16 12:28:38] Generated 4 proposals\n",
            "[2026-02-16 12:28:38] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:38] ‚öñÔ∏è  Reward: +0.135, PredError: 0.433, Valence: -0.082, MatchScore: 0.50\n",
            "[2026-02-16 12:28:38] Executed: No action\n",
            "[2026-02-16 12:28:38] Tick 23 complete\n",
            "[2026-02-16 12:28:43] \n",
            "============================================================\n",
            "[2026-02-16 12:28:43] TICK 24\n",
            "[2026-02-16 12:28:43] ============================================================\n",
            "[2026-02-16 12:28:43] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:28:43] Coherence C_total: 0.612\n",
            "[2026-02-16 12:28:43] Mode: SLEEP\n",
            "[2026-02-16 12:28:43] Energy: 0.97, Coherence: 0.59, Novelty: 0.89\n",
            "[2026-02-16 12:28:43] Emotion: curious, Mood: 0.57\n",
            "[2026-02-16 12:28:43] Generated 4 proposals\n",
            "[2026-02-16 12:28:43] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:43] ‚öñÔ∏è  Reward: +0.085, PredError: 0.458, Valence: -0.144, MatchScore: 0.50\n",
            "[2026-02-16 12:28:43] Executed: No action\n",
            "[2026-02-16 12:28:43] Tick 24 complete\n",
            "[2026-02-16 12:28:48] === Session Complete ===\n",
            "\n",
            ">>> Injecting user input: Open the box\n",
            "[2026-02-16 12:28:48] Starting core loop for 6 ticks...\n",
            "[2026-02-16 12:28:48] \n",
            "============================================================\n",
            "[2026-02-16 12:28:48] TICK 25\n",
            "[2026-02-16 12:28:48] ============================================================\n",
            "[2026-02-16 12:28:48] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:28:48] Coherence C_total: 0.612\n",
            "[2026-02-16 12:28:48] Mode: SLEEP\n",
            "[2026-02-16 12:28:48] Energy: 0.96, Coherence: 0.58, Novelty: 0.87\n",
            "[2026-02-16 12:28:48] Emotion: curious, Mood: 0.57\n",
            "[2026-02-16 12:28:48] Generated 4 proposals\n",
            "[2026-02-16 12:28:48] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:48] ‚öñÔ∏è  Reward: +0.104, PredError: 0.448, Valence: -0.120, MatchScore: 0.50\n",
            "[2026-02-16 12:28:48] Executed: No action\n",
            "[2026-02-16 12:28:48] State saved\n",
            "[2026-02-16 12:28:48] Tick 25 complete\n",
            "[2026-02-16 12:28:53] \n",
            "============================================================\n",
            "[2026-02-16 12:28:53] TICK 26\n",
            "[2026-02-16 12:28:53] ============================================================\n",
            "[2026-02-16 12:28:53] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:28:53] Coherence C_total: 0.612\n",
            "[2026-02-16 12:28:53] Mode: SLEEP\n",
            "[2026-02-16 12:28:53] Energy: 0.95, Coherence: 0.58, Novelty: 0.86\n",
            "[2026-02-16 12:28:53] Emotion: curious, Mood: 0.57\n",
            "[2026-02-16 12:28:53] Generated 4 proposals\n",
            "[2026-02-16 12:28:53] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:53] ‚öñÔ∏è  Reward: +0.133, PredError: 0.433, Valence: -0.084, MatchScore: 0.50\n",
            "[2026-02-16 12:28:53] Executed: No action\n",
            "[2026-02-16 12:28:53] Tick 26 complete\n",
            "[2026-02-16 12:28:58] \n",
            "============================================================\n",
            "[2026-02-16 12:28:58] TICK 27\n",
            "[2026-02-16 12:28:58] ============================================================\n",
            "[2026-02-16 12:28:58] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:28:58] Coherence C_total: 0.612\n",
            "[2026-02-16 12:28:58] Mode: SLEEP\n",
            "[2026-02-16 12:28:58] Energy: 0.94, Coherence: 0.58, Novelty: 0.84\n",
            "[2026-02-16 12:28:58] Emotion: curious, Mood: 0.57\n",
            "[2026-02-16 12:28:58] Generated 4 proposals\n",
            "[2026-02-16 12:28:58] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:28:58] ‚öñÔ∏è  Reward: +0.052, PredError: 0.474, Valence: -0.185, MatchScore: 0.50\n",
            "[2026-02-16 12:28:58] Executed: No action\n",
            "[2026-02-16 12:28:58] Tick 27 complete\n",
            "[2026-02-16 12:29:03] \n",
            "============================================================\n",
            "[2026-02-16 12:29:03] TICK 28\n",
            "[2026-02-16 12:29:03] ============================================================\n",
            "[2026-02-16 12:29:03] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:29:03] Coherence C_total: 0.612\n",
            "[2026-02-16 12:29:03] Mode: SLEEP\n",
            "[2026-02-16 12:29:03] Energy: 0.93, Coherence: 0.58, Novelty: 0.82\n",
            "[2026-02-16 12:29:03] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:03] Generated 4 proposals\n",
            "[2026-02-16 12:29:03] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:29:03] ‚öñÔ∏è  Reward: +0.081, PredError: 0.460, Valence: -0.149, MatchScore: 0.50\n",
            "[2026-02-16 12:29:03] Executed: No action\n",
            "[2026-02-16 12:29:03] Tick 28 complete\n",
            "[2026-02-16 12:29:08] \n",
            "============================================================\n",
            "[2026-02-16 12:29:08] TICK 29\n",
            "[2026-02-16 12:29:08] ============================================================\n",
            "[2026-02-16 12:29:08] Attention spotlight: ['user_query_20', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:29:08] Coherence C_total: 0.612\n",
            "[2026-02-16 12:29:08] Mode: SLEEP\n",
            "[2026-02-16 12:29:08] Energy: 0.92, Coherence: 0.57, Novelty: 0.81\n",
            "[2026-02-16 12:29:08] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:08] Generated 4 proposals\n",
            "[2026-02-16 12:29:08] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:29:08] ‚öñÔ∏è  Reward: +0.080, PredError: 0.460, Valence: -0.150, MatchScore: 0.50\n",
            "[2026-02-16 12:29:08] Executed: No action\n",
            "[2026-02-16 12:29:08] Tick 29 complete\n",
            "[2026-02-16 12:29:13] \n",
            "============================================================\n",
            "[2026-02-16 12:29:13] TICK 30\n",
            "[2026-02-16 12:29:13] ============================================================\n",
            "[2026-02-16 12:29:13] üì® User input: Calculate 25 + 17\n",
            "[2026-02-16 12:29:13] Attention spotlight: ['user_query_30', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:29:13] Coherence C_total: 0.612\n",
            "[2026-02-16 12:29:13] Mode: ANSWER\n",
            "[2026-02-16 12:29:13] Energy: 0.91, Coherence: 0.57, Novelty: 0.94\n",
            "[2026-02-16 12:29:13] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:13] Generated 5 proposals\n",
            "[2026-02-16 12:29:13] Arbitration: 7 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:29:13] ‚öñÔ∏è  Reward: +0.177, PredError: 0.411, Valence: -0.028, MatchScore: 0.50\n",
            "[2026-02-16 12:29:13] Executed: No action\n",
            "[2026-02-16 12:29:13] State saved\n",
            "[2026-02-16 12:29:13] Tick 30 complete\n",
            "[2026-02-16 12:29:18] === Session Complete ===\n",
            "\n",
            ">>> Injecting user input: Close the box\n",
            "[2026-02-16 12:29:18] Starting core loop for 6 ticks...\n",
            "[2026-02-16 12:29:18] \n",
            "============================================================\n",
            "[2026-02-16 12:29:18] TICK 31\n",
            "[2026-02-16 12:29:18] ============================================================\n",
            "[2026-02-16 12:29:18] Attention spotlight: ['user_query_30', 'event_e269af8b', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0']\n",
            "[2026-02-16 12:29:18] Coherence C_total: 0.613\n",
            "[2026-02-16 12:29:18] Mode: SLEEP\n",
            "[2026-02-16 12:29:18] Energy: 0.90, Coherence: 0.57, Novelty: 0.92\n",
            "[2026-02-16 12:29:18] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:18] Generated 1 proposals\n",
            "[2026-02-16 12:29:18] Arbitration: 4 proposals, winner: SLEEP (score: 0.35)\n",
            "[2026-02-16 12:29:18] ‚ö° Intent completion: forcing a resolving action\n",
            "[2026-02-16 12:29:18] ‚öñÔ∏è  Reward: +0.047, PredError: 0.501, Valence: -0.203, MatchScore: 0.50\n",
            "[2026-02-16 12:29:18] Executed: üåç observe: {}, R=0.05, PE=0.00\n",
            "[2026-02-16 12:29:18] ‚úÖ Event closed: event_e269af8b\n",
            "[2026-02-16 12:29:18] Tick 31 complete\n",
            "[2026-02-16 12:29:23] \n",
            "============================================================\n",
            "[2026-02-16 12:29:23] TICK 32\n",
            "[2026-02-16 12:29:23] ============================================================\n",
            "[2026-02-16 12:29:23] Attention spotlight: ['user_query_30', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0', 'event_01c8e06f']\n",
            "[2026-02-16 12:29:23] Coherence C_total: 0.617\n",
            "[2026-02-16 12:29:23] Mode: SLEEP\n",
            "[2026-02-16 12:29:23] Energy: 0.89, Coherence: 0.57, Novelty: 0.90\n",
            "[2026-02-16 12:29:23] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:23] Generated 1 proposals\n",
            "[2026-02-16 12:29:23] Arbitration: 4 proposals, winner: SLEEP (score: 0.35)\n",
            "[2026-02-16 12:29:23] Entering SLEEP mode...\n",
            "[2026-02-16 12:29:23] ‚öñÔ∏è  Reward: +0.068, PredError: 0.391, Valence: -0.128, MatchScore: 0.50\n",
            "[2026-02-16 12:29:23] Executed: Sleep cycle 2 completed | verify: +0/-0/?12 pending 12‚Üí0\n",
            "[2026-02-16 12:29:23] Tick 32 complete\n",
            "[2026-02-16 12:29:28] \n",
            "============================================================\n",
            "[2026-02-16 12:29:28] TICK 33\n",
            "[2026-02-16 12:29:28] ============================================================\n",
            "[2026-02-16 12:29:28] Attention spotlight: ['user_query_30', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0', 'event_01c8e06f']\n",
            "[2026-02-16 12:29:28] Coherence C_total: 0.617\n",
            "[2026-02-16 12:29:28] Mode: REFLECT\n",
            "[2026-02-16 12:29:28] Energy: 0.99, Coherence: 0.57, Novelty: 0.88\n",
            "[2026-02-16 12:29:28] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:28] Generated 4 proposals\n",
            "[2026-02-16 12:29:28] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:29:28] ‚öñÔ∏è  Reward: +0.116, PredError: 0.442, Valence: -0.104, MatchScore: 0.50\n",
            "[2026-02-16 12:29:28] Executed: No action\n",
            "[2026-02-16 12:29:28] Tick 33 complete\n",
            "[2026-02-16 12:29:33] \n",
            "============================================================\n",
            "[2026-02-16 12:29:33] TICK 34\n",
            "[2026-02-16 12:29:33] ============================================================\n",
            "[2026-02-16 12:29:33] Attention spotlight: ['user_query_30', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0', 'event_01c8e06f']\n",
            "[2026-02-16 12:29:33] Coherence C_total: 0.617\n",
            "[2026-02-16 12:29:33] Mode: REFLECT\n",
            "[2026-02-16 12:29:33] Energy: 0.98, Coherence: 0.57, Novelty: 0.87\n",
            "[2026-02-16 12:29:33] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:33] Generated 4 proposals\n",
            "[2026-02-16 12:29:33] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:29:33] ‚öñÔ∏è  Reward: +0.098, PredError: 0.451, Valence: -0.128, MatchScore: 0.50\n",
            "[2026-02-16 12:29:33] Executed: No action\n",
            "[2026-02-16 12:29:33] Tick 34 complete\n",
            "[2026-02-16 12:29:38] \n",
            "============================================================\n",
            "[2026-02-16 12:29:38] TICK 35\n",
            "[2026-02-16 12:29:38] ============================================================\n",
            "[2026-02-16 12:29:38] Attention spotlight: ['user_query_30', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0', 'event_01c8e06f']\n",
            "[2026-02-16 12:29:38] Coherence C_total: 0.618\n",
            "[2026-02-16 12:29:38] Mode: SLEEP\n",
            "[2026-02-16 12:29:38] Energy: 0.97, Coherence: 0.57, Novelty: 0.85\n",
            "[2026-02-16 12:29:38] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:38] Generated 4 proposals\n",
            "[2026-02-16 12:29:38] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:29:38] ‚öñÔ∏è  Reward: +0.047, PredError: 0.477, Valence: -0.191, MatchScore: 0.50\n",
            "[2026-02-16 12:29:38] Executed: No action\n",
            "[2026-02-16 12:29:38] State saved\n",
            "[2026-02-16 12:29:38] Tick 35 complete\n",
            "[2026-02-16 12:29:43] \n",
            "============================================================\n",
            "[2026-02-16 12:29:43] TICK 36\n",
            "[2026-02-16 12:29:43] ============================================================\n",
            "[2026-02-16 12:29:43] Attention spotlight: ['user_query_30', 'event_bfc52ba1', 'event_8df4a085', 'event_7fae8918', 'event_9da51bb0', 'event_01c8e06f']\n",
            "[2026-02-16 12:29:43] Coherence C_total: 0.618\n",
            "[2026-02-16 12:29:43] Mode: SLEEP\n",
            "[2026-02-16 12:29:43] Energy: 0.96, Coherence: 0.57, Novelty: 0.83\n",
            "[2026-02-16 12:29:43] Emotion: curious, Mood: 0.58\n",
            "[2026-02-16 12:29:43] Generated 4 proposals\n",
            "[2026-02-16 12:29:43] Arbitration: 6 proposals, winner: META (score: 0.38)\n",
            "[2026-02-16 12:29:43] ‚öñÔ∏è  Reward: +0.076, PredError: 0.462, Valence: -0.155, MatchScore: 0.50\n",
            "[2026-02-16 12:29:43] Executed: No action\n",
            "[2026-02-16 12:29:43] Tick 36 complete\n",
            "[2026-02-16 12:29:48] === Session Complete ===\n",
            "\n",
            "=== Test-input session complete ===\n"
          ]
        }
      ],
      "source": [
        "# CELL 17: Initialize and Run\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CR-SSCP v3.2 - Consciousness-like Cognitive Architecture\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "core_loop = CoreLoop(state_manager, llm)\n",
        "\n",
        "# Print initial state\n",
        "print(f\"Initial Coherence: {state_manager.state['coherence']['C_total']:.3f}\")\n",
        "print(f\"Initial Energy: {state_manager.state['drives']['energy']:.2f}\")\n",
        "print(f\"Initial Emotion: {state_manager.state['affect']['current_emotion']}\")\n",
        "print(f\"Mode: {state_manager.state['pb']['mode']}\")\n",
        "print(f\"\\nIdentity anchors:\")\n",
        "for anchor in state_manager.state['narrative']['identity_anchors']:\n",
        "    print(f\"  - {anchor}\")\n",
        "\n",
        "print(f\"\\nRunning {Config.MAX_TICKS} ticks (~{Config.MAX_TICKS * Config.TICK_INTERVAL // 60} minutes)...\\n\")\n",
        "\n",
        "# Run the loop\n",
        "if RUN_AUTOPILOT:\n",
        "    core_loop.run(max_ticks=Config.MAX_TICKS)\n",
        "else:\n",
        "    run_with_test_inputs(state_manager, core_loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "df62eece",
      "metadata": {
        "id": "df62eece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6695c0-ce64-433c-d99f-1dc1f127509f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SESSION ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Total ticks: 36\n",
            "Sleep cycles: 2\n",
            "Mode flips: 9\n",
            "\n",
            "Final Metrics:\n",
            "  Coherence (C_total): 0.618\n",
            "  - Evidence (Ce): 0.214\n",
            "  - Historical (Ch): 1.000\n",
            "  - Structural (Cs): 1.000\n",
            "  - Identity (Ci): 0.517\n",
            "  - Predictive (Cp): 0.500\n",
            "\n",
            "Drive States:\n",
            "  coherence: 0.56\n",
            "  uncertainty: 0.10\n",
            "  prediction_error: 0.45\n",
            "  novelty: 0.83\n",
            "  energy: 0.96\n",
            "  social_commitment: 0.10\n",
            "\n",
            "Affective State:\n",
            "  Emotion: frustrated\n",
            "  Mood: 0.58\n",
            "\n",
            "Memory:\n",
            "  Grounded facts: 5\n",
            "  Ungrounded notes: 1\n",
            "  Quarantined: 0\n",
            "\n",
            "Agency:\n",
            "  Self-initiated actions: 31/36\n",
            "  External-triggered actions: 5/36\n",
            "  Causal Closure Ratio (self-initiated/total): 86.11%\n",
            "\n",
            "Claim Ledger:\n",
            "  Total claims: 42\n",
            "  Verified claims: 0\n",
            "  Failed claims: 0\n",
            "  Uncertain claims: 37\n",
            "  Pending claims: 5\n",
            "\n",
            "Narrative:\n",
            "  Current arc: exploration\n",
            "  Theme: discovering capabilities\n",
            "\n",
            "============================================================\n",
            "State saved to: /content/drive/MyDrive/crsscp_state.json\n",
            "Logs saved to: /content/drive/MyDrive/crsscp_logs.txt\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# CELL 18: Analysis and Metrics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SESSION ANALYSIS\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "final_state = state_manager.state\n",
        "\n",
        "print(f\"Total ticks: {final_state['tick_count']}\")\n",
        "print(f\"Sleep cycles: {final_state['sleep_count']}\")\n",
        "print(f\"Mode flips: {final_state.get('metrics', {}).get('mode_flip_count', 0)}\")\n",
        "\n",
        "print(f\"\\nFinal Metrics:\")\n",
        "print(f\"  Coherence (C_total): {final_state['coherence']['C_total']:.3f}\")\n",
        "print(f\"  - Evidence (Ce): {final_state['coherence']['Ce']:.3f}\")\n",
        "print(f\"  - Historical (Ch): {final_state['coherence']['Ch']:.3f}\")\n",
        "print(f\"  - Structural (Cs): {final_state['coherence']['Cs']:.3f}\")\n",
        "print(f\"  - Identity (Ci): {final_state['coherence']['Ci']:.3f}\")\n",
        "print(f\"  - Predictive (Cp): {final_state['coherence']['Cp']:.3f}\")\n",
        "\n",
        "print(f\"\\nDrive States:\")\n",
        "for drive, value in final_state['drives'].items():\n",
        "    print(f\"  {drive}: {value:.2f}\")\n",
        "\n",
        "print(f\"\\nAffective State:\")\n",
        "print(f\"  Emotion: {final_state['affect']['current_emotion']}\")\n",
        "print(f\"  Mood: {final_state['affect']['mood']:.2f}\")\n",
        "\n",
        "print(f\"\\nMemory:\")\n",
        "print(f\"  Grounded facts: {len(final_state['memory']['grounded'])}\")\n",
        "print(f\"  Ungrounded notes: {len(final_state['memory']['ungrounded'])}\")\n",
        "print(f\"  Quarantined: {len(final_state['memory']['quarantine'])}\")\n",
        "\n",
        "print(f\"\\nAgency:\")\n",
        "self_actions = sum(1 for a in final_state['agency']['authorship_log'] if a['authorship'] == 'self_initiated')\n",
        "total_actions = len(final_state['agency']['authorship_log'])\n",
        "external_actions = sum(1 for a in final_state['agency']['authorship_log'] if a['authorship'] == 'external_triggered')\n",
        "print(f\"  Self-initiated actions: {self_actions}/{total_actions}\")\n",
        "print(f\"  External-triggered actions: {external_actions}/{total_actions}\")\n",
        "if total_actions > 0:\n",
        "    print(f\"  Causal Closure Ratio (self-initiated/total): {self_actions/total_actions:.2%}\")\n",
        "\n",
        "print(f\"\\nClaim Ledger:\")\n",
        "print(f\"  Total claims: {len(final_state['claim_ledger'])}\")\n",
        "verified = sum(1 for c in final_state['claim_ledger'] if c.get('verifier_result') == 'pass')\n",
        "failed = sum(1 for c in final_state['claim_ledger'] if c.get('verifier_result') == 'fail')\n",
        "uncertain = sum(1 for c in final_state['claim_ledger'] if c.get('verifier_result') == 'uncertain')\n",
        "pending = sum(1 for c in final_state['claim_ledger'] if c.get('verifier_result') == 'pending')\n",
        "print(f\"  Verified claims: {verified}\")\n",
        "print(f\"  Failed claims: {failed}\")\n",
        "print(f\"  Uncertain claims: {uncertain}\")\n",
        "print(f\"  Pending claims: {pending}\")\n",
        "\n",
        "print(f\"\\nNarrative:\")\n",
        "print(f\"  Current arc: {final_state['narrative']['current_arc']['direction']}\")\n",
        "print(f\"  Theme: {final_state['narrative']['current_arc']['meaning']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"State saved to: {Config.STATE_PATH}\")\n",
        "print(f\"Logs saved to: {Config.LOG_PATH}\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "H100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c8850be07204dc58a90dcd2218c90d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba26487ea18e45dda3d82fc304631457",
              "IPY_MODEL_8c54ad31897043cdbaa28a2d44a58d0f",
              "IPY_MODEL_dd43bd0ae0f54dfe8f6f89e3c08c5b59"
            ],
            "layout": "IPY_MODEL_03a669e8c305416392302fc1304db408"
          }
        },
        "ba26487ea18e45dda3d82fc304631457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e8bf8cf51049d1b895144ea6fad1f8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_53a9a10837b74fdd928f2a9a7b0406e7",
            "value": "config.json:‚Äá100%"
          }
        },
        "8c54ad31897043cdbaa28a2d44a58d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f76f03c14a34968adf45cc7122241c3",
            "max": 663,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d371cd8f8cd476b943e7d073bbc07ad",
            "value": 663
          }
        },
        "dd43bd0ae0f54dfe8f6f89e3c08c5b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec1315901b24144b09ce56dc61bb3d4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e00d8f201ced49f9a088b37ea28d1409",
            "value": "‚Äá663/663‚Äá[00:00&lt;00:00,‚Äá140kB/s]"
          }
        },
        "03a669e8c305416392302fc1304db408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e8bf8cf51049d1b895144ea6fad1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a9a10837b74fdd928f2a9a7b0406e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f76f03c14a34968adf45cc7122241c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d371cd8f8cd476b943e7d073bbc07ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ec1315901b24144b09ce56dc61bb3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00d8f201ced49f9a088b37ea28d1409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0a58eaca8a9412caae8ba3841f20997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d0e4742096c464e805405bb207b6532",
              "IPY_MODEL_7968147cb0ce4dd28adbbcdc6baed77b",
              "IPY_MODEL_a6ce031419284065b517626c697bfc10"
            ],
            "layout": "IPY_MODEL_6b6ed3674c3b440cbecb4a2a8804bc0f"
          }
        },
        "0d0e4742096c464e805405bb207b6532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872baee055a342e7ae92008d6ef2c1f4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bc460b9ed3b149b280460daa68a59b71",
            "value": "tokenizer_config.json:‚Äá"
          }
        },
        "7968147cb0ce4dd28adbbcdc6baed77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dae663b4113472e8050d20eb445865f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9f13a24c5224dfba2df0c5ae397862b",
            "value": 1
          }
        },
        "a6ce031419284065b517626c697bfc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02e92ef49124c4cb5b6b32d6d79008f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9e8dd5420a99404e9a07ad014682a978",
            "value": "‚Äá7.30k/?‚Äá[00:00&lt;00:00,‚Äá1.38MB/s]"
          }
        },
        "6b6ed3674c3b440cbecb4a2a8804bc0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872baee055a342e7ae92008d6ef2c1f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc460b9ed3b149b280460daa68a59b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dae663b4113472e8050d20eb445865f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f9f13a24c5224dfba2df0c5ae397862b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02e92ef49124c4cb5b6b32d6d79008f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e8dd5420a99404e9a07ad014682a978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a95136bfbd74dbf9e988ed2bedfaede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bccf7eec51894fbea8ecbb3b8276c548",
              "IPY_MODEL_9773f4e22a9a4ff48318e4fa333110dd",
              "IPY_MODEL_2d66248bc34c4b1baefe8460971f32b4"
            ],
            "layout": "IPY_MODEL_1fc9ea1de49c444da42e686bfdc7a846"
          }
        },
        "bccf7eec51894fbea8ecbb3b8276c548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfb66e472616424e9d63cfb4e95ab3b5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5abe4a0e44db46b09f5ee8bd8e926c19",
            "value": "vocab.json:‚Äá"
          }
        },
        "9773f4e22a9a4ff48318e4fa333110dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d561a371994d3ca3f243c7b255dc1e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcde097123c949da963ae11e72edd046",
            "value": 1
          }
        },
        "2d66248bc34c4b1baefe8460971f32b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af1adc26d5474731883057d8e1572d26",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d96d8a67f84840569aa2324d1c3f7b66",
            "value": "‚Äá2.78M/?‚Äá[00:00&lt;00:00,‚Äá96.5MB/s]"
          }
        },
        "1fc9ea1de49c444da42e686bfdc7a846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb66e472616424e9d63cfb4e95ab3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abe4a0e44db46b09f5ee8bd8e926c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d561a371994d3ca3f243c7b255dc1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dcde097123c949da963ae11e72edd046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af1adc26d5474731883057d8e1572d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d96d8a67f84840569aa2324d1c3f7b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b22b8e2f864f455d91bfc9eca5a4383a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50b765a18a4d488fb5e6eef328cc90a0",
              "IPY_MODEL_3f2e4912c2f74d36aa2c5483d7802bf2",
              "IPY_MODEL_9a45464d652a463189444a5531518418"
            ],
            "layout": "IPY_MODEL_c922c973bba14b61aff65a40b4a59c8b"
          }
        },
        "50b765a18a4d488fb5e6eef328cc90a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d69a19a3ea24f879ffbcf3b2b6f1f52",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a879de09ebd84f5498ad5ec098902b66",
            "value": "merges.txt:‚Äá"
          }
        },
        "3f2e4912c2f74d36aa2c5483d7802bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a7a756b7dc47c2a64fa888889181ac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca867e5401cd43fbad91fd6459834823",
            "value": 1
          }
        },
        "9a45464d652a463189444a5531518418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0faca91f71a449f2855d4fd258c9a6cf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6f507596930548a6bf250143b8a346c7",
            "value": "‚Äá1.67M/?‚Äá[00:00&lt;00:00,‚Äá92.1MB/s]"
          }
        },
        "c922c973bba14b61aff65a40b4a59c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d69a19a3ea24f879ffbcf3b2b6f1f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a879de09ebd84f5498ad5ec098902b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6a7a756b7dc47c2a64fa888889181ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca867e5401cd43fbad91fd6459834823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0faca91f71a449f2855d4fd258c9a6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f507596930548a6bf250143b8a346c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52808ed0835844a088b90aa60d80983d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98575bdf65f943e091fa9b18b060f2ea",
              "IPY_MODEL_bfa48cbf0fdf4d1aba798678e77fe709",
              "IPY_MODEL_3dd27293438c4f278ffda48458eec4fb"
            ],
            "layout": "IPY_MODEL_5154a1bc404a4341a213edb6e4ad0c9e"
          }
        },
        "98575bdf65f943e091fa9b18b060f2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c1e49b07a7a44aaaaaa74040fbde8a9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_599b5fe137ed4c878e77b395600bc442",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "bfa48cbf0fdf4d1aba798678e77fe709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfe568c38e274001bbfb7927732881d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_342ecc94cbe24c29a1e9a6a6620faabb",
            "value": 1
          }
        },
        "3dd27293438c4f278ffda48458eec4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18f948b13aa4ad6af071ffda94b953c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c24e59b9116a4e3a9e83733e575809e7",
            "value": "‚Äá7.03M/?‚Äá[00:00&lt;00:00,‚Äá158MB/s]"
          }
        },
        "5154a1bc404a4341a213edb6e4ad0c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c1e49b07a7a44aaaaaa74040fbde8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "599b5fe137ed4c878e77b395600bc442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfe568c38e274001bbfb7927732881d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "342ecc94cbe24c29a1e9a6a6620faabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c18f948b13aa4ad6af071ffda94b953c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24e59b9116a4e3a9e83733e575809e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c238b0cef9cb4837a0c9595dc510aecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f6dfaeca3c241f8a6248da7a3d9eb47",
              "IPY_MODEL_c83441c0f6fc497f80a7718a12d01973",
              "IPY_MODEL_28a143ca0bf045de8d818e25365d83ea"
            ],
            "layout": "IPY_MODEL_45e43b25b0494a2baf50e63798831998"
          }
        },
        "0f6dfaeca3c241f8a6248da7a3d9eb47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_653abbf9f0a5494d82e1686fd072053b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f66f89fdece416d947f0353fb068392",
            "value": "model.safetensors.index.json:‚Äá"
          }
        },
        "c83441c0f6fc497f80a7718a12d01973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99fb7b619bb64eb3882d5a72087d979a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0da8c6b972094809bd004bed413d638f",
            "value": 1
          }
        },
        "28a143ca0bf045de8d818e25365d83ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c79c814a3eb4a15a7b8ac12ba6eac0d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_090ecfc0c12e44ee97c5dfc849d215fa",
            "value": "‚Äá27.8k/?‚Äá[00:00&lt;00:00,‚Äá4.06MB/s]"
          }
        },
        "45e43b25b0494a2baf50e63798831998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653abbf9f0a5494d82e1686fd072053b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f66f89fdece416d947f0353fb068392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99fb7b619bb64eb3882d5a72087d979a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0da8c6b972094809bd004bed413d638f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c79c814a3eb4a15a7b8ac12ba6eac0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090ecfc0c12e44ee97c5dfc849d215fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2530ced3ecbf4a8eb564106b82a17677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad37ce9175174e20b42fa9ab63b8869a",
              "IPY_MODEL_ee3d1d159632415f97fb963b91e7c405",
              "IPY_MODEL_ed7c6fc3421e4e739cbb62b17cd31e4f"
            ],
            "layout": "IPY_MODEL_a5f0ca771c3c4c659d1beadc246df2e7"
          }
        },
        "ad37ce9175174e20b42fa9ab63b8869a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67f8b485c98e4e249909a5a283e76057",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6241d31bdd5343a6bcdaed16de4b6337",
            "value": "Download‚Äácomplete:‚Äá100%"
          }
        },
        "ee3d1d159632415f97fb963b91e7c405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93f05e1cf7540398518bd2641c0a291",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_985baec613354784950265f167e03119",
            "value": 1
          }
        },
        "ed7c6fc3421e4e739cbb62b17cd31e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875ada384b42429483d85cd7994deba4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bdfff935187d4f12b1559b213e8cca77",
            "value": "‚Äá15.2G/15.2G‚Äá[00:49&lt;00:00,‚Äá356MB/s]"
          }
        },
        "a5f0ca771c3c4c659d1beadc246df2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f8b485c98e4e249909a5a283e76057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6241d31bdd5343a6bcdaed16de4b6337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93f05e1cf7540398518bd2641c0a291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "985baec613354784950265f167e03119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "875ada384b42429483d85cd7994deba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdfff935187d4f12b1559b213e8cca77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29a3c9cbe2454387baf3748f6c1eaf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f60540b4bb994ee38b7105bb58a25ba5",
              "IPY_MODEL_67c39a9ebe204956822267b139911d6f",
              "IPY_MODEL_867679b164a5458fbc9567081a5e3d9f"
            ],
            "layout": "IPY_MODEL_2e16de24fcbc4cda8a0e9dfc011e9464"
          }
        },
        "f60540b4bb994ee38b7105bb58a25ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638fb77053194886b39bde1b63784be8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_457b38af2aea4cbb884a4217f5b6068c",
            "value": "Fetching‚Äá4‚Äáfiles:‚Äá100%"
          }
        },
        "67c39a9ebe204956822267b139911d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1b01e60f2d46cfaba53d98fe48b396",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34c80b48bb9b4ac589120e6ae65ae7b6",
            "value": 4
          }
        },
        "867679b164a5458fbc9567081a5e3d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad90caa7cbc48c48e8ce0dd6f5c5a7e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0f85cfadbc8b490aa5a47ea4f05a1b3a",
            "value": "‚Äá4/4‚Äá[00:49&lt;00:00,‚Äá49.57s/it]"
          }
        },
        "2e16de24fcbc4cda8a0e9dfc011e9464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638fb77053194886b39bde1b63784be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457b38af2aea4cbb884a4217f5b6068c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b1b01e60f2d46cfaba53d98fe48b396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c80b48bb9b4ac589120e6ae65ae7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ad90caa7cbc48c48e8ce0dd6f5c5a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f85cfadbc8b490aa5a47ea4f05a1b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3241a71b944e4f3bb932542b6bbf20d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_632be2d52f6e4bc18c36fff24ea356d1",
              "IPY_MODEL_2cc44924edeb441f94c3c7778dd0501a",
              "IPY_MODEL_17fbb0efa5e0482a97d63f17676d679f"
            ],
            "layout": "IPY_MODEL_85472e70709c42c1ae601c6fcbc0d74e"
          }
        },
        "632be2d52f6e4bc18c36fff24ea356d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70995f59a76c45caa635b93789c1d7de",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b669095f9f8a40e3b50897ff596da0a2",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "2cc44924edeb441f94c3c7778dd0501a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ac32db0fac46c190bc8ca4babdc1e7",
            "max": 339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acf248c5e0d148f4bbdadd5dc865d6a3",
            "value": 339
          }
        },
        "17fbb0efa5e0482a97d63f17676d679f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fecf941ed5e14560a97b9d757d866c31",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_21a53af27469445aa886f6923e97e284",
            "value": "‚Äá339/339‚Äá[00:02&lt;00:00,‚Äá386.19it/s,‚ÄáMaterializing‚Äáparam=model.norm.weight]"
          }
        },
        "85472e70709c42c1ae601c6fcbc0d74e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70995f59a76c45caa635b93789c1d7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b669095f9f8a40e3b50897ff596da0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96ac32db0fac46c190bc8ca4babdc1e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acf248c5e0d148f4bbdadd5dc865d6a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fecf941ed5e14560a97b9d757d866c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a53af27469445aa886f6923e97e284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e14ef665804e4215a8eadbea4bb5b367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd24a20452164b2188525b0621315114",
              "IPY_MODEL_0a1f498bcc194fd994ce2f998a8e74b6",
              "IPY_MODEL_9cbd8ce83ebf47f7a21078b2246d5cd1"
            ],
            "layout": "IPY_MODEL_cba42e119d2f4ffd8e5c7218fab0c55a"
          }
        },
        "cd24a20452164b2188525b0621315114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95e7b11b4ee47cca94af95990919856",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4fb0754f02144d958e11c82886e6ff3b",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "0a1f498bcc194fd994ce2f998a8e74b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df723ea6b48c432088d0b2f6737c981a",
            "max": 243,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cc95d165136484787dcd57a0f2095ba",
            "value": 243
          }
        },
        "9cbd8ce83ebf47f7a21078b2246d5cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3bcb4424fe5427480de01c04a1ea132",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_95d618d14ebf4df6965a6fce2881a65a",
            "value": "‚Äá243/243‚Äá[00:00&lt;00:00,‚Äá58.5kB/s]"
          }
        },
        "cba42e119d2f4ffd8e5c7218fab0c55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95e7b11b4ee47cca94af95990919856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb0754f02144d958e11c82886e6ff3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df723ea6b48c432088d0b2f6737c981a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cc95d165136484787dcd57a0f2095ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3bcb4424fe5427480de01c04a1ea132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d618d14ebf4df6965a6fce2881a65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}